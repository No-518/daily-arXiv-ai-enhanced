<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 84]
- [cs.RO](#cs.RO) [Total: 23]
- [cs.AI](#cs.AI) [Total: 55]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Do Open-Vocabulary Detectors Transfer to Aerial Imagery? A Comparative Evaluation](https://arxiv.org/abs/2601.22164)
*Christos Tsourveloudis*

Main category: cs.CV

TL;DR: First benchmark of open-vocabulary detection on aerial imagery shows severe domain transfer failure, with semantic confusion as primary bottleneck, not visual localization.


<details>
  <summary>Details</summary>
Motivation: Open-vocabulary detection works well on natural images but transferability to aerial imagery remains unexplored, requiring systematic evaluation.

Method: Benchmarked 5 state-of-the-art OVD models on LAE-80C aerial dataset (3,592 images, 80 categories) under strict zero-shot conditions with Global, Oracle, and Single-Category inference modes to isolate semantic confusion from visual localization.

Result: Severe domain transfer failure: best model (OWLv2) achieved only 27.6% F1-score with 69% false positive rate. Reducing vocabulary size from 80 to 3.2 classes yielded 15x improvement. Prompt engineering failed to help. Performance varied dramatically across datasets (F1: 0.53 on DIOR, 0.12 on FAIR1M).

Conclusion: Semantic confusion is primary bottleneck in aerial OVD, not visual localization. Findings establish baseline expectations and highlight need for domain-adaptive approaches in aerial open-vocabulary detection.

Abstract: Open-vocabulary object detection (OVD) enables zero-shot recognition of novel categories through vision-language models, achieving strong performance on natural images. However, transferability to aerial imagery remains unexplored. We present the first systematic benchmark evaluating five state-of-the-art OVD models on the LAE-80C aerial dataset (3,592 images, 80 categories) under strict zero-shot conditions. Our experimental protocol isolates semantic confusion from visual localization through Global, Oracle, and Single-Category inference modes. Results reveal severe domain transfer failure: the best model (OWLv2) achieves only 27.6% F1-score with 69% false positive rate. Critically, reducing vocabulary size from 80 to 3.2 classes yields 15x improvement, demonstrating that semantic confusion is the primary bottleneck. Prompt engineering strategies such as domain-specific prefixing and synonym expansion, fail to provide meaningful performance gains. Performance varies dramatically across datasets (F1: 0.53 on DIOR, 0.12 on FAIR1M), exposing brittleness to imaging conditions. These findings establish baseline expectations and highlight the need for domain-adaptive approaches in aerial OVD.

</details>


### [2] [What Lies Beneath: A Call for Distribution-based Visual Question & Answer Datasets](https://arxiv.org/abs/2601.22218)
*Jill P. Naiman,Daniel J. Evans,JooYoung Seo*

Main category: cs.CV

TL;DR: Proposes a new VQA benchmark for scientific charts where answers require reasoning about underlying data, not just chart marks.


<details>
  <summary>Details</summary>
Motivation: Current VQA datasets lack scientific chart interpretation where charts are transformations of data, not direct representations, creating a reasoning gap.

Method: Survey existing VQA datasets, generate synthetic histogram charts with ground truth data, test humans and large reasoning models on questions requiring underlying data access.

Result: Release open-source dataset with figures, underlying data, distribution parameters, and bounding boxes for all figure marks and text.

Conclusion: Need dedicated VQA benchmark for scientific charts without 1-to-1 correspondence between chart marks and underlying data to address current limitations.

Abstract: Visual Question Answering (VQA) has become an important benchmark for assessing how large multimodal models (LMMs) interpret images. However, most VQA datasets focus on real-world images or simple diagrammatic analysis, with few focused on interpreting complex scientific charts. Indeed, many VQA datasets that analyze charts do not contain the underlying data behind those charts or assume a 1-to-1 correspondence between chart marks and underlying data. In reality, charts are transformations (i.e. analysis, simplification, modification) of data. This distinction introduces a reasoning challenge in VQA that the current datasets do not capture. In this paper, we argue for a dedicated VQA benchmark for scientific charts where there is no 1-to-1 correspondence between chart marks and underlying data. To do so, we survey existing VQA datasets and highlight limitations of the current field. We then generate synthetic histogram charts based on ground truth data, and ask both humans and a large reasoning model questions where precise answers depend on access to the underlying data. We release the open-source dataset, including figures, underlying data, distribution parameters used to generate the data, and bounding boxes for all figure marks and text for future research.

</details>


### [3] [Lost in Space? Vision-Language Models Struggle with Relative Camera Pose Estimation](https://arxiv.org/abs/2601.22228)
*Ken Deng,Yifu Qiu,Yoni Kasten,Shay B. Cohen,Yftah Ziser*

Main category: cs.CV

TL;DR: VLMs struggle with 3D spatial reasoning, particularly in relative camera pose estimation, performing worse than classic geometric methods and humans.


<details>
  <summary>Details</summary>
Motivation: To investigate the gap between VLMs' strong 2D perception capabilities and their limited understanding of 3D spatial structure, using relative camera pose estimation as a fundamental test case.

Method: Created two benchmarks: VRRPI-Bench (from unlabeled egocentric videos with verbalized camera motion annotations) and VRRPI-Diag (isolating individual motion degrees of freedom). Tested VLMs on relative camera pose estimation tasks.

Result: Most VLMs fail to generalize beyond shallow 2D heuristics, especially for depth changes and roll transformations. Even state-of-the-art models like GPT-5 (0.64) underperform classic geometric baselines (0.97) and humans (0.92). VLMs also struggle with multi-image reasoning (best 59.7%).

Conclusion: VLMs have significant limitations in 3D spatial grounding and multi-view reasoning, revealing fundamental gaps in their spatial understanding capabilities.

Abstract: Vision-Language Models (VLMs) perform well in 2D perception and semantic reasoning compared to their limited understanding of 3D spatial structure. We investigate this gap using relative camera pose estimation (RCPE), a fundamental vision task that requires inferring relative camera translation and rotation from a pair of images. We introduce VRRPI-Bench, a benchmark derived from unlabeled egocentric videos with verbalized annotations of relative camera motion, reflecting realistic scenarios with simultaneous translation and rotation around a shared object. We further propose VRRPI-Diag, a diagnostic benchmark that isolates individual motion degrees of freedom. Despite the simplicity of RCPE, most VLMs fail to generalize beyond shallow 2D heuristics, particularly for depth changes and roll transformations along the optical axis. Even state-of-the-art models such as GPT-5 ($0.64$) fall short of classic geometric baselines ($0.97$) and human performance ($0.92$). Moreover, VLMs exhibit difficulty in multi-image reasoning, with inconsistent performance (best $59.7\%$) when integrating spatial cues across frames. Our findings reveal limitations in grounding VLMs in 3D and multi-view spatial reasoning.

</details>


### [4] [Geometry without Position? When Positional Embeddings Help and Hurt Spatial Reasoning](https://arxiv.org/abs/2601.22231)
*Jian Shi,Michael Birsak,Wenqing Cui,Zhenyu Li,Peter Wonka*

Main category: cs.CV

TL;DR: PEs in ViTs act as geometric priors shaping spatial structure, not just token indices; diagnostics show they govern multi-view geometric consistency.


<details>
  <summary>Details</summary>
Motivation: To understand the true role of positional embeddings in vision transformers from a geometric perspective, moving beyond the conventional view of PEs as mere token indices.

Method: Introduce token-level diagnostics to measure multi-view geometric consistency in ViT representations dependent on consistent PEs, conduct extensive experiments on 14 foundation ViT models.

Result: Reveal how PEs influence multi-view geometry and spatial reasoning, showing they function as geometric priors that shape spatial structure of representations.

Conclusion: PEs serve as a causal mechanism governing spatial structure in ViT representations, clarifying their fundamental role in geometric reasoning.

Abstract: This paper revisits the role of positional embeddings (PEs) within vision transformers (ViTs) from a geometric perspective. We show that PEs are not mere token indices but effectively function as geometric priors that shape the spatial structure of the representation. We introduce token-level diagnostics that measure how multi-view geometric consistency in ViT representation depends on consitent PEs. Through extensive experiments on 14 foundation ViT models, we reveal how PEs influence multi-view geometry and spatial reasoning. Our findings clarify the role of PEs as a causal mechanism that governs spatial structure in ViT representations. Our code is provided in https://github.com/shijianjian/vit-geometry-probes

</details>


### [5] [Is Hierarchical Quantization Essential for Optimal Reconstruction?](https://arxiv.org/abs/2601.22244)
*Shirin Reyhanian,Laurenz Wiskott*

Main category: cs.CV

TL;DR: Single-level VQ-VAEs can match hierarchical VQ-VAE reconstruction fidelity when representational budgets are matched and codebook collapse is mitigated, challenging the assumption that hierarchical quantization is inherently superior.


<details>
  <summary>Details</summary>
Motivation: Hierarchical VQ-VAEs are credited with superior reconstruction performance, but higher levels derive all information from lower levels, so they shouldn't carry additional reconstructive content beyond what lower levels already encode. The effect of hierarchy on reconstruction accuracy, isolated from codebook utilization and capacity, remains empirically underexamined.

Method: Compared a two-level VQ-VAE with a capacity-matched single-level model on high-resolution ImageNet images. Used lightweight interventions: initialization from data, periodic reset of inactive codebook vectors, and systematic tuning of codebook hyperparameters to reduce codebook collapse.

Result: Confirmed that inadequate codebook utilization limits single-level VQ-VAEs and overly high-dimensional embeddings destabilize quantization. With matched representational budgets and mitigated codebook collapse, single-level VQ-VAEs can match the reconstruction fidelity of hierarchical variants.

Conclusion: Hierarchical quantization is not inherently superior for high-quality reconstructions. Single-level VQ-VAEs can achieve comparable reconstruction fidelity when properly configured, challenging common assumptions about the necessity of hierarchical structure for reconstruction performance.

Abstract: Vector-quantized variational autoencoders (VQ-VAEs) are central to models that rely on high reconstruction fidelity, from neural compression to generative pipelines. Hierarchical extensions, such as VQ-VAE2, are often credited with superior reconstruction performance because they split global and local features across multiple levels. However, since higher levels derive all their information from lower levels, they should not carry additional reconstructive content beyond what the lower-level already encodes. Combined with recent advances in training objectives and quantization mechanisms, this leads us to ask whether a single-level VQ-VAE, with matched representational budget and no codebook collapse, can equal the reconstruction fidelity of its hierarchical counterpart. Although the multi-scale structure of hierarchical models may improve perceptual quality in downstream tasks, the effect of hierarchy on reconstruction accuracy, isolated from codebook utilization and overall representational capacity, remains empirically underexamined. We revisit this question by comparing a two-level VQ-VAE and a capacity-matched single-level model on high-resolution ImageNet images. Consistent with prior observations, we confirm that inadequate codebook utilization limits single-level VQ-VAEs and that overly high-dimensional embeddings destabilize quantization and increase codebook collapse. We show that lightweight interventions such as initialization from data, periodic reset of inactive codebook vectors, and systematic tuning of codebook hyperparameters significantly reduce collapse. Our results demonstrate that when representational budgets are matched, and codebook collapse is mitigated, single-level VQ-VAEs can match the reconstruction fidelity of hierarchical variants, challenging the assumption that hierarchical quantization is inherently superior for high-quality reconstructions.

</details>


### [6] [VMonarch: Efficient Video Diffusion Transformers with Structured Attention](https://arxiv.org/abs/2601.22275)
*Cheng Liang,Haoxian Chen,Liang Hou,Qi Fan,Gangshan Wu,Xin Tao,Limin Wang*

Main category: cs.CV

TL;DR: VMonarch introduces a structured sparse attention mechanism using Monarch matrices to reduce quadratic complexity in Video Diffusion Transformers, achieving 17.5× FLOPs reduction and 5× speedup while maintaining generation quality.


<details>
  <summary>Details</summary>
Motivation: The quadratic complexity of attention mechanisms severely limits context scalability in Video Diffusion Transformers (DiTs), creating a computational bottleneck for long video generation.

Method: Proposes VMonarch with three key innovations: 1) Spatio-temporal Monarch factorization to capture intra-frame and inter-frame correlations, 2) Recomputation strategy to mitigate artifacts from alternating minimization instability, 3) Online entropy algorithm fused with FlashAttention for fast Monarch matrix updates.

Result: Achieves comparable or superior generation quality to full attention on VBench, reduces attention FLOPs by 17.5×, achieves over 5× speedup in attention computation for long videos, and outperforms state-of-the-art sparse attention methods at 90% sparsity.

Conclusion: VMonarch effectively overcomes the attention bottleneck in Video DiTs by leveraging structured Monarch matrices to enable efficient sub-quadratic attention computation while maintaining high-quality video generation.

Abstract: The quadratic complexity of the attention mechanism severely limits the context scalability of Video Diffusion Transformers (DiTs). We find that the highly sparse spatio-temporal attention patterns exhibited in Video DiTs can be naturally represented by the Monarch matrix. It is a class of structured matrices with flexible sparsity, enabling sub-quadratic attention via an alternating minimization algorithm. Accordingly, we propose VMonarch, a novel attention mechanism for Video DiTs that enables efficient computation over the dynamic sparse patterns with structured Monarch matrices. First, we adapt spatio-temporal Monarch factorization to explicitly capture the intra-frame and inter-frame correlations of the video data. Second, we introduce a recomputation strategy to mitigate artifacts arising from instabilities during alternating minimization of Monarch matrices. Third, we propose a novel online entropy algorithm fused into FlashAttention, enabling fast Monarch matrix updates for long sequences. Extensive experiments demonstrate that VMonarch achieves comparable or superior generation quality to full attention on VBench after minimal tuning. It overcomes the attention bottleneck in Video DiTs, reduces attention FLOPs by a factor of 17.5, and achieves a speedup of over 5x in attention computation for long videos, surpassing state-of-the-art sparse attention methods at 90% sparsity.

</details>


### [7] [Coarse-to-Real: Generative Rendering for Populated Dynamic Scenes](https://arxiv.org/abs/2601.22301)
*Gonzalo Gomez-Nogales,Yicong Hong,Chongjian Ge,Marc Comino-Trinidad,Dan Casas,Yi Zhou*

Main category: cs.CV

TL;DR: C2R is a generative rendering framework that converts coarse 3D simulations into realistic urban crowd videos using neural rendering guided by text prompts.


<details>
  <summary>Details</summary>
Motivation: Traditional rendering pipelines require complex assets, accurate materials/lighting, and substantial computational resources, yet still struggle with scalability and realism for populated dynamic scenes.

Method: Uses coarse 3D renderings to control scene layout, camera motion, and human trajectories, while a neural renderer generates realistic appearance guided by text prompts. Employs two-phase mixed CG-real training strategy to overcome lack of paired training data.

Result: Produces temporally consistent, controllable, and realistic urban scene videos from minimal 3D input, generalizes across diverse CG and game inputs, and supports coarse-to-fine control.

Conclusion: C2R enables realistic urban crowd video generation from simple 3D simulations through a novel generative rendering framework that bridges the gap between coarse control and photorealistic output.

Abstract: Traditional rendering pipelines rely on complex assets, accurate materials and lighting, and substantial computational resources to produce realistic imagery, yet they still face challenges in scalability and realism for populated dynamic scenes. We present C2R (Coarse-to-Real), a generative rendering framework that synthesizes real-style urban crowd videos from coarse 3D simulations. Our approach uses coarse 3D renderings to explicitly control scene layout, camera motion, and human trajectories, while a learned neural renderer generates realistic appearance, lighting, and fine-scale dynamics guided by text prompts. To overcome the lack of paired training data between coarse simulations and real videos, we adopt a two-phase mixed CG-real training strategy that learns a strong generative prior from large-scale real footage and introduces controllability through shared implicit spatio-temporal features across domains. The resulting system supports coarse-to-fine control, generalizes across diverse CG and game inputs, and produces temporally consistent, controllable, and realistic urban scene videos from minimal 3D input. We will release the model and project webpage at https://gonzalognogales.github.io/coarse2real/.

</details>


### [8] [FlexMap: Generalized HD Map Construction from Flexible Camera Configurations](https://arxiv.org/abs/2601.22376)
*Run Wang,Chaoyi Zhou,Amir Salarpour,Xi Liu,Zhi-Qi Cheng,Feng Luo,Mert D. Pesé,Siyu Huang*

Main category: cs.CV

TL;DR: FlexMap: A flexible HD map construction method that adapts to variable camera configurations without architectural changes or per-config retraining, using geometry-aware foundation models instead of explicit projections.


<details>
  <summary>Details</summary>
Motivation: Current HD map construction methods require fixed multi-camera setups and 2D-to-BEV transformations, making them fragile when sensors fail or camera configurations vary across vehicle fleets. There's a need for more adaptable and robust approaches.

Method: Uses geometry-aware foundation model with cross-frame attention to implicitly encode 3D scene understanding in feature space. Features spatial-temporal enhancement module separating cross-view spatial reasoning from temporal dynamics, and camera-aware decoder with latent camera tokens for view-adaptive attention without projection matrices.

Result: Outperforms existing methods across multiple camera configurations while maintaining robustness to missing views and sensor variations.

Conclusion: FlexMap enables more practical real-world deployment of HD map construction by adapting to variable camera configurations without architectural changes or retraining, using implicit 3D scene understanding instead of explicit geometric projections.

Abstract: High-definition (HD) maps provide essential semantic information of road structures for autonomous driving systems, yet current HD map construction methods require calibrated multi-camera setups and either implicit or explicit 2D-to-BEV transformations, making them fragile when sensors fail or camera configurations vary across vehicle fleets. We introduce FlexMap, unlike prior methods that are fixed to a specific N-camera rig, our approach adapts to variable camera configurations without any architectural changes or per-configuration retraining. Our key innovation eliminates explicit geometric projections by using a geometry-aware foundation model with cross-frame attention to implicitly encode 3D scene understanding in feature space. FlexMap features two core components: a spatial-temporal enhancement module that separates cross-view spatial reasoning from temporal dynamics, and a camera-aware decoder with latent camera tokens, enabling view-adaptive attention without the need for projection matrices. Experiments demonstrate that FlexMap outperforms existing methods across multiple configurations while maintaining robustness to missing views and sensor variations, enabling more practical real-world deployment.

</details>


### [9] [Jailbreaks on Vision Language Model via Multimodal Reasoning](https://arxiv.org/abs/2601.22398)
*Aarush Noheria,Yuguang Yao*

Main category: cs.CV

TL;DR: A jailbreak framework using Chain-of-Thought prompting and ReAct-driven adaptive noising to bypass VLM safety filters while maintaining naturalness.


<details>
  <summary>Details</summary>
Motivation: Vision-language models are vulnerable to prompt variations that can reveal safety alignment weaknesses, creating a need to understand and exploit these vulnerabilities.

Method: Dual-strategy approach: 1) Post-training Chain-of-Thought prompting to construct stealthy prompts, 2) ReAct-driven adaptive noising mechanism that iteratively perturbs input images based on model feedback to refine adversarial noise in sensitive regions.

Result: The proposed approach significantly improves attack success rates (ASR) while maintaining naturalness in both text and visual domains.

Conclusion: The framework successfully demonstrates how to exploit VLM vulnerabilities through combined prompt engineering and adaptive visual perturbations, highlighting security concerns in safety-aligned vision-language models.

Abstract: Vision-language models (VLMs) have become central to tasks such as visual question answering, image captioning, and text-to-image generation. However, their outputs are highly sensitive to prompt variations, which can reveal vulnerabilities in safety alignment. In this work, we present a jailbreak framework that exploits post-training Chain-of-Thought (CoT) prompting to construct stealthy prompts capable of bypassing safety filters. To further increase attack success rates (ASR), we propose a ReAct-driven adaptive noising mechanism that iteratively perturbs input images based on model feedback. This approach leverages the ReAct paradigm to refine adversarial noise in regions most likely to activate safety defenses, thereby enhancing stealth and evasion. Experimental results demonstrate that the proposed dual-strategy significantly improves ASR while maintaining naturalness in both text and visual domains.

</details>


### [10] [EMBC Special Issue: Calibrated Uncertainty for Trustworthy Clinical Gait Analysis Using Probabilistic Multiview Markerless Motion Capture](https://arxiv.org/abs/2601.22412)
*Seth Donahue,Irina Djuraskovic,Kunal Shah,Fabian Sinz,Ross Chafetz,R. James Cotton*

Main category: cs.CV

TL;DR: Probabilistic multi-view markerless motion capture produces reliable confidence intervals for gait analysis, with good calibration and accurate uncertainty quantification.


<details>
  <summary>Details</summary>
Motivation: Clinical implementation of markerless motion capture requires not just accuracy but also reliable confidence intervals to indicate how accurate the system is for individual cases, enabling trust in clinical practice.

Method: Used variational inference to estimate joint angle posterior distributions, evaluated calibration using Expected Calibration Error (ECE), analyzed data from 68 participants across two institutions, validated against instrumented walkway and marker-based motion capture.

Result: Model demonstrated reliable calibration with ECE values generally < 0.1 for step/stride length and gait kinematics, median step length error ~16mm, stride length error ~12mm, kinematic errors 1.5-3.8 degrees, predicted uncertainty strongly correlated with observed error.

Conclusion: The probabilistic model successfully quantifies epistemic uncertainty, allowing identification of unreliable outputs without ground-truth instrumentation, supporting clinical implementation of markerless motion capture systems.

Abstract: Video-based human movement analysis holds potential for movement assessment in clinical practice and research. However, the clinical implementation and trust of multi-view markerless motion capture (MMMC) require that, in addition to being accurate, these systems produce reliable confidence intervals to indicate how accurate they are for any individual. Building on our prior work utilizing variational inference to estimate joint angle posterior distributions, this study evaluates the calibration and reliability of a probabilistic MMMC method. We analyzed data from 68 participants across two institutions, validating the model against an instrumented walkway and standard marker-based motion capture. We measured the calibration of the confidence intervals using the Expected Calibration Error (ECE). The model demonstrated reliable calibration, yielding ECE values generally < 0.1 for both step and stride length and bias-corrected gait kinematics. We observed a median step and stride length error of ~16 mm and ~12 mm respectively, with median bias-corrected kinematic errors ranging from 1.5 to 3.8 degrees across lower extremity joints. Consistent with the calibrated ECE, the magnitude of the model's predicted uncertainty correlated strongly with observed error measures. These findings indicate that, as designed, the probabilistic model reconstruction quantifies epistemic uncertainty, allowing it to identify unreliable outputs without the need for concurrent ground-truth instrumentation.

</details>


### [11] [Countering the Over-Reliance Trap: Mitigating Object Hallucination for LVLMs via a Self-Validation Framework](https://arxiv.org/abs/2601.22451)
*Shiyu Liu,Xinyi Wen,Zhibin Lan,Ante Wang,Jinsong Su*

Main category: cs.CV

TL;DR: A novel training-free Self-Validation Framework that uses Language-Prior-Free Verification to mitigate object hallucination in LVLMs by validating object existence in candidate captions and selecting/aggregating the best ones.


<details>
  <summary>Details</summary>
Motivation: Object hallucination remains a critical reliability issue in Large Vision Language Models (LVLMs) for image captioning, where models generate descriptions of non-existent objects. Previous work lacks thorough analysis of LVLMs' over-reliance on language priors, which is identified as the root cause.

Method: Proposes a training-free Self-Validation Framework with Language-Prior-Free Verification. First validates object existence in sampled candidate captions, then mitigates hallucination through caption selection or aggregation. The verification method enables LVLMs to faithfully check object existence confidence without language priors.

Result: Significantly mitigates object hallucination in image captioning, achieving 65.6% improvement on CHAIRI metric with LLaVA-v1.5-7B, surpassing previous state-of-the-art methods.

Conclusion: The framework highlights a novel path toward mitigating hallucination by unlocking the inherent potential within LVLMs themselves, demonstrating that training-free approaches can effectively address the over-reliance on language priors that causes object hallucination.

Abstract: Despite progress in Large Vision Language Models (LVLMs), object hallucination remains a critical issue in image captioning task, where models generate descriptions of non-existent objects, compromising their reliability. Previous work attributes this to LVLMs' over-reliance on language priors and attempts to mitigate it through logits calibration. However, they still lack a thorough analysis of the over-reliance. To gain a deeper understanding of over-reliance, we conduct a series of preliminary experiments, indicating that as the generation length increases, LVLMs' over-reliance on language priors leads to inflated probability of hallucinated object tokens, consequently exacerbating object hallucination. To circumvent this issue, we propose Language-Prior-Free Verification to enable LVLMs to faithfully verify the confidence of object existence. Based on this, we propose a novel training-free Self-Validation Framework to counter the over-reliance trap. It first validates objects' existence in sampled candidate captions and further mitigates object hallucination via caption selection or aggregation. Experiment results demonstrate that our framework mitigates object hallucination significantly in image captioning task (e.g., 65.6% improvement on CHAIRI metric with LLaVA-v1.5-7B), surpassing the previous SOTA methods. This result highlights a novel path towards mitigating hallucination by unlocking the inherent potential within LVLMs themselves.

</details>


### [12] [ScribbleSense: Generative Scribble-Based Texture Editing with Intent Prediction](https://arxiv.org/abs/2601.22455)
*Yudi Zhang,Yeming Geng,Lei Zhang*

Main category: cs.CV

TL;DR: ScribbleSense uses MLLMs to interpret scribble-based texture editing intentions and image generation models to extract local texture details, achieving state-of-the-art performance for interactive 3D model texture editing.


<details>
  <summary>Details</summary>
Motivation: Existing 3D texture editing methods primarily support sketch-based outlining but struggle with coarse-grained scribble-based interactions due to ambiguous editing intentions and unclear target semantic locations in scribble instructions.

Method: Combines multimodal large language models (MLLMs) to predict editing intent behind scribbles, then uses globally generated images to extract local texture details, anchoring local semantics and resolving ambiguity about target locations.

Result: Experimental results show the method effectively leverages MLLMs' strengths and achieves state-of-the-art interactive editing performance for scribble-based texture editing.

Conclusion: ScribbleSense successfully addresses the challenges of scribble-based 3D texture editing by combining MLLMs for intent prediction with image generation for local detail extraction, providing an effective solution for intuitive interactive editing.

Abstract: Interactive 3D model texture editing presents enhanced opportunities for creating 3D assets, with freehand drawing style offering the most intuitive experience. However, existing methods primarily support sketch-based interactions for outlining, while the utilization of coarse-grained scribble-based interaction remains limited. Furthermore, current methodologies often encounter challenges due to the abstract nature of scribble instructions, which can result in ambiguous editing intentions and unclear target semantic locations. To address these issues, we propose ScribbleSense, an editing method that combines multimodal large language models (MLLMs) and image generation models to effectively resolve these challenges. We leverage the visual capabilities of MLLMs to predict the editing intent behind the scribbles. Once the semantic intent of the scribble is discerned, we employ globally generated images to extract local texture details, thereby anchoring local semantics and alleviating ambiguities concerning the target semantic locations. Experimental results indicate that our method effectively leverages the strengths of MLLMs, achieving state-of-the-art interactive editing performance for scribble-based texture editing.

</details>


### [13] [Training-Free Representation Guidance for Diffusion Models with a Representation Alignment Projector](https://arxiv.org/abs/2601.22468)
*Wenqiang Zu,Shenghao Xie,Bo Lei,Lei Ma*

Main category: cs.CV

TL;DR: The paper introduces a representation alignment guidance method for diffusion models that uses a projector to inject semantic features during sampling, reducing semantic drift and improving image quality without architecture changes.


<details>
  <summary>Details</summary>
Motivation: Current inference-time guidance methods like classifier-free guidance don't fully exploit unsupervised feature representations, and diffusion transformers suffer from semantic drift in early denoising stages where stochasticity causes inconsistent alignment even with identical conditioning.

Method: Proposes a guidance scheme using a representation alignment projector that injects representations predicted by the projector into intermediate sampling steps, providing semantic anchors without modifying model architecture.

Result: Significant improvements in class-conditional ImageNet synthesis with substantially lower FID scores: REPA-XL/2 improves from 5.9 to 3.3, and the method outperforms representative guidance on SiT models. Combined with classifier-free guidance yields complementary gains.

Conclusion: Representation-informed diffusion sampling is a practical strategy for reinforcing semantic preservation and image consistency, enhancing semantic coherence and visual fidelity in diffusion-based generation.

Abstract: Recent progress in generative modeling has enabled high-quality visual synthesis with diffusion-based frameworks, supporting controllable sampling and large-scale training. Inference-time guidance methods such as classifier-free and representative guidance enhance semantic alignment by modifying sampling dynamics; however, they do not fully exploit unsupervised feature representations. Although such visual representations contain rich semantic structure, their integration during generation is constrained by the absence of ground-truth reference images at inference. This work reveals semantic drift in the early denoising stages of diffusion transformers, where stochasticity results in inconsistent alignment even under identical conditioning. To mitigate this issue, we introduce a guidance scheme using a representation alignment projector that injects representations predicted by a projector into intermediate sampling steps, providing an effective semantic anchor without modifying the model architecture. Experiments on SiTs and REPAs show notable improvements in class-conditional ImageNet synthesis, achieving substantially lower FID scores; for example, REPA-XL/2 improves from 5.9 to 3.3, and the proposed method outperforms representative guidance when applied to SiT models. The approach further yields complementary gains when combined with classifier-free guidance, demonstrating enhanced semantic coherence and visual fidelity. These results establish representation-informed diffusion sampling as a practical strategy for reinforcing semantic preservation and image consistency.

</details>


### [14] [Head-Aware Visual Cropping: Enhancing Fine-Grained VQA with Attention-Guided Subimage](https://arxiv.org/abs/2601.22483)
*Junfei Xie,Peng Pan,Xulong Zhang*

Main category: cs.CV

TL;DR: HAVC improves MLLM fine-grained reasoning by selectively using attention heads to identify and crop task-relevant image regions, enhancing visual grounding without training.


<details>
  <summary>Details</summary>
Motivation: MLLMs struggle with fine-grained reasoning due to low-resolution inputs and noisy attention aggregation, limiting their visual grounding capabilities.

Method: HAVC filters attention heads via OCR diagnostics, refines them using spatial entropy and gradient sensitivity, generates a Visual Cropping Guidance Map, and crops relevant subimages for MLLM input.

Result: Outperforms state-of-the-art cropping strategies on multiple fine-grained VQA benchmarks, achieving better localization and visual grounding.

Conclusion: HAVC provides a simple, training-free method to enhance MLLM precision through selective attention head utilization and targeted image cropping.

Abstract: Multimodal Large Language Models (MLLMs) show strong performance in Visual Question Answering (VQA) but remain limited in fine-grained reasoning due to low-resolution inputs and noisy attention aggregation. We propose \textbf{Head Aware Visual Cropping (HAVC)}, a training-free method that improves visual grounding by leveraging a selectively refined subset of attention heads. HAVC first filters heads through an OCR-based diagnostic task, ensuring that only those with genuine grounding ability are retained. At inference, these heads are further refined using spatial entropy for stronger spatial concentration and gradient sensitivity for predictive contribution. The fused signals produce a reliable Visual Cropping Guidance Map, which highlights the most task-relevant region and guides the cropping of a subimage subsequently provided to the MLLM together with the image-question pair. Extensive experiments on multiple fine-grained VQA benchmarks demonstrate that HAVC consistently outperforms state-of-the-art cropping strategies, achieving more precise localization, stronger visual grounding, providing a simple yet effective strategy for enhancing precision in MLLMs.

</details>


### [15] [PromptMAD: Cross-Modal Prompting for Multi-Class Visual Anomaly Localization](https://arxiv.org/abs/2601.22492)
*Duncan McCain,Hossein Kashiani,Fatemeh Afghah*

Main category: cs.CV

TL;DR: PromptMAD: A cross-modal prompting framework for unsupervised visual anomaly detection using CLIP text prompts and semantic guidance to improve detection of subtle anomalies, achieving state-of-the-art performance on MVTec-AD.


<details>
  <summary>Details</summary>
Motivation: Visual anomaly detection in multi-class settings faces challenges including diversity of object categories, scarcity of anomalous examples, and camouflaged defects. Existing methods struggle with subtle and textural anomalies.

Method: Proposes PromptMAD framework that integrates semantic guidance through vision-language alignment using CLIP-encoded text prompts describing normal/anomalous characteristics. Uses Focal loss to address class imbalance, and a supervised segmentor with multi-scale convolutional features, Transformer-based spatial attention, and diffusion iterative refinement.

Result: Achieves state-of-the-art pixel-level performance on MVTec-AD dataset: 98.35% mean AUC and 66.54% AP, while maintaining efficiency across diverse categories.

Conclusion: PromptMAD effectively addresses multi-class visual anomaly detection challenges by integrating semantic guidance through cross-modal prompting, improving detection of subtle anomalies and achieving superior performance compared to existing methods.

Abstract: Visual anomaly detection in multi-class settings poses significant challenges due to the diversity of object categories, the scarcity of anomalous examples, and the presence of camouflaged defects. In this paper, we propose PromptMAD, a cross-modal prompting framework for unsupervised visual anomaly detection and localization that integrates semantic guidance through vision-language alignment. By leveraging CLIP-encoded text prompts describing both normal and anomalous class-specific characteristics, our method enriches visual reconstruction with semantic context, improving the detection of subtle and textural anomalies. To further address the challenge of class imbalance at the pixel level, we incorporate Focal loss function, which emphasizes hard-to-detect anomalous regions during training. Our architecture also includes a supervised segmentor that fuses multi-scale convolutional features with Transformer-based spatial attention and diffusion iterative refinement, yielding precise and high-resolution anomaly maps. Extensive experiments on the MVTec-AD dataset demonstrate that our method achieves state-of-the-art pixel-level performance, improving mean AUC to 98.35% and AP to 66.54%, while maintaining efficiency across diverse categories.

</details>


### [16] [MIRRORTALK: Forging Personalized Avatars Via Disentangled Style and Hierarchical Motion Control](https://arxiv.org/abs/2601.22501)
*Renjie Lu,Xulong Zhang,Xiaoyang Qu,Jianzong Wang,Shangfei Wang*

Main category: cs.CV

TL;DR: MirrorTalk is a diffusion-based framework for personalized talking face synthesis that disentangles speaker style from semantic content to preserve unique persona while maintaining lip-sync accuracy.


<details>
  <summary>Details</summary>
Motivation: Existing talking face synthesis methods struggle with confounding speaker-specific talking style and semantic content within facial motions, preventing faithful transfer of a speaker's unique persona to arbitrary speech.

Method: Uses conditional diffusion model with Semantically-Disentangled Style Encoder (SDSE) to distill pure style representations from reference videos, plus hierarchical modulation strategy to dynamically balance audio and style features across facial regions.

Result: Extensive experiments show MirrorTalk achieves significant improvements over state-of-the-art methods in both lip-sync accuracy and personalization preservation.

Conclusion: MirrorTalk effectively addresses the challenge of synthesizing personalized talking faces that maintain speaker identity while achieving accurate lip synchronization.

Abstract: Synthesizing personalized talking faces that uphold and highlight a speaker's unique style while maintaining lip-sync accuracy remains a significant challenge. A primary limitation of existing approaches is the intrinsic confounding of speaker-specific talking style and semantic content within facial motions, which prevents the faithful transfer of a speaker's unique persona to arbitrary speech. In this paper, we propose MirrorTalk, a generative framework based on a conditional diffusion model, combined with a Semantically-Disentangled Style Encoder (SDSE) that can distill pure style representations from a brief reference video. To effectively utilize this representation, we further introduce a hierarchical modulation strategy within the diffusion process. This mechanism guides the synthesis by dynamically balancing the contributions of audio and style features across distinct facial regions, ensuring both precise lip-sync accuracy and expressive full-face dynamics. Extensive experiments demonstrate that MirrorTalk achieves significant improvements over state-of-the-art methods in terms of lip-sync accuracy and personalization preservation.

</details>


### [17] [DreamVAR: Taming Reinforced Visual Autoregressive Model for High-Fidelity Subject-Driven Image Generation](https://arxiv.org/abs/2601.22507)
*Xin Jiang,Jingwen Chen,Yehao Li,Yingwei Pan,Kezhou Chen,Zechao Li,Ting Yao,Tao Mei*

Main category: cs.CV

TL;DR: DreamVAR is a subject-driven image generation framework using Visual Autoregressive models with next-scale prediction and reinforcement learning for better subject consistency.


<details>
  <summary>Details</summary>
Motivation: Visual Autoregressive (VAR) models have unified architecture and efficient inference but remain underexplored for subject-driven image generation compared to diffusion models.

Method: Uses VAR model with next-scale prediction, extracts multi-scale subject features with visual tokenizer, pre-fills full subject feature sequence before predicting target tokens, and incorporates reinforcement learning for semantic alignment and subject consistency.

Result: Extensive experiments show DreamVAR achieves superior appearance preservation compared to leading diffusion-based methods.

Conclusion: DreamVAR demonstrates the potential of VAR models for subject-driven image synthesis with improved subject consistency and simplified autoregressive dependencies.

Abstract: Recent advances in subject-driven image generation using diffusion models have attracted considerable attention for their remarkable capabilities in producing high-quality images. Nevertheless, the potential of Visual Autoregressive (VAR) models, despite their unified architecture and efficient inference, remains underexplored. In this work, we present DreamVAR, a novel framework for subject-driven image synthesis built upon a VAR model that employs next-scale prediction. Technically, multi-scale features of the reference subject are first extracted by a visual tokenizer. Instead of interleaving these conditional features with target image tokens across scales, our DreamVAR pre-fills the full subject feature sequence prior to predicting target image tokens. This design simplifies autoregressive dependencies and mitigates the train-test discrepancy in multi-scale conditioning scenario within the VAR paradigm. DreamVAR further incorporates reinforcement learning to jointly enhance semantic alignment and subject consistency. Extensive experiments demonstrate that DreamVAR achieves superior appearance preservation compared to leading diffusion-based methods.

</details>


### [18] [CoVA: Text-Guided Composed Video Retrieval for Audio-Visual Content](https://arxiv.org/abs/2601.22508)
*Gyuwon Han,Young Kyun Jang,Chanho Eom*

Main category: cs.CV

TL;DR: Introduces CoVA (Composed retrieval for Video with its Audio), a new task for retrieving videos using both visual and auditory modifications specified in text, along with AV-Comp benchmark and AVT Compositional Fusion method.


<details>
  <summary>Details</summary>
Motivation: Existing composed video retrieval benchmarks only consider visual changes, ignoring videos that differ in audio despite visual similarity. This limitation fails to account for real-world scenarios where both visual and auditory variations matter.

Method: Proposes AVT Compositional Fusion (AVT) which integrates video, audio, and text features by selectively aligning the textual query to the most relevant modality for effective cross-modal retrieval.

Result: AVT outperforms traditional unimodal fusion methods and serves as a strong baseline for the new CoVA task. The AV-Comp benchmark provides video pairs with cross-modal changes and corresponding textual queries.

Conclusion: The paper introduces a more comprehensive video retrieval task that accounts for both visual and auditory variations, providing a new benchmark and effective fusion method for multimodal composed video retrieval.

Abstract: Composed Video Retrieval (CoVR) aims to retrieve a target video from a large gallery using a reference video and a textual query specifying visual modifications. However, existing benchmarks consider only visual changes, ignoring videos that differ in audio despite visual similarity. To address this limitation, we introduce Composed retrieval for Video with its Audio CoVA, a new retrieval task that accounts for both visual and auditory variations. To support this, we construct AV-Comp, a benchmark consisting of video pairs with cross-modal changes and corresponding textual queries that describe the differences. We also propose AVT Compositional Fusion (AVT), which integrates video, audio, and text features by selectively aligning the query to the most relevant modality. AVT outperforms traditional unimodal fusion and serves as a strong baseline for CoVA. Examples from the proposed dataset, including both visual and auditory information, are available at https://perceptualai-lab.github.io/CoVA/.

</details>


### [19] [DNA: Uncovering Universal Latent Forgery Knowledge](https://arxiv.org/abs/2601.22515)
*Jingtong Dou,Chuancheng Shi,Yemin Wang,Shiming Guo,Anqi Yi,Wenhua Wu,Li Zhang,Fei Shen,Tat-Seng Chua*

Main category: cs.CV

TL;DR: DNA framework extracts forgery detection capabilities from pre-trained models using neural anchors instead of fine-tuning, achieving state-of-the-art performance on new high-fidelity synthetic benchmark.


<details>
  <summary>Details</summary>
Motivation: As generative AI becomes hyper-realistic, traditional artifact detection fails. Current methods require resource-intensive fine-tuning of black-box models, but the authors believe forgery detection capability is already encoded within pre-trained models and just needs to be elicited.

Method: DNA framework uses coarse-to-fine excavation: 1) analyzes feature decoupling and attention distribution to find critical layers where focus shifts from global semantics to local anomalies, 2) uses triadic fusion scoring with curvature-truncation to isolate forgery-discriminative units (FDUs), 3) introduces HIFI-Gen benchmark with latest generative models.

Result: DNA achieves superior detection performance even with few-shot learning, shows remarkable robustness across diverse architectures and against unseen generative models, validating that activating latent neurons is more effective than extensive fine-tuning.

Conclusion: Forgery detection capabilities are inherently present in pre-trained models and can be effectively elicited through the DNA framework without end-to-end retraining, offering a more efficient and robust approach than traditional fine-tuning methods.

Abstract: As generative AI achieves hyper-realism, superficial artifact detection has become obsolete. While prevailing methods rely on resource-intensive fine-tuning of black-box backbones, we propose that forgery detection capability is already encoded within pre-trained models rather than requiring end-to-end retraining. To elicit this intrinsic capability, we propose the discriminative neural anchors (DNA) framework, which employs a coarse-to-fine excavation mechanism. First, by analyzing feature decoupling and attention distribution shifts, we pinpoint critical intermediate layers where the focus of the model logically transitions from global semantics to local anomalies. Subsequently, we introduce a triadic fusion scoring metric paired with a curvature-truncation strategy to strip away semantic redundancy, precisely isolating the forgery-discriminative units (FDUs) inherently imprinted with sensitivity to forgery traces. Moreover, we introduce HIFI-Gen, a high-fidelity synthetic benchmark built upon the very latest models, to address the lag in existing datasets. Experiments demonstrate that by solely relying on these anchors, DNA achieves superior detection performance even under few-shot conditions. Furthermore, it exhibits remarkable robustness across diverse architectures and against unseen generative models, validating that waking up latent neurons is more effective than extensive fine-tuning.

</details>


### [20] [Can 3D point cloud data improve automated body condition score prediction in dairy cattle?](https://arxiv.org/abs/2601.22522)
*Zhou Tang,Jin Wang,Angelo De Castro,Yuxi Zhang,Victoria Bastos Primo,Ana Beatriz Montevecchio Bernardino,Gota Morota,Xu Wang,Ricardo C Chebel,Haipeng Yu*

Main category: cs.CV

TL;DR: Depth images outperform point clouds for dairy cattle body condition scoring, with comparable performance only when using segmented hindquarter data.


<details>
  <summary>Details</summary>
Motivation: Body condition score (BCS) is crucial for dairy cattle health and productivity, but visual scoring is subjective and labor-intensive. Computer vision offers automation, but comparisons between depth images and 3D point clouds for BCS prediction are limited.

Method: Compared top-view depth images and point clouds for BCS prediction under four settings: unsegmented raw data, segmented full-body data, segmented hindquarter data, and handcrafted feature data. Used data from 1,020 dairy cows with cow-level cross-validation to prevent data leakage.

Result: Depth image-based models consistently achieved higher accuracy than point cloud-based models with unsegmented and full-body segmented data. Comparable performance was observed with segmented hindquarter data. Both approaches showed reduced accuracy with handcrafted features. Point clouds were more sensitive to noise and model architecture.

Conclusion: Three-dimensional point clouds do not provide a consistent advantage over depth images for BCS prediction in dairy cattle under the evaluated conditions, suggesting depth images remain a more robust approach.

Abstract: Body condition score (BCS) is a widely used indicator of body energy status and is closely associated with metabolic status, reproductive performance, and health in dairy cattle; however, conventional visual scoring is subjective and labor-intensive. Computer vision approaches have been applied to BCS prediction, with depth images widely used because they capture geometric information independent of coat color and texture. More recently, three-dimensional point cloud data have attracted increasing interest due to their ability to represent richer geometric characteristics of animal morphology, but direct head-to-head comparisons with depth image-based approaches remain limited. In this study, we compared top-view depth image and point cloud data for BCS prediction under four settings: 1) unsegmented raw data, 2) segmented full-body data, 3) segmented hindquarter data, and 4) handcrafted feature data. Prediction models were evaluated using data from 1,020 dairy cows collected on a commercial farm, with cow-level cross-validation to prevent data leakage. Depth image-based models consistently achieved higher accuracy than point cloud-based models when unsegmented raw data and segmented full-body data were used, whereas comparable performance was observed when segmented hindquarter data were used. Both depth image and point cloud approaches showed reduced accuracy when handcrafted feature data were employed compared with the other settings. Overall, point cloud-based predictions were more sensitive to noise and model architecture than depth image-based predictions. Taken together, these results indicate that three-dimensional point clouds do not provide a consistent advantage over depth images for BCS prediction in dairy cattle under the evaluated conditions.

</details>


### [21] [SHED Light on Segmentation for Dense Prediction](https://arxiv.org/abs/2601.22529)
*Seung Hyun Lee,Sangwoo Mo,Stella X. Yu*

Main category: cs.CV

TL;DR: SHED is an encoder-decoder architecture that incorporates segmentation into dense prediction to enforce geometric priors, improving structural consistency without explicit segmentation supervision.


<details>
  <summary>Details</summary>
Motivation: Existing dense prediction methods treat pixels independently, leading to structural inconsistencies despite real-world scenes having strong geometric structure.

Method: SHED uses bidirectional hierarchical reasoning where segment tokens are hierarchically pooled in the encoder and unpooled in the decoder, supervised only at the final output to allow segmentation hierarchy to emerge naturally.

Result: SHED improves depth boundary sharpness, segment coherence, cross-domain generalization, 3D scene layout understanding, semantic segmentation performance, 3D reconstruction quality, and reveals interpretable part-level structures.

Conclusion: Incorporating segmentation into dense prediction through hierarchical reasoning effectively enforces geometric priors, leading to more structurally consistent predictions and better performance across multiple 3D perception tasks.

Abstract: Dense prediction infers per-pixel values from a single image and is fundamental to 3D perception and robotics. Although real-world scenes exhibit strong structure, existing methods treat it as an independent pixel-wise prediction, often resulting in structural inconsistencies. We propose SHED, a novel encoder-decoder architecture that enforces geometric prior explicitly by incorporating segmentation into dense prediction. By bidirectional hierarchical reasoning, segment tokens are hierarchically pooled in the encoder and unpooled in the decoder to reverse the hierarchy. The model is supervised only at the final output, allowing the segment hierarchy to emerge without explicit segmentation supervision. SHED improves depth boundary sharpness and segment coherence, while demonstrating strong cross-domain generalization from synthetic to the real-world environments. Its hierarchy-aware decoder better captures global 3D scene layouts, leading to improved semantic segmentation performance. Moreover, SHED enhances 3D reconstruction quality and reveals interpretable part-level structures that are often missed by conventional pixel-wise methods.

</details>


### [22] [A Comparative Evaluation of Large Vision-Language Models for 2D Object Detection under SOTIF Conditions](https://arxiv.org/abs/2601.22830)
*Ji Zhou,Yilin Ding,Yongqi Zhao,Jiachen Xu,Arno Eichberger*

Main category: cs.CV

TL;DR: LVLMs show strong recall for complex natural scenarios but lag in geometric precision compared to YOLO, suggesting complementary roles in SOTIF systems.


<details>
  <summary>Details</summary>
Motivation: Safety-critical perception under adverse conditions remains challenging for automated vehicles, with conventional detectors often failing. LVLMs show semantic reasoning potential but their quantitative effectiveness for 2D object detection in safety-critical contexts is underexplored.

Method: Systematic evaluation of ten representative LVLMs using the PeSOTIF dataset (curated for long-tail traffic scenarios and environmental degradations), with quantitative comparison against YOLO-based classical perception approach.

Result: Top-performing LVLMs (Gemini 3, Doubao) surpass YOLO baseline in recall by over 25% in complex natural scenarios with superior robustness to visual degradation, while YOLO retains advantage in geometric precision for synthetic perturbations.

Conclusion: Findings highlight complementary strengths of semantic reasoning (LVLMs) versus geometric regression (YOLO), supporting LVLMs as high-level safety validators in SOTIF-oriented automated driving systems.

Abstract: Reliable environmental perception remains one of the main obstacles for safe operation of automated vehicles. Safety of the Intended Functionality (SOTIF) concerns safety risks from perception insufficiencies, particularly under adverse conditions where conventional detectors often falter. While Large Vision-Language Models (LVLMs) demonstrate promising semantic reasoning, their quantitative effectiveness for safety-critical 2D object detection is underexplored. This paper presents a systematic evaluation of ten representative LVLMs using the PeSOTIF dataset, a benchmark specifically curated for long-tail traffic scenarios and environmental degradations. Performance is quantitatively compared against the classical perception approach, a YOLO-based detector. Experimental results reveal a critical trade-off: top-performing LVLMs (e.g., Gemini 3, Doubao) surpass the YOLO baseline in recall by over 25% in complex natural scenarios, exhibiting superior robustness to visual degradation. Conversely, the baseline retains an advantage in geometric precision for synthetic perturbations. These findings highlight the complementary strengths of semantic reasoning versus geometric regression, supporting the use of LVLMs as high-level safety validators in SOTIF-oriented automated driving systems.

</details>


### [23] [Hybrid Cross-Device Localization via Neural Metric Learning and Feature Fusion](https://arxiv.org/abs/2601.22551)
*Meixia Lin,Mingkai Liu,Shuxue Peng,Dikai Fan,Shengyu Gu,Xianliang Huang,Haoyang Ye,Xiao Liu*

Main category: cs.CV

TL;DR: Hybrid cross-device localization pipeline with retrieval encoder, geometric PnP branch, neural feed-forward branch, and neural-guided pruning achieves 92.62 score in CroCoDL 2025 Challenge.


<details>
  <summary>Details</summary>
Motivation: To develop an effective cross-device localization system for the CroCoDL 2025 Challenge that can handle diverse scenarios and improve recall and accuracy across HYDRO and SUCCU benchmarks.

Method: Hybrid pipeline with shared retrieval encoder, two complementary branches: classical geometric (feature fusion + PnP) and neural feed-forward (MapAnything), plus neural-guided candidate pruning and depth-conditioned localization refinement.

Result: Achieved final score of 92.62 (R@0.5m, 5°) in the challenge, with significant improvements in recall and accuracy across both HYDRO and SUCCU benchmarks.

Conclusion: The hybrid approach combining classical geometric methods with neural networks, enhanced by pruning and refinement strategies, provides an effective solution for cross-device localization challenges.

Abstract: We present a hybrid cross-device localization pipeline developed for the CroCoDL 2025 Challenge. Our approach integrates a shared retrieval encoder and two complementary localization branches: a classical geometric branch using feature fusion and PnP, and a neural feed-forward branch (MapAnything) for metric localization conditioned on geometric inputs. A neural-guided candidate pruning strategy further filters unreliable map frames based on translation consistency, while depth-conditioned localization refines metric scale and translation precision on Spot scenes. These components jointly lead to significant improvements in recall and accuracy across both HYDRO and SUCCU benchmarks. Our method achieved a final score of 92.62 (R@0.5m, 5°) during the challenge.

</details>


### [24] [About an Automating Annotation Method for Robot Markers](https://arxiv.org/abs/2601.22982)
*Wataru Uemura,Takeru Nagashima*

Main category: cs.CV

TL;DR: Automated annotation method for training deep-learning models on ArUco marker images using built-in marker detection to eliminate manual labeling, improving recognition performance especially under blur/defocus conditions.


<details>
  <summary>Details</summary>
Motivation: Factory automation needs robust marker recognition for mobile robots, but conventional OpenCV methods fail under noise/blur/illumination variations, and deep learning requires extensive manual annotation which is time-consuming and inconsistent.

Method: Proposes automated annotation using ArUco marker detection results (ID and position) to generate training data automatically, then trains a YOLO-based deep learning model on this dataset.

Result: The method improves recognition performance compared to conventional image processing, particularly for blurry/defocused images, while reducing human effort and ensuring consistent labeling quality.

Conclusion: Automatic annotation using built-in marker detection enables efficient deep learning training for robust marker recognition in factory automation, with future work exploring confidence threshold optimization.

Abstract: Factory automation has become increasingly important due to labor shortages, leading to the introduction of autonomous mobile robots for tasks such as material transportation. Markers are commonly used for robot self-localization and object identification. In the RoboCup Logistics League (RCLL), ArUco markers are employed both for robot localization and for identifying processing modules. Conventional recognition relies on OpenCV-based image processing, which detects black-and-white marker patterns. However, these methods often fail under noise, motion blur, defocus, or varying illumination conditions. Deep-learning-based recognition offers improved robustness under such conditions, but requires large amounts of annotated data. Annotation must typically be done manually, as the type and position of objects cannot be detected automatically, making dataset preparation a major bottleneck. In contrast, ArUco markers include built-in recognition modules that provide both ID and positional information, enabling automatic annotation. This paper proposes an automated annotation method for training deep-learning models on ArUco marker images. By leveraging marker detection results obtained from the ArUco module, the proposed approach eliminates the need for manual labeling. A YOLO-based model is trained using the automatically annotated dataset, and its performance is evaluated under various conditions. Experimental results demonstrate that the proposed method improves recognition performance compared with conventional image-processing techniques, particularly for images affected by blur or defocus. Automatic annotation also reduces human effort and ensures consistent labeling quality. Future work will investigate the relationship between confidence thresholds and recognition performance.

</details>


### [25] [Leveraging Data to Say No: Memory Augmented Plug-and-Play Selective Prediction](https://arxiv.org/abs/2601.22570)
*Aditya Sarkar,Yi Li,Jiacheng Cheng,Shlok Mishra,Nuno Vasconcelos*

Main category: cs.CV

TL;DR: MA-PaPSP improves selective prediction for vision-language models by addressing embedding instability and poor calibration through memory-augmented retrieval and contrastive normalization.


<details>
  <summary>Details</summary>
Motivation: Existing selective prediction methods focus on closed-set tasks, but vision-language foundation models need selective prediction for open-set tasks with unbounded vocabularies like image captioning. There's a need for training-free, low-complexity approaches applicable to any foundation model.

Method: Proposes MA-PaPSP (Memory-Augmented Plug-and-Play Selective Prediction) which augments PaPSP with a retrieval dataset of image-text pairs. Uses nearest-neighbor retrieval to reduce embedding variance through averaging, and applies contrastive normalization to improve score calibration.

Result: MA-PaPSP outperforms PaPSP and other selective prediction baselines across multiple datasets for selective captioning, image-text matching, and fine-grained classification tasks.

Conclusion: Memory augmentation effectively addresses the key challenges of embedding instability and poor calibration in selective prediction for vision-language models, enabling reliable training-free selective prediction across diverse tasks.

Abstract: Selective prediction aims to endow predictors with a reject option, to avoid low confidence predictions. However, existing literature has primarily focused on closed-set tasks, such as visual question answering with predefined options or fixed-category classification. This paper considers selective prediction for visual language foundation models, addressing a taxonomy of tasks ranging from closed to open set and from finite to unbounded vocabularies, as in image captioning. We seek training-free approaches of low-complexity, applicable to any foundation model and consider methods based on external vision-language model embeddings, like CLIP. This is denoted as Plug-and-Play Selective Prediction (PaPSP). We identify two key challenges: (1) instability of the visual-language representations, leading to high variance in image-text embeddings, and (2) poor calibration of similarity scores. To address these issues, we propose a memory augmented PaPSP (MA-PaPSP) model, which augments PaPSP with a retrieval dataset of image-text pairs. This is leveraged to reduce embedding variance by averaging retrieved nearest-neighbor pairs and is complemented by the use of contrastive normalization to improve score calibration. Through extensive experiments on multiple datasets, we show that MA-PaPSP outperforms PaPSP and other selective prediction baselines for selective captioning, image-text matching, and fine-grained classification. Code is publicly available at https://github.com/kingston-aditya/MA-PaPSP.

</details>


### [26] [FlowCalib: LiDAR-to-Vehicle Miscalibration Detection using Scene Flows](https://arxiv.org/abs/2601.23107)
*Ilir Tahiraj,Peter Wittal,Markus Lienkamp*

Main category: cs.CV

TL;DR: FlowCalib detects LiDAR-to-vehicle miscalibration using scene flow from static objects, combining neural flow estimation with geometric features for binary classification of misalignment presence and axis-specific errors.


<details>
  <summary>Details</summary>
Motivation: Current calibration methods focus on correcting sensor-to-sensor errors but ignore individual sensor miscalibrations that cause these errors. Angular misalignments of LiDAR sensors can lead to safety-critical issues in autonomous driving, creating a need for direct sensor-to-vehicle calibration detection.

Method: Uses motion cues from scene flow of static objects to detect rotational misalignment. Combines neural scene flow prior for flow estimation with dual-branch detection network that fuses learned global flow features with handcrafted geometric descriptors. Performs two binary classification tasks: global misalignment detection and axis-specific misalignment detection for each rotational axis.

Result: Experiments on nuScenes dataset demonstrate robust miscalibration detection capability. Establishes first benchmark for sensor-to-vehicle miscalibration detection without needing additional sensors.

Conclusion: FlowCalib provides the first framework for detecting LiDAR-to-vehicle miscalibration using scene flow, addressing a critical gap in autonomous driving safety by identifying individual sensor calibration errors that current methods overlook.

Abstract: Accurate sensor-to-vehicle calibration is essential for safe autonomous driving. Angular misalignments of LiDAR sensors can lead to safety-critical issues during autonomous operation. However, current methods primarily focus on correcting sensor-to-sensor errors without considering the miscalibration of individual sensors that cause these errors in the first place. We introduce FlowCalib, the first framework that detects LiDAR-to-vehicle miscalibration using motion cues from the scene flow of static objects. Our approach leverages the systematic bias induced by rotational misalignment in the flow field generated from sequential 3D point clouds, eliminating the need for additional sensors. The architecture integrates a neural scene flow prior for flow estimation and incorporates a dual-branch detection network that fuses learned global flow features with handcrafted geometric descriptors. These combined representations allow the system to perform two complementary binary classification tasks: a global binary decision indicating whether misalignment is present and separate, axis-specific binary decisions indicating whether each rotational axis is misaligned. Experiments on the nuScenes dataset demonstrate FlowCalib's ability to robustly detect miscalibration, establishing a benchmark for sensor-to-vehicle miscalibration detection.

</details>


### [27] [DELNet: Continuous All-in-One Weather Removal via Dynamic Expert Library](https://arxiv.org/abs/2601.22573)
*Shihong Liu,Kun Zuo,Hanguang Xiao*

Main category: cs.CV

TL;DR: DELNet is a continual learning framework for weather image restoration that uses a judging valve and dynamic expert library to handle new degradations without retraining existing models.


<details>
  <summary>Details</summary>
Motivation: Current all-in-one weather image restoration methods require pre-collected data and retraining for unseen degradations, which is costly and impractical for real-world deployment.

Method: DELNet integrates a judging valve to measure task similarity and distinguish new from known tasks, plus a dynamic expert library storing experts trained on different degradations. For new tasks, it selects top-k experts for knowledge transfer while adding new experts; for known tasks, it reuses existing experts.

Result: DELNet surpasses state-of-the-art continual learning methods on OTS, Rain100H, and Snow100K datasets, achieving PSNR gains of 16%, 11%, and 12% respectively.

Conclusion: DELNet effectively reduces retraining costs and enables practical deployment in real-world scenarios through its continual learning approach, demonstrating effectiveness, robustness, and efficiency.

Abstract: All-in-one weather image restoration methods are valuable in practice but depend on pre-collected data and require retraining for unseen degradations, leading to high cost. We propose DELNet, a continual learning framework for weather image restoration. DELNet integrates a judging valve that measures task similarity to distinguish new from known tasks, and a dynamic expert library that stores experts trained on different degradations. For new tasks, the valve selects top-k experts for knowledge transfer while adding new experts to capture task-specific features; for known tasks, the corresponding experts are directly reused. This design enables continuous optimization without retraining existing models. Experiments on OTS, Rain100H, and Snow100K demonstrate that DELNet surpasses state-of-the-art continual learning methods, achieving PSNR gains of 16\%, 11\%, and 12\%, respectively. These results highlight the effectiveness, robustness, and efficiency of DELNet, which reduces retraining cost and enables practical deployment in real-world scenarios.

</details>


### [28] [Mitigating Hallucinations in Video Large Language Models via Spatiotemporal-Semantic Contrastive Decoding](https://arxiv.org/abs/2601.22574)
*Yuansheng Gao,Jinman Zhao,Tong Zhang,Xingguo Xu,Han Bao,Zonghui Wang,Wenzhi Chen*

Main category: cs.CV

TL;DR: Spatiotemporal-Semantic Contrastive Decoding (SSCD) mitigates video hallucination in Video LLMs by constructing negative features that disrupt spatiotemporal consistency and semantic associations, then using contrastive decoding against original video features during inference.


<details>
  <summary>Details</summary>
Motivation: Video Large Language Models suffer from hallucination problems (generating outputs inconsistent with video content or factual evidence). Existing decoding methods for mitigating video hallucinations rely on heuristic designs and fail to capture root causes and fine-grained temporal/semantic correlations, leading to limited robustness and generalization in complex scenarios.

Method: Propose Spatiotemporal-Semantic Contrastive Decoding (SSCD) strategy that constructs negative features by deliberately disrupting spatiotemporal consistency and semantic associations of video features, then suppresses hallucinations through contrastive decoding against original video features during inference.

Result: Extensive experiments demonstrate the method effectively mitigates hallucination occurrence while preserving the model's general video understanding and reasoning capabilities.

Conclusion: The proposed SSCD approach provides a more effective solution for mitigating video hallucinations compared to existing heuristic methods, addressing both spatiotemporal and semantic aspects of video content.

Abstract: Although Video Large Language Models perform remarkably well across tasks such as video understanding, question answering, and reasoning, they still suffer from the problem of hallucination, which refers to generating outputs that are inconsistent with explicit video content or factual evidence. However, existing decoding methods for mitigating video hallucinations, while considering the spatiotemporal characteristics of videos, mostly rely on heuristic designs. As a result, they fail to precisely capture the root causes of hallucinations and their fine-grained temporal and semantic correlations, leading to limited robustness and generalization in complex scenarios. To more effectively mitigate video hallucinations, we propose a novel decoding strategy termed Spatiotemporal-Semantic Contrastive Decoding. This strategy constructs negative features by deliberately disrupting the spatiotemporal consistency and semantic associations of video features, and suppresses video hallucinations through contrastive decoding against the original video features during inference. Extensive experiments demonstrate that our method not only effectively mitigates the occurrence of hallucinations, but also preserves the general video understanding and reasoning capabilities of the model.

</details>


### [29] [PhoStream: Benchmarking Real-World Streaming for Omnimodal Assistants in Mobile Scenarios](https://arxiv.org/abs/2601.22575)
*Xudong Lu,Huankang Guan,Yang Bo,Jinpeng Chen,Xintong Guo,Shuhan Li,Fang Liu,Peiwen Sun,Xueying Li,Wei Zhang,Xue Yang,Rui Liu,Hongsheng Li*

Main category: cs.CV

TL;DR: PhoStream is the first mobile-centric streaming benchmark for evaluating multimodal LLMs on continuous audio-visual streams, revealing models struggle with timing decisions (when to respond) rather than content generation.


<details>
  <summary>Details</summary>
Motivation: Current multimodal LLMs excel at offline understanding but their ability to serve as mobile assistants in continuous real-world audio-visual streams remains underexplored, with existing benchmarks limited to multiple-choice questions or shorter videos.

Method: Created PhoStream benchmark with 5,572 open-ended QA pairs from 578 videos across 4 scenarios and 10 capabilities, using an Automated Generative Pipeline with human verification, and evaluated models with realistic Online Inference Pipeline and LLM-as-a-Judge scoring.

Result: Models show temporal asymmetry: perform well on Instant and Backward tasks (Gemini 3 Pro exceeds 80/100) but drop sharply on Forward tasks (16.40), largely due to early responses before required cues appear.

Conclusion: Current MLLMs have a fundamental limitation: they struggle to decide when to speak, not just what to say, highlighting the need for better temporal reasoning in streaming multimodal assistants.

Abstract: Multimodal Large Language Models excel at offline audio-visual understanding, but their ability to serve as mobile assistants in continuous real-world streams remains underexplored. In daily phone use, mobile assistants must track streaming audio-visual inputs and respond at the right time, yet existing benchmarks are often restricted to multiple-choice questions or use shorter videos. In this paper, we introduce PhoStream, the first mobile-centric streaming benchmark that unifies on-screen and off-screen scenarios to evaluate video, audio, and temporal reasoning. PhoStream contains 5,572 open-ended QA pairs from 578 videos across 4 scenarios and 10 capabilities. We build it with an Automated Generative Pipeline backed by rigorous human verification, and evaluate models using a realistic Online Inference Pipeline and LLM-as-a-Judge evaluation for open-ended responses. Experiments reveal a temporal asymmetry in LLM-judged scores (0-100): models perform well on Instant and Backward tasks (Gemini 3 Pro exceeds 80), but drop sharply on Forward tasks (16.40), largely due to early responses before the required visual and audio cues appear. This highlights a fundamental limitation: current MLLMs struggle to decide when to speak, not just what to say. Code and datasets used in this work will be made publicly accessible at https://github.com/Lucky-Lance/PhoStream.

</details>


### [30] [Cross-Domain Few-Shot Learning for Hyperspectral Image Classification Based on Mixup Foundation Model](https://arxiv.org/abs/2601.22581)
*Naeem Paeedeh,Mahardhika Pratama,Ary Shiddiqi,Zehong Cao,Mukesh Prasad,Wisnu Jatmiko*

Main category: cs.CV

TL;DR: MIFOMO is a novel cross-domain few-shot learning framework for hyperspectral image classification that leverages foundation models, mixup domain adaptation, and label smoothing to address data scarcity and domain discrepancy without external data augmentation.


<details>
  <summary>Details</summary>
Motivation: Existing CDFSL methods for HSI classification rely on unrealistic external data augmentation and have many parameters causing overfitting. No prior work has explored foundation models' generalization power for quick adaptation to downstream tasks.

Method: Proposes MIFOMO built on RS foundation model pre-trained across large-scale RS problems. Uses coalescent projection to adapt foundation model while freezing backbone, mixup domain adaptation for extreme domain discrepancy, and label smoothing for noisy pseudo-labels.

Result: MIFOMO outperforms prior arts by up to 14% margin in rigorous experiments, demonstrating significant advantage in cross-domain few-shot learning for HSI classification.

Conclusion: MIFOMO effectively addresses data scarcity and domain discrepancy in CDFSL for HSI classification by leveraging foundation models' generalization power with innovative adaptation techniques, achieving state-of-the-art performance.

Abstract: Although cross-domain few-shot learning (CDFSL) for hyper-spectral image (HSI) classification has attracted significant research interest, existing works often rely on an unrealistic data augmentation procedure in the form of external noise to enlarge the sample size, thus greatly simplifying the issue of data scarcity. They involve a large number of parameters for model updates, being prone to the overfitting problem. To the best of our knowledge, none has explored the strength of the foundation model, having strong generalization power to be quickly adapted to downstream tasks. This paper proposes the MIxup FOundation MOdel (MIFOMO) for CDFSL of HSI classifications. MIFOMO is built upon the concept of a remote sensing (RS) foundation model, pre-trained across a large scale of RS problems, thus featuring generalizable features. The notion of coalescent projection (CP) is introduced to quickly adapt the foundation model to downstream tasks while freezing the backbone network. The concept of mixup domain adaptation (MDM) is proposed to address the extreme domain discrepancy problem. Last but not least, the label smoothing concept is implemented to cope with noisy pseudo-label problems. Our rigorous experiments demonstrate the advantage of MIFOMO, where it beats prior arts with up to 14% margin. The source code of MIFOMO is open-sourced in https://github.com/Naeem- Paeedeh/MIFOMO for reproducibility and convenient further study.

</details>


### [31] [FOTBCD: A Large-Scale Building Change Detection Benchmark from French Orthophotos and Topographic Data](https://arxiv.org/abs/2601.22596)
*Abdelrrahman Moubane*

Main category: cs.CV

TL;DR: FOTBCD is a large-scale French building change detection dataset spanning 28 departments, designed to benchmark geographic domain shift generalization with 28K image pairs and instance-level annotations.


<details>
  <summary>Details</summary>
Motivation: Existing building change detection datasets are geographically constrained to single cities or limited regions, limiting evaluation of cross-domain generalization. There's a need for geographically diverse datasets to properly assess model performance under geographic domain shift.

Method: Created FOTBCD using authoritative French orthophotos and topographic building data from IGN France. Dataset spans 28 departments across mainland France with 25 for training and 3 geographically disjoint departments for evaluation. Includes both binary change masks (FOTBCD-Binary) and instance-level annotations (FOTBCD-Instances).

Result: Publicly released FOTBCD-Binary with ~28,000 before/after image pairs with pixel-wise binary building change masks, and FOTBCD-Instances with instance-level annotations. Benchmarking shows geographic diversity at dataset level improves cross-domain generalization in building change detection.

Conclusion: FOTBCD provides a geographically diverse benchmark for building change detection that enables proper evaluation of cross-domain generalization, addressing limitations of existing geographically constrained datasets.

Abstract: We introduce FOTBCD, a large-scale building change detection dataset derived from authoritative French orthophotos and topographic building data provided by IGN France. Unlike existing benchmarks that are geographically constrained to single cities or limited regions, FOTBCD spans 28 departments across mainland France, with 25 used for training and three geographically disjoint departments held out for evaluation. The dataset covers diverse urban, suburban, and rural environments at 0.2m/pixel resolution. We publicly release FOTBCD-Binary, a dataset comprising approximately 28,000 before/after image pairs with pixel-wise binary building change masks, each associated with patch-level spatial metadata. The dataset is designed for large-scale benchmarking and evaluation under geographic domain shift, with validation and test samples drawn from held-out departments and manually verified to ensure label quality. In addition, we publicly release FOTBCD-Instances, a publicly available instance-level annotated subset comprising several thousand image pairs, which illustrates the complete annotation schema used in the full instance-level version of FOTBCD. Using a fixed reference baseline, we benchmark FOTBCD-Binary against LEVIR-CD+ and WHU-CD, providing strong empirical evidence that geographic diversity at the dataset level is associated with improved cross-domain generalization in building change detection.

</details>


### [32] [TTSA3R: Training-Free Temporal-Spatial Adaptive Persistent State for Streaming 3D Reconstruction](https://arxiv.org/abs/2601.22615)
*Zhijie Zheng,Xinhao Xiang,Jiawei Zhang*

Main category: cs.CV

TL;DR: TTSA3R is a training-free framework for 3D reconstruction that addresses catastrophic memory forgetting in streaming recurrent models by using temporal state evolution patterns and spatial observation quality to determine adaptive state updates.


<details>
  <summary>Details</summary>
Motivation: Streaming recurrent models for 3D reconstruction suffer from catastrophic memory forgetting over long sequences when balancing historical information with new observations. Existing methods use adaptive signals from attention perspective but operate on single dimensions without considering temporal and spatial consistency.

Method: Proposes TTSA3R with two modules: 1) Temporal Adaptive Update Module that regulates update magnitude by analyzing temporal state evolution patterns, and 2) Spatial Contextual Update Module that localizes spatial regions needing updates through observation-state alignment and scene dynamics. These complementary signals are fused to determine state updating strategies.

Result: Extensive experiments show effectiveness in diverse 3D tasks. The method exhibits only 15% error increase compared to over 200% degradation in baseline models on extended sequences, significantly improving long-term reconstruction stability.

Conclusion: TTSA3R effectively addresses catastrophic memory forgetting in streaming 3D reconstruction by jointly considering temporal state evolution and spatial observation quality for adaptive state updates, achieving much better long-term stability than baseline approaches.

Abstract: Streaming recurrent models enable efficient 3D reconstruction by maintaining persistent state representations. However, they suffer from catastrophic memory forgetting over long sequences due to balancing historical information with new observations. Recent methods alleviate this by deriving adaptive signals from attention perspective, but they operate on single dimensions without considering temporal and spatial consistency. To this end, we propose a training-free framework termed TTSA3R that leverages both temporal state evolution and spatial observation quality for adaptive state updates in 3D reconstruction. In particular, we devise a Temporal Adaptive Update Module that regulates update magnitude by analyzing temporal state evolution patterns. Then, a Spatial Contextual Update Module is introduced to localize spatial regions that require updates through observation-state alignment and scene dynamics. These complementary signals are finally fused to determine the state updating strategies. Extensive experiments demonstrate the effectiveness of TTSA3R in diverse 3D tasks. Moreover, our method exhibits only 15% error increase compared to over 200% degradation in baseline models on extended sequences, significantly improving long-term reconstruction stability. Our codes will be available soon.

</details>


### [33] [UniGeo: A Unified 3D Indoor Object Detection Framework Integrating Geometry-Aware Learning and Dynamic Channel Gating](https://arxiv.org/abs/2601.22616)
*Xing Yi,Jinyang Huang,Feng-Qi Cui,Anyang Tong,Ruimin Wang,Liu Liu,Dan Guo*

Main category: cs.CV

TL;DR: UniGeo: A unified 3D indoor detection framework that addresses geometric relationship modeling and feature distribution in sparse point clouds through geometry-aware learning and dynamic channel gating.


<details>
  <summary>Details</summary>
Motivation: Previous 3D object detection methods fail to model geometric relationships in sparse point cloud scenes and ignore feature distribution in significant areas, limiting their performance for robotics and augmented reality applications.

Method: Proposes UniGeo with two key components: 1) Geometry-aware learning module that establishes learnable mapping from spatial relationships to feature weights for explicit geometric feature enhancement, and 2) Dynamic channel gating mechanism that uses learnable channel-wise weighting to adaptively optimize features from sparse 3D U-Net network.

Result: Extensive experiments on six different indoor scene datasets clearly validate the superior performance of the proposed method.

Conclusion: UniGeo effectively addresses the limitations of previous methods by modeling geometric relationships and enhancing feature representation in sparse point cloud scenes, demonstrating superior performance for 3D indoor object detection.

Abstract: The growing adoption of robotics and augmented reality in real-world applications has driven considerable research interest in 3D object detection based on point clouds. While previous methods address unified training across multiple datasets, they fail to model geometric relationships in sparse point cloud scenes and ignore the feature distribution in significant areas, which ultimately restricts their performance. To deal with this issue, a unified 3D indoor detection framework, called UniGeo, is proposed. To model geometric relations in scenes, we first propose a geometry-aware learning module that establishes a learnable mapping from spatial relationships to feature weights, which enabes explicit geometric feature enhancement. Then, to further enhance point cloud feature representation, we propose a dynamic channel gating mechanism that leverages learnable channel-wise weighting. This mechanism adaptively optimizes features generated by the sparse 3D U-Net network, significantly enhancing key geometric information. Extensive experiments on six different indoor scene datasets clearly validate the superior performance of our method.

</details>


### [34] [LINA: Linear Autoregressive Image Generative Models with Continuous Tokens](https://arxiv.org/abs/2601.22630)
*Jiahao Wang,Ting Pan,Haoge Deng,Dongchen Han,Taiqiang Wu,Xinlong Wang,Ping Luo*

Main category: cs.CV

TL;DR: LINA is a compute-efficient text-to-image model using linear attention with division-based normalization and KV gating, achieving competitive performance with 61% FLOPs reduction.


<details>
  <summary>Details</summary>
Motivation: Autoregressive models with continuous tokens show promise for visual generation but suffer from high computational costs. The paper aims to design compute-efficient linear attention for text-to-image synthesis by studying scaling behavior under different design choices.

Method: Systematic empirical analysis of scaling behavior with different normalization paradigms (division-based vs. subtraction-based) and depthwise convolution for locality augmentation. Extended gating mechanisms to bidirectional setting with proposed KV gate for flexible memory management. Built LINA model entirely on linear attention.

Result: Division-based normalization scales better than subtraction-based for linear generative transformers. Convolution for locality modeling is crucial for autoregressive generation. LINA achieves 2.18 FID on ImageNet (1.4B params) and 0.74 on GenEval (1.5B params) with 61% FLOPs reduction compared to softmax attention.

Conclusion: LINA demonstrates that linear attention can be both compute-efficient and effective for high-fidelity text-to-image generation, achieving competitive performance on benchmarks while significantly reducing computational costs.

Abstract: Autoregressive models with continuous tokens form a promising paradigm for visual generation, especially for text-to-image (T2I) synthesis, but they suffer from high computational cost. We study how to design compute-efficient linear attention within this framework. Specifically, we conduct a systematic empirical analysis of scaling behavior with respect to parameter counts under different design choices, focusing on (1) normalization paradigms in linear attention (division-based vs. subtraction-based) and (2) depthwise convolution for locality augmentation.
  Our results show that although subtraction-based normalization is effective for image classification, division-based normalization scales better for linear generative transformers. In addition, incorporating convolution for locality modeling plays a crucial role in autoregressive generation, consistent with findings in diffusion models.
  We further extend gating mechanisms, commonly used in causal linear attention, to the bidirectional setting and propose a KV gate. By introducing data-independent learnable parameters to the key and value states, the KV gate assigns token-wise memory weights, enabling flexible memory management similar to forget gates in language models.
  Based on these findings, we present LINA, a simple and compute-efficient T2I model built entirely on linear attention, capable of generating high-fidelity 1024x1024 images from user instructions. LINA achieves competitive performance on both class-conditional and T2I benchmarks, obtaining 2.18 FID on ImageNet (about 1.4B parameters) and 0.74 on GenEval (about 1.5B parameters). A single linear attention module reduces FLOPs by about 61 percent compared to softmax attention. Code and models are available at: https://github.com/techmonsterwang/LINA.

</details>


### [35] [What can Computer Vision learn from Ranganathan?](https://arxiv.org/abs/2601.22634)
*Mayukh Bagchi,Fausto Giunchiglia*

Main category: cs.CV

TL;DR: Using library science classification principles to address semantic gaps in computer vision datasets improves annotation quality and accuracy.


<details>
  <summary>Details</summary>
Motivation: The semantic gap problem in computer vision arises from misalignment between visual and lexical semantics, leading to flawed dataset design and benchmarks that need principled solutions.

Method: Adapting S.R. Ranganathan's classification principles from library science to create the vTelos CV annotation methodology for addressing semantic gaps.

Result: Experimental evidence shows improvements in computer vision annotation quality and accuracy, validating the vTelos methodology.

Conclusion: Ranganathan's classification principles provide a principled foundation for addressing semantic gaps in computer vision and designing higher-quality datasets through the vTelos methodology.

Abstract: The Semantic Gap Problem (SGP) in Computer Vision (CV) arises from the misalignment between visual and lexical semantics leading to flawed CV dataset design and CV benchmarks. This paper proposes that classification principles of S.R. Ranganathan can offer a principled starting point to address SGP and design high-quality CV datasets. We elucidate how these principles, suitably adapted, underpin the vTelos CV annotation methodology. The paper also briefly presents experimental evidence showing improvements in CV annotation and accuracy, thereby, validating vTelos.

</details>


### [36] [Unsupervised Synthetic Image Attribution: Alignment and Disentanglement](https://arxiv.org/abs/2601.22663)
*Zongfang Liu,Guangyi Chen,Boyang Sun,Tongliang Liu,Kun Zhang*

Main category: cs.CV

TL;DR: Unsupervised method for synthetic image attribution using alignment and disentanglement beats supervised approaches without needing paired annotations.


<details>
  <summary>Details</summary>
Motivation: Existing synthetic image attribution methods require costly paired annotations between synthetic images and training sources, which is challenging to obtain. Need for unsupervised approach to eliminate annotation requirements while maintaining attribution accuracy.

Method: Propose Alignment and Disentanglement method: 1) Basic concept alignment using contrastive self-supervised learning (MoCo/DINO), 2) Enhance attribution via representation disentanglement with Infomax loss. Theoretical foundation shows how this approximates concept-matching through canonical correlation analysis decomposition.

Result: On real-world AbC benchmarks, the unsupervised method surprisingly outperforms supervised methods, demonstrating effectiveness without paired annotations.

Conclusion: Unsupervised synthetic image attribution is feasible and can surpass supervised approaches. The alignment and disentanglement framework provides intuitive insights and a fresh perspective for this challenging task.

Abstract: As the quality of synthetic images improves, identifying the underlying concepts of model-generated images is becoming increasingly crucial for copyright protection and ensuring model transparency. Existing methods achieve this attribution goal by training models using annotated pairs of synthetic images and their original training sources. However, obtaining such paired supervision is challenging, as it requires either well-designed synthetic concepts or precise annotations from millions of training sources. To eliminate the need for costly paired annotations, in this paper, we explore the possibility of unsupervised synthetic image attribution. We propose a simple yet effective unsupervised method called Alignment and Disentanglement. Specifically, we begin by performing basic concept alignment using contrastive self-supervised learning. Next, we enhance the model's attribution ability by promoting representation disentanglement with the Infomax loss. This approach is motivated by an interesting observation: contrastive self-supervised models, such as MoCo and DINO, inherently exhibit the ability to perform simple cross-domain alignment. By formulating this observation as a theoretical assumption on cross-covariance, we provide a theoretical explanation of how alignment and disentanglement can approximate the concept-matching process through a decomposition of the canonical correlation analysis objective. On the real-world benchmarks, AbC, we show that our unsupervised method surprisingly outperforms the supervised methods. As a starting point, we expect our intuitive insights and experimental findings to provide a fresh perspective on this challenging task.

</details>


### [37] [ExpAlign: Expectation-Guided Vision-Language Alignment for Open-Vocabulary Grounding](https://arxiv.org/abs/2601.22666)
*Junyi Hu,Tian Bai,Fengyi Wu,Wenyan Li,Zhenming Peng,Yi Zhang*

Main category: cs.CV

TL;DR: ExpAlign: A lightweight vision-language alignment framework using expectation-based MIL pooling and energy-based consistency regularization for improved open-vocabulary detection and segmentation.


<details>
  <summary>Details</summary>
Motivation: Existing methods for open-vocabulary grounding either use global sentence embeddings lacking fine-grained expressiveness, or require explicit supervision/heavy cross-attention designs for token-level alignment.

Method: ExpAlign uses Expectation Alignment Head with attention-based soft MIL pooling over token-region similarities for implicit token/instance selection, plus energy-based multi-scale consistency regularization including Top-K multi-positive contrastive objective and Geometry-Aware Consistency Objective.

Result: Achieves 36.2 AP_r on LVIS minival split, outperforming SOTA methods at comparable model scale while remaining lightweight and inference-efficient; consistently improves open-vocabulary detection and zero-shot instance segmentation, especially on long-tail categories.

Conclusion: ExpAlign provides a theoretically grounded, efficient framework for vision-language alignment that enables fine-grained open-vocabulary grounding without explicit supervision or heavy computational overhead.

Abstract: Open-vocabulary grounding requires accurate vision-language alignment under weak supervision, yet existing methods either rely on global sentence embeddings that lack fine-grained expressiveness or introduce token-level alignment with explicit supervision or heavy cross-attention designs. We propose ExpAlign, a theoretically grounded vision-language alignment framework built on a principled multiple instance learning formulation. ExpAlign introduces an Expectation Alignment Head that performs attention-based soft MIL pooling over token-region similarities, enabling implicit token and instance selection without additional annotations. To further stabilize alignment learning, we develop an energy-based multi-scale consistency regularization scheme, including a Top-K multi-positive contrastive objective and a Geometry-Aware Consistency Objective derived from a Lagrangian-constrained free-energy minimization. Extensive experiments show that ExpAlign consistently improves open-vocabulary detection and zero-shot instance segmentation, particularly on long-tail categories. Most notably, it achieves 36.2 AP$_r$ on the LVIS minival split, outperforming other state-of-the-art methods at comparable model scale, while remaining lightweight and inference-efficient.

</details>


### [38] [VisionTrim: Unified Vision Token Compression for Training-Free MLLM Acceleration](https://arxiv.org/abs/2601.22674)
*Hanxun Yu,Wentong Li,Xuan Qu,Song Wang,Junbo Chen,Jianke Zhu*

Main category: cs.CV

TL;DR: VisionTrim is a training-free framework that accelerates multimodal LLMs by reducing visual tokens through two plug-and-play modules: DVTS for token selection and TGVC for text-guided token merging.


<details>
  <summary>Details</summary>
Motivation: MLLMs suffer from high computational costs due to excessive visual tokens, especially in high-resolution and video scenarios. Existing token reduction methods are isolated and neglect textual alignment, causing performance degradation.

Method: Proposes VisionTrim with two modules: 1) Dominant Vision Token Selection (DVTS) preserves essential tokens via global-local view, and 2) Text-Guided Vision Complement (TGVC) enables context-aware token merging guided by textual cues.

Result: Extensive experiments across diverse image and video multimodal benchmarks demonstrate performance superiority, advancing practical MLLM deployment in real-world applications.

Conclusion: VisionTrim provides an effective training-free framework for MLLM acceleration that maintains performance while reducing computational costs, with code publicly available.

Abstract: Multimodal large language models (MLLMs) suffer from high computational costs due to excessive visual tokens, particularly in high-resolution and video-based scenarios. Existing token reduction methods typically focus on isolated pipeline components and often neglect textual alignment, leading to performance degradation. In this paper, we propose VisionTrim, a unified framework for training-free MLLM acceleration, integrating two effective plug-and-play modules: 1) the Dominant Vision Token Selection (DVTS) module, which preserves essential visual tokens via a global-local view, and 2) the Text-Guided Vision Complement (TGVC) module, which facilitates context-aware token merging guided by textual cues. Extensive experiments across diverse image and video multimodal benchmarks demonstrate the performance superiority of our VisionTrim, advancing practical MLLM deployment in real-world applications. The code is available at: https://github.com/hanxunyu/VisionTrim.

</details>


### [39] [Fire on Motion: Optimizing Video Pass-bands for Efficient Spiking Action Recognition](https://arxiv.org/abs/2601.22675)
*Shuhan Ye,Yuanbin Qian,Yi Yu,Chong Wang,Yuqi Xie,Jiazhen Xu,Kun Wang,Xudong Jiang*

Main category: cs.CV

TL;DR: SNNs have temporal low-pass filtering that hurts video tasks; PBO optimizes pass-bands toward motion content with minimal parameters, boosting performance on dynamic vision tasks.


<details>
  <summary>Details</summary>
Motivation: SNNs underperform on dynamic video tasks compared to ANNs despite having temporal processing capabilities. The authors identify a fundamental "pass-band mismatch" where standard spiking dynamics act as temporal low-pass filters that emphasize static content while attenuating motion-bearing frequency bands crucial for video understanding.

Method: Propose Pass-Bands Optimizer (PBO), a plug-and-play module that optimizes temporal pass-bands toward task-relevant motion bands. PBO introduces only two learnable parameters and a lightweight consistency constraint to preserve semantics and boundaries. It deliberately suppresses static components and effectively high-passes the stream to concentrate spiking activity on motion content.

Result: PBO yields over 10 percentage points improvement on UCF101 action recognition. On more complex multi-modal action recognition and weakly supervised video anomaly detection, PBO delivers consistent and significant gains.

Conclusion: PBO addresses the fundamental pass-band mismatch in SNNs for video tasks, offering a new perspective for SNN-based video processing and understanding with minimal computational overhead and no architectural changes required.

Abstract: Spiking neural networks (SNNs) have gained traction in vision due to their energy efficiency, bio-plausibility, and inherent temporal processing. Yet, despite this temporal capacity, most progress concentrates on static image benchmarks, and SNNs still underperform on dynamic video tasks compared to artificial neural networks (ANNs). In this work, we diagnose a fundamental pass-band mismatch: Standard spiking dynamics behave as a temporal low pass that emphasizes static content while attenuating motion bearing bands, where task relevant information concentrates in dynamic tasks. This phenomenon explains why SNNs can approach ANNs on static tasks yet fall behind on tasks that demand richer temporal understanding.To remedy this, we propose the Pass-Bands Optimizer (PBO), a plug-and-play module that optimizes the temporal pass-band toward task-relevant motion bands. PBO introduces only two learnable parameters, and a lightweight consistency constraint that preserves semantics and boundaries, incurring negligible computational overhead and requires no architectural changes. PBO deliberately suppresses static components that contribute little to discrimination, effectively high passing the stream so that spiking activity concentrates on motion bearing content. On UCF101, PBO yields over ten percentage points improvement. On more complex multi-modal action recognition and weakly supervised video anomaly detection, PBO delivers consistent and significant gains, offering a new perspective for SNN based video processing and understanding.

</details>


### [40] [Visual Personalization Turing Test](https://arxiv.org/abs/2601.22680)
*Rameen Abdal,James Burgess,Sergey Tulyakov,Kuan-Chieh Jackson Wang*

Main category: cs.CV

TL;DR: VPTT is a new evaluation paradigm for contextual visual personalization based on perceptual indistinguishability rather than identity replication, with a framework including benchmark, retrieval-augmented generator, and calibrated metric.


<details>
  <summary>Details</summary>
Motivation: Current evaluation of visual personalization focuses too much on identity replication rather than whether generated content looks like something a person would plausibly create or share. There's a need for a more nuanced evaluation based on perceptual indistinguishability.

Method: Proposes Visual Personalization Turing Test (VPTT) paradigm with three components: 1) VPTT-Bench (10k-persona benchmark), 2) VPRAG (visual retrieval-augmented generator), and 3) VPTT Score (text-only metric calibrated against human and VLM judgments).

Result: High correlation across human, VLM, and VPTT evaluations, validating VPTT Score as reliable perceptual proxy. VPRAG achieves best alignment-originality balance, offering scalable and privacy-safe foundation for personalized generative AI.

Conclusion: VPTT provides a new evaluation paradigm for contextual visual personalization based on perceptual indistinguishability, with a practical framework that enables scalable, privacy-safe personalized generative AI with validated evaluation metrics.

Abstract: We introduce the Visual Personalization Turing Test (VPTT), a new paradigm for evaluating contextual visual personalization based on perceptual indistinguishability, rather than identity replication. A model passes the VPTT if its output (image, video, 3D asset, etc.) is indistinguishable to a human or calibrated VLM judge from content a given person might plausibly create or share. To operationalize VPTT, we present the VPTT Framework, integrating a 10k-persona benchmark (VPTT-Bench), a visual retrieval-augmented generator (VPRAG), and the VPTT Score, a text-only metric calibrated against human and VLM judgments. We show high correlation across human, VLM, and VPTT evaluations, validating the VPTT Score as a reliable perceptual proxy. Experiments demonstrate that VPRAG achieves the best alignment-originality balance, offering a scalable and privacy-safe foundation for personalized generative AI.

</details>


### [41] [OOVDet: Low-Density Prior Learning for Zero-Shot Out-of-Vocabulary Object Detection](https://arxiv.org/abs/2601.22685)
*Binyi Su,Chenghao Huang,Haiyong Chen*

Main category: cs.CV

TL;DR: OOVDet: A zero-shot out-of-vocabulary detection framework that synthesizes OOV prompts from low-likelihood regions and mines pseudo-OOV images using Dirichlet-based gradient attribution to improve OOV detection performance.


<details>
  <summary>Details</summary>
Motivation: Previous zero-shot OOV detection methods tend to overfit in-vocabulary classes, causing undefined OOV classes to be misclassified as IV classes with high confidence. There's a need for better detection of predefined classes while reliably rejecting undefined ones in zero-shot scenarios.

Method: 1) Synthesize region-level OOV prompts by sampling from low-likelihood regions of class-conditional Gaussian distributions in hidden space; 2) Propose Dirichlet-based gradient attribution mechanism to mine pseudo-OOV image samples using prediction uncertainty; 3) Construct OOV decision boundary through low-density prior constraint using Gaussian kernel density estimation.

Result: Experimental results show significant improvement in OOV detection performance in zero-shot scenes compared to previous methods.

Conclusion: OOVDet effectively addresses the overfitting problem in zero-shot OOV detection by leveraging low-density assumptions and uncertainty estimation to better distinguish between in-vocabulary and out-of-vocabulary classes.

Abstract: Zero-shot out-of-vocabulary detection (ZS-OOVD) aims to accurately recognize objects of in-vocabulary (IV) categories provided at zero-shot inference, while simultaneously rejecting undefined ones (out-of-vocabulary, OOV) that lack corresponding category prompts. However, previous methods are prone to overfitting the IV classes, leading to the OOV or undefined classes being misclassified as IV ones with a high confidence score. To address this issue, this paper proposes a zero-shot OOV detector (OOVDet), a novel framework that effectively detects predefined classes while reliably rejecting undefined ones in zero-shot scenes. Specifically, due to the model's lack of prior knowledge about the distribution of OOV data, we synthesize region-level OOV prompts by sampling from the low-likelihood regions of the class-conditional Gaussian distributions in the hidden space, motivated by the assumption that unknown semantics are more likely to emerge in low-density areas of the latent space. For OOV images, we further propose a Dirichlet-based gradient attribution mechanism to mine pseudo-OOV image samples, where the attribution gradients are interpreted as Dirichlet evidence to estimate prediction uncertainty, and samples with high uncertainty are selected as pseudo-OOV images. Building on these synthesized OOV prompts and pseudo-OOV images, we construct the OOV decision boundary through a low-density prior constraint, which regularizes the optimization of OOV classes using Gaussian kernel density estimation in accordance with the above assumption.
  Experimental results show that our method significantly improves the OOV detection performance in zero-shot scenes. The code is available at https://github.com/binyisu/OOV-detector.

</details>


### [42] [PEAR: Pixel-aligned Expressive humAn mesh Recovery](https://arxiv.org/abs/2601.22693)
*Jiahao Wu,Yunfei Liu,Lijian Lin,Ye Zhu,Lei Zhu,Jingyi Li,Yu Li*

Main category: cs.CV

TL;DR: PEAR is a fast, pixel-aligned framework for expressive human mesh recovery from single images that achieves real-time inference (100+ FPS) with improved accuracy on fine-grained details like faces and hands.


<details>
  <summary>Details</summary>
Motivation: Existing SMPLX-based methods for 3D human mesh reconstruction suffer from slow inference, produce only coarse body poses, and exhibit misalignments/artifacts in fine-grained regions (face, hands), making them difficult to apply to downstream tasks.

Method: Proposes a clean, unified ViT-based model for coarse 3D geometry recovery, adds pixel-level supervision to optimize fine-grained details, and introduces modular data annotation strategy to enrich training data and enhance robustness.

Result: Achieves over 100 FPS inference speed while substantially improving pose estimation accuracy on multiple benchmark datasets compared to previous SMPLX-based approaches.

Conclusion: PEAR provides a preprocessing-free, fast, and robust framework for expressive human mesh recovery that addresses key limitations of existing methods and enables practical downstream applications.

Abstract: Reconstructing detailed 3D human meshes from a single in-the-wild image remains a fundamental challenge in computer vision. Existing SMPLX-based methods often suffer from slow inference, produce only coarse body poses, and exhibit misalignments or unnatural artifacts in fine-grained regions such as the face and hands. These issues make current approaches difficult to apply to downstream tasks. To address these challenges, we propose PEAR-a fast and robust framework for pixel-aligned expressive human mesh recovery. PEAR explicitly tackles three major limitations of existing methods: slow inference, inaccurate localization of fine-grained human pose details, and insufficient facial expression capture. Specifically, to enable real-time SMPLX parameter inference, we depart from prior designs that rely on high resolution inputs or multi-branch architectures. Instead, we adopt a clean and unified ViT-based model capable of recovering coarse 3D human geometry. To compensate for the loss of fine-grained details caused by this simplified architecture, we introduce pixel-level supervision to optimize the geometry, significantly improving the reconstruction accuracy of fine-grained human details. To make this approach practical, we further propose a modular data annotation strategy that enriches the training data and enhances the robustness of the model. Overall, PEAR is a preprocessing-free framework that can simultaneously infer EHM-s (SMPLX and scaled-FLAME) parameters at over 100 FPS. Extensive experiments on multiple benchmark datasets demonstrate that our method achieves substantial improvements in pose estimation accuracy compared to previous SMPLX-based approaches. Project page: https://wujh2001.github.io/PEAR

</details>


### [43] [Bi-MCQ: Reformulating Vision-Language Alignment for Negation Understanding](https://arxiv.org/abs/2601.22696)
*Tae Hun Kim,Hyun Gyu Lee*

Main category: cs.CV

TL;DR: Bi-MCQ framework improves medical VLMs' negation understanding by reformulating vision-language alignment as conditional semantic comparison through bi-directional multiple-choice learning.


<details>
  <summary>Details</summary>
Motivation: Existing vision-language models (VLMs) are weak at understanding negated clinical statements due to contrastive alignment objectives that treat negation as minor linguistic variation rather than meaning-inverting operator, limiting effective learning of disease absence.

Method: Bi-directional multiple-choice learning framework (Bi-MCQ) with joint Image-to-Text and Text-to-Image MCQ tasks using affirmative, negative, and mixed prompts; includes direction-specific Cross-Attention fusion modules to handle asymmetric cues and reduce alignment interference.

Result: Improves negation understanding by up to 0.47 AUC over zero-shot SOTA CARZero; achieves up to 0.08 absolute gain on positive-negative combined evaluation; reduces affirmative-negative AUC gap by average 0.12 compared to InfoNCE-based fine-tuning.

Conclusion: Objective reformulation through conditional semantic comparison (Bi-MCQ) substantially enhances negation understanding in medical VLMs, addressing a critical limitation in clinical applications.

Abstract: Recent vision-language models (VLMs) achieve strong zero-shot performance via large-scale image-text pretraining and have been widely adopted in medical image analysis. However, existing VLMs remain notably weak at understanding negated clinical statements, largely due to contrastive alignment objectives that treat negation as a minor linguistic variation rather than a meaning-inverting operator. In multi-label settings, prompt-based InfoNCE fine-tuning further reinforces easy-positive image-prompt alignments, limiting effective learning of disease absence. To overcome these limitations, we reformulate vision-language alignment as a conditional semantic comparison problem, which is instantiated through a bi-directional multiple-choice learning framework(Bi-MCQ). By jointly training Image-to-Text and Text-to-Image MCQ tasks with affirmative, negative, and mixed prompts, our method implements fine-tuning as conditional semantic comparison instead of global similarity maximization. We further introduce direction-specific Cross-Attention fusion modules to address asymmetric cues required by bi-directional reasoning and reduce alignment interference. Experiments on ChestXray14, Open-I, CheXpert, and PadChest show that Bi-MCQ improves negation understanding by up to 0.47 AUC over the zero-shot performance of the state-of-the-art CARZero model, while achieving up to a 0.08 absolute gain on positive-negative combined (PNC) evaluation. Additionally, Bi-MCQ reduces the affirmative-negative AUC gap by an average of 0.12 compared to InfoNCE-based fine-tuning, demonstrating that objective reformulation can substantially enhance negation understanding in medical VLMs.

</details>


### [44] [DAVIS: OOD Detection via Dominant Activations and Variance for Increased Separation](https://arxiv.org/abs/2601.22703)
*Abid Hassan,Tuan Ngo,Saad Shafiq,Nenad Medvidovic*

Main category: cs.CV

TL;DR: DAVIS improves OOD detection by incorporating channel-wise variance and maximum activations from feature maps before global average pooling, addressing information loss and achieving significant performance gains across various architectures.


<details>
  <summary>Details</summary>
Motivation: Most post-hoc OOD detection methods use feature representations from global average pooling (GAP), which discards valuable distributional statistics from activation maps. These overlooked statistics (channel-wise variance and maximum activations) are highly discriminative for OOD detection but are currently ignored.

Method: DAVIS is a simple post-hoc technique that enriches feature vectors by incorporating channel-wise variance and dominant (maximum) activations from activation maps before GAP. It directly addresses the information loss from GAP and can be broadly applied to various architectures.

Result: DAVIS sets new benchmarks across diverse architectures (ResNet, DenseNet, EfficientNet, MobileNet). Achieves significant FPR95 reductions: 48.26% on CIFAR-10 (ResNet-18), 38.13% on CIFAR-100 (ResNet-34), and 26.83% on ImageNet-1k (MobileNet-v2).

Conclusion: The paper demonstrates that incorporating distributional statistics beyond the mean (specifically variance and maximum activations) provides a principled basis for improving OOD detection, moving beyond the limitations of mean-based representations from global average pooling.

Abstract: Detecting out-of-distribution (OOD) inputs is a critical safeguard for deploying machine learning models in the real world. However, most post-hoc detection methods operate on penultimate feature representations derived from global average pooling (GAP) -- a lossy operation that discards valuable distributional statistics from activation maps prior to global average pooling. We contend that these overlooked statistics, particularly channel-wise variance and dominant (maximum) activations, are highly discriminative for OOD detection. We introduce DAVIS, a simple and broadly applicable post-hoc technique that enriches feature vectors by incorporating these crucial statistics, directly addressing the information loss from GAP. Extensive evaluations show DAVIS sets a new benchmark across diverse architectures, including ResNet, DenseNet, and EfficientNet. It achieves significant reductions in the false positive rate (FPR95), with improvements of 48.26\% on CIFAR-10 using ResNet-18, 38.13\% on CIFAR-100 using ResNet-34, and 26.83\% on ImageNet-1k benchmarks using MobileNet-v2. Our analysis reveals the underlying mechanism for this improvement, providing a principled basis for moving beyond the mean in OOD detection.

</details>


### [45] [Gated Relational Alignment via Confidence-based Distillation for Efficient VLMs](https://arxiv.org/abs/2601.22709)
*Yanlong Chen,Amirhossein Habibian,Luca Benini,Yawei Li*

Main category: cs.CV

TL;DR: GRACE is a quantization-aware training framework for Vision-Language Models that unifies knowledge distillation and quantization under Information Bottleneck principle, achieving INT4 quantization with minimal accuracy loss and significant efficiency gains.


<details>
  <summary>Details</summary>
Motivation: Vision-Language Models are costly to deploy, and existing post-training quantization methods cause significant accuracy loss. Quantization-aware training for VLMs remains underexplored despite its potential for efficient deployment.

Method: GRACE unifies knowledge distillation and quantization-aware training under Information Bottleneck principle. It uses confidence-gated decoupled distillation to filter unreliable supervision, relational centered kernel alignment to transfer visual token structures, and an adaptive controller via Lagrangian relaxation to balance fidelity against capacity constraints.

Result: INT4 models consistently outperform FP16 baselines across LLaVA and Qwen families (e.g., LLaVA-1.5-7B: 70.1 vs. 66.8 on SQA; Qwen2-VL-2B: 76.9 vs. 72.6 on MMBench), nearly matching teacher performance. Achieves 3× throughput with 54% memory reduction using real INT4 kernels.

Conclusion: GRACE provides a principled framework that significantly outperforms existing quantization methods, making it a compelling solution for resource-constrained deployment of Vision-Language Models while maintaining high accuracy.

Abstract: Vision-Language Models (VLMs) achieve strong multimodal performance but are costly to deploy, and post-training quantization often causes significant accuracy loss. Despite its potential, quantization-aware training for VLMs remains underexplored. We propose GRACE, a framework unifying knowledge distillation and QAT under the Information Bottleneck principle: quantization constrains information capacity while distillation guides what to preserve within this budget. Treating the teacher as a proxy for task-relevant information, we introduce confidence-gated decoupled distillation to filter unreliable supervision, relational centered kernel alignment to transfer visual token structures, and an adaptive controller via Lagrangian relaxation to balance fidelity against capacity constraints. Across extensive benchmarks on LLaVA and Qwen families, our INT4 models consistently outperform FP16 baselines (e.g., LLaVA-1.5-7B: 70.1 vs. 66.8 on SQA; Qwen2-VL-2B: 76.9 vs. 72.6 on MMBench), nearly matching teacher performance. Using real INT4 kernel, we achieve 3$\times$ throughput with 54% memory reduction. This principled framework significantly outperforms existing quantization methods, making GRACE a compelling solution for resource-constrained deployment.

</details>


### [46] [OpenVTON-Bench: A Large-Scale High-Resolution Benchmark for Controllable Virtual Try-On Evaluation](https://arxiv.org/abs/2601.22725)
*Jin Li,Tao Chen,Shuai Jiang,Weijie Wang,Jingwen Luo,Chenhui Wu*

Main category: cs.CV

TL;DR: OpenVTON-Bench is a large-scale benchmark for Virtual Try-On evaluation with 100K high-res image pairs, addressing limitations in existing metrics and datasets through multi-modal evaluation across five dimensions.


<details>
  <summary>Details</summary>
Motivation: Current VTON evaluation suffers from unreliable metrics that can't quantify fine-grained texture details and semantic consistency, and existing datasets lack commercial-scale diversity and quality.

Method: Created OpenVTON-Bench with 100K high-resolution image pairs using DINOv3-based hierarchical clustering for balanced sampling and Gemini-powered dense captioning. Proposed multi-modal evaluation protocol with five dimensions, integrating VLM-based semantic reasoning and novel Multi-Scale Representation Metric using SAM3 segmentation and morphological erosion.

Result: The benchmark achieves strong agreement with human judgments (Kendall's τ of 0.833 vs. 0.611 for SSIM), establishing a robust evaluation standard for VTON systems.

Conclusion: OpenVTON-Bench provides a comprehensive, reliable benchmark for VTON evaluation that addresses current limitations in metrics and datasets, enabling better assessment of virtual try-on systems.

Abstract: Recent advances in diffusion models have significantly elevated the visual fidelity of Virtual Try-On (VTON) systems, yet reliable evaluation remains a persistent bottleneck. Traditional metrics struggle to quantify fine-grained texture details and semantic consistency, while existing datasets fail to meet commercial standards in scale and diversity. We present OpenVTON-Bench, a large-scale benchmark comprising approximately 100K high-resolution image pairs (up to $1536 \times 1536$). The dataset is constructed using DINOv3-based hierarchical clustering for semantically balanced sampling and Gemini-powered dense captioning, ensuring a uniform distribution across 20 fine-grained garment categories. To support reliable evaluation, we propose a multi-modal protocol that measures VTON quality along five interpretable dimensions: background consistency, identity fidelity, texture fidelity, shape plausibility, and overall realism. The protocol integrates VLM-based semantic reasoning with a novel Multi-Scale Representation Metric based on SAM3 segmentation and morphological erosion, enabling the separation of boundary alignment errors from internal texture artifacts. Experimental results show strong agreement with human judgments (Kendall's $τ$ of 0.833 vs. 0.611 for SSIM), establishing a robust benchmark for VTON evaluation.

</details>


### [47] [GaussianOcc3D: A Gaussian-Based Adaptive Multi-modal 3D Occupancy Prediction](https://arxiv.org/abs/2601.22729)
*A. Enes Doruk,Hasan F. Ates*

Main category: cs.CV

TL;DR: GaussianOcc3D: A multi-modal 3D semantic occupancy prediction framework using continuous 3D Gaussian representation to bridge camera semantics and LiDAR geometry, achieving SOTA performance with efficient memory usage.


<details>
  <summary>Details</summary>
Motivation: Single-modality methods face trade-offs between camera semantics and LiDAR geometry, while existing multi-modal frameworks struggle with modality heterogeneity, spatial misalignment, and representation crisis (voxels are computationally heavy, BEV alternatives are lossy).

Method: Four key modules: 1) LiDAR Depth Feature Aggregation (LDFA) using depth-wise deformable sampling, 2) Entropy-Based Feature Smoothing (EBFS) to mitigate domain noise, 3) Adaptive Camera-LiDAR Fusion (ACLF) with uncertainty-aware reweighting, and 4) Gauss-Mamba Head leveraging Selective State Space Models for global context with linear complexity.

Result: State-of-the-art performance on Occ3D (49.4% mIoU), SurroundOcc (28.9% mIoU), and SemanticKITTI (25.2% mIoU) benchmarks, with superior robustness across challenging rainy and nighttime conditions.

Conclusion: GaussianOcc3D effectively bridges camera and LiDAR modalities through a memory-efficient continuous 3D Gaussian representation, solving key challenges in multi-modal 3D semantic occupancy prediction while maintaining computational efficiency.

Abstract: 3D semantic occupancy prediction is a pivotal task in autonomous driving, providing a dense and fine-grained understanding of the surrounding environment, yet single-modality methods face trade-offs between camera semantics and LiDAR geometry. Existing multi-modal frameworks often struggle with modality heterogeneity, spatial misalignment, and the representation crisis--where voxels are computationally heavy and BEV alternatives are lossy. We present GaussianOcc3D, a multi-modal framework bridging camera and LiDAR through a memory-efficient, continuous 3D Gaussian representation. We introduce four modules: (1) LiDAR Depth Feature Aggregation (LDFA), using depth-wise deformable sampling to lift sparse signals onto Gaussian primitives; (2) Entropy-Based Feature Smoothing (EBFS) to mitigate domain noise; (3) Adaptive Camera-LiDAR Fusion (ACLF) with uncertainty-aware reweighting for sensor reliability; and (4) a Gauss-Mamba Head leveraging Selective State Space Models for global context with linear complexity. Evaluations on Occ3D, SurroundOcc, and SemanticKITTI benchmarks demonstrate state-of-the-art performance, achieving mIoU scores of 49.4%, 28.9%, and 25.2% respectively. GaussianOcc3D exhibits superior robustness across challenging rainy and nighttime conditions.

</details>


### [48] [ImgCoT: Compressing Long Chain of Thought into Compact Visual Tokens for Efficient Reasoning of Large Language Model](https://arxiv.org/abs/2601.22730)
*Xiaoshu Chen,Sihang Zhou,Ke Liang,Taichun Zhou,Xinwang Liu*

Main category: cs.CV

TL;DR: ImgCoT compresses CoT reasoning by replacing textual reconstruction with visual rendering, using spatial bias instead of linguistic bias to better capture reasoning structure, with a hybrid version adding key textual steps for detail preservation.


<details>
  <summary>Details</summary>
Motivation: Current autoencoder methods for compressing CoT use textual reconstruction, which forces latent tokens to preserve surface-level linguistic features rather than reasoning structure, limiting logical abstraction.

Method: Two approaches: 1) ImgCoT replaces textual CoT reconstruction with visual CoT rendering to leverage spatial inductive bias; 2) Loose ImgCoT augments visual latent tokens with selected key textual reasoning steps based on low token log-likelihood for hybrid reasoning.

Result: Extensive experiments across multiple datasets and LLMs demonstrate effectiveness of both ImgCoT versions in compressing reasoning chains while preserving structure and details.

Conclusion: Visual reconstruction provides better reasoning structure encoding than textual reconstruction, and hybrid visual-textual approach offers efficient compression with both global structure and fine-grained detail preservation.

Abstract: Compressing long chains of thought (CoT) into compact latent tokens is crucial for efficient reasoning with large language models (LLMs). Recent studies employ autoencoders to achieve this by reconstructing textual CoT from latent tokens, thus encoding CoT semantics. However, treating textual CoT as the reconstruction target forces latent tokens to preserve surface-level linguistic features (e.g., word choice and syntax), introducing a strong linguistic inductive bias that prioritizes linguistic form over reasoning structure and limits logical abstraction. Thus, we propose ImgCoT that replaces the reconstruction target from textual CoT to the visual CoT obtained by rendering CoT into images. This substitutes linguistic bias with spatial inductive bias, i.e., a tendency to model spatial layouts of the reasoning steps in visual CoT, enabling latent tokens to better capture global reasoning structure. Moreover, although visual latent tokens encode abstract reasoning structure, they may blur reasoning details. We thus propose a loose ImgCoT, a hybrid reasoning that augments visual latent tokens with a few key textual reasoning steps, selected based on low token log-likelihood. This design allows LLMs to retain both global reasoning structure and fine-grained reasoning details with fewer tokens than the complete CoT. Extensive experiments across multiple datasets and LLMs demonstrate the effectiveness of the two versions of ImgCoT.

</details>


### [49] [Lingua-SafetyBench: A Benchmark for Safety Evaluation of Multilingual Vision-Language Models](https://arxiv.org/abs/2601.22737)
*Enyi Shi,Pengyang Shao,Yanxin Zhang,Chenhang Cui,Jiayi Lyu,Xu Xie,Xiaobo Xia,Fei Shen,Tat-Seng Chua*

Main category: cs.CV

TL;DR: Lingua-SafetyBench is a multilingual multimodal safety benchmark with 100k+ harmful image-text pairs across 10 languages, revealing language-modality safety asymmetries in VLLMs.


<details>
  <summary>Details</summary>
Motivation: Existing safety benchmarks are either multilingual but text-only, or multimodal but monolingual, lacking coverage of realistic cross-modal interactions in multilingual multimodal settings. Current multilingual multimodal red-teaming relies heavily on typography-style visuals without semantically grounded image-text pairs.

Method: Created Lingua-SafetyBench with 100,440 harmful image-text pairs across 10 languages, explicitly partitioned into image-dominant and text-dominant subsets to disentangle risk sources. Evaluated 11 open-source VLLMs and conducted controlled studies on Qwen series models.

Result: Revealed consistent asymmetry: image-dominant risks yield higher Attack Success Rate (ASR) in high-resource languages, while text-dominant risks are more severe in non-high-resource languages. Scaling and version upgrades reduce ASR overall but disproportionately benefit high-resource languages, widening the safety gap for non-high-resource languages under text-dominant risks.

Conclusion: Highlights the necessity of language- and modality-aware safety alignment beyond mere scaling. The benchmark, model checkpoints, and source code will be publicly released to facilitate reproducibility and future research.

Abstract: Robust safety of vision-language large models (VLLMs) under joint multilingual and multimodal inputs remains underexplored. Existing benchmarks are typically multilingual but text-only, or multimodal but monolingual. Recent multilingual multimodal red-teaming efforts render harmful prompts into images, yet rely heavily on typography-style visuals and lack semantically grounded image-text pairs, limiting coverage of realistic cross-modal interactions. We introduce Lingua-SafetyBench, a benchmark of 100,440 harmful image-text pairs across 10 languages, explicitly partitioned into image-dominant and text-dominant subsets to disentangle risk sources. Evaluating 11 open-source VLLMs reveals a consistent asymmetry: image-dominant risks yield higher ASR in high-resource languages, while text-dominant risks are more severe in non-high-resource languages. A controlled study on the Qwen series shows that scaling and version upgrades reduce Attack Success Rate (ASR) overall but disproportionately benefit HRLs, widening the gap between HRLs and Non-HRLs under text-dominant risks. This underscores the necessity of language- and modality-aware safety alignment beyond mere scaling.To facilitate reproducibility and future research, we will publicly release our benchmark, model checkpoints, and source code.The code and dataset will be available at https://github.com/zsxr15/Lingua-SafetyBench.Warning: this paper contains examples with unsafe content.

</details>


### [50] [StreamSense: Streaming Social Task Detection with Selective Vision-Language Model Routing](https://arxiv.org/abs/2601.22738)
*Han Wang,Deyi Ji,Lanyun Zhu,Jiebo Luo,Roy Ka-Wei Lee*

Main category: cs.CV

TL;DR: StreamSense is a streaming detector that uses a lightweight encoder for most timestamps and selectively routes hard cases to a Vision-Language Model, achieving higher accuracy with lower latency than VLM-only approaches.


<details>
  <summary>Details</summary>
Motivation: Live streaming platforms need real-time monitoring of social signals using partial, asynchronous evidence from multiple modalities (video, text, audio), requiring efficient and accurate detection systems.

Method: Combines lightweight streaming encoder with selective routing to VLM expert; uses cross-modal contrastive training for alignment and IoU-weighted loss to mitigate label interference across segment boundaries.

Result: Achieves higher accuracy than VLM-only streaming while only occasionally invoking the VLM, reducing average latency and compute on social streaming detection tasks like sentiment classification and hate content moderation.

Conclusion: Selective escalation and deferral are effective primitives for streaming social tasks, enabling efficient real-time monitoring with improved accuracy and reduced computational cost.

Abstract: Live streaming platforms require real-time monitoring and reaction to social signals, utilizing partial and asynchronous evidence from video, text, and audio. We propose StreamSense, a streaming detector that couples a lightweight streaming encoder with selective routing to a Vision-Language Model (VLM) expert. StreamSense handles most timestamps with the lightweight streaming encoder, escalates hard/ambiguous cases to the VLM, and defers decisions when context is insufficient. The encoder is trained using (i) a cross-modal contrastive term to align visual/audio cues with textual signals, and (ii) an IoU-weighted loss that down-weights poorly overlapping target segments, mitigating label interference across segment boundaries. We evaluate StreamSense on multiple social streaming detection tasks (e.g., sentiment classification and hate content moderation), and the results show that StreamSense achieves higher accuracy than VLM-only streaming while only occasionally invoking the VLM, thereby reducing average latency and compute. Our results indicate that selective escalation and deferral are effective primitives for understanding streaming social tasks. Code is publicly available on GitHub.

</details>


### [51] [Beauty and the Beast: Imperceptible Perturbations Against Diffusion-Based Face Swapping via Directional Attribute Editing](https://arxiv.org/abs/2601.22744)
*Yilong Huang,Songze Li*

Main category: cs.CV

TL;DR: FaceDefense: Enhanced proactive defense against diffusion-based face swapping using diffusion loss and facial attribute editing for better imperceptibility and protection.


<details>
  <summary>Details</summary>
Motivation: Diffusion-based face swapping achieves SOTA performance but exacerbates malicious use (portraiture rights violation, reputation damage). Existing proactive defense methods face trade-off: large perturbations distort faces, small ones weaken protection.

Method: Introduces diffusion loss to strengthen adversarial examples' defensive efficacy, uses directional facial attribute editing to restore perturbation-induced distortions, and employs two-phase alternating optimization to generate final perturbed face images.

Result: Extensive experiments show FaceDefense significantly outperforms existing methods in both imperceptibility and defense effectiveness, achieving superior trade-off.

Conclusion: FaceDefense provides enhanced proactive defense framework that addresses the core trade-off in existing methods, offering better protection against malicious diffusion-based face swapping while maintaining visual quality.

Abstract: Diffusion-based face swapping achieves state-of-the-art performance, yet it also exacerbates the potential harm of malicious face swapping to violate portraiture right or undermine personal reputation. This has spurred the development of proactive defense methods. However, existing approaches face a core trade-off: large perturbations distort facial structures, while small ones weaken protection effectiveness. To address these issues, we propose FaceDefense, an enhanced proactive defense framework against diffusion-based face swapping. Our method introduces a new diffusion loss to strengthen the defensive efficacy of adversarial examples, and employs a directional facial attribute editing to restore perturbation-induced distortions, thereby enhancing visual imperceptibility. A two-phase alternating optimization strategy is designed to generate final perturbed face images. Extensive experiments show that FaceDefense significantly outperforms existing methods in both imperceptibility and defense effectiveness, achieving a superior trade-off.

</details>


### [52] [Procedural Knowledge Extraction from Industrial Troubleshooting Guides Using Vision Language Models](https://arxiv.org/abs/2601.22754)
*Guillermo Gil de Avalle,Laura Maruster,Christos Emmanouilidis*

Main category: cs.CV

TL;DR: VLMs can automate extraction of structured knowledge from troubleshooting flowcharts, with trade-offs between layout sensitivity and semantic robustness depending on prompting strategies.


<details>
  <summary>Details</summary>
Motivation: Manual extraction of diagnostic procedures from troubleshooting flowcharts is labor-intensive and error-prone, but necessary for integrating this knowledge into operator support systems. VLMs offer potential for automation but their performance on such guides is underexplored.

Method: Evaluated two Vision Language Models on extracting structured knowledge from troubleshooting guides, comparing two prompting strategies: standard instruction-guided prompting versus an augmented approach that cues troubleshooting layout patterns.

Result: Results reveal model-specific trade-offs between layout sensitivity and semantic robustness, with different models performing better under different prompting strategies.

Conclusion: The findings inform practical deployment decisions for using VLMs to automate extraction of structured knowledge from troubleshooting guides, highlighting the importance of choosing appropriate models and prompting strategies based on specific needs.

Abstract: Industrial troubleshooting guides encode diagnostic procedures in flowchart-like diagrams where spatial layout and technical language jointly convey meaning. To integrate this knowledge into operator support systems, which assist shop-floor personnel in diagnosing and resolving equipment issues, the information must first be extracted and structured for machine interpretation. However, when performed manually, this extraction is labor-intensive and error-prone. Vision Language Models offer potential to automate this process by jointly interpreting visual and textual meaning, yet their performance on such guides remains underexplored. This paper evaluates two VLMs on extracting structured knowledge, comparing two prompting strategies: standard instruction-guided versus an augmented approach that cues troubleshooting layout patterns. Results reveal model-specific trade-offs between layout sensitivity and semantic robustness, informing practical deployment decisions.

</details>


### [53] [Is Training Necessary for Anomaly Detection?](https://arxiv.org/abs/2601.22763)
*Xingwu Zhang,Guanxuan Li,Paul Henderson,Gerardo Aragon-Camarasa,Zijun Long*

Main category: cs.CV

TL;DR: RAD introduces a training-free, retrieval-based approach for multi-class unsupervised anomaly detection that outperforms reconstruction-based methods by storing anomaly-free features in memory and using multi-level retrieval for detection.


<details>
  <summary>Details</summary>
Motivation: Current state-of-the-art MUAD methods rely on encoder-decoder reconstruction models, which suffer from a fidelity-stability dilemma in detecting anomalies via reconstruction residuals. The authors aim to overcome this limitation by abandoning the reconstruction paradigm entirely.

Method: RAD is a training-free approach that stores anomaly-free features in a memory bank and detects anomalies through multi-level retrieval, matching test patches against the stored memory rather than reconstructing them.

Result: RAD achieves state-of-the-art performance across four benchmarks (MVTec-AD, VisA, Real-IAD, 3D-ADAM) under standard and few-shot settings. On MVTec-AD, it reaches 96.7% Pixel AUROC with just one anomaly-free image, approaching 98.5% full-data performance.

Conclusion: The findings overturn the assumption that MUAD requires task-specific training, demonstrating that state-of-the-art anomaly detection is feasible with memory-based retrieval, and proving that retrieval-based scores theoretically upper-bound reconstruction-residual scores.

Abstract: Current state-of-the-art multi-class unsupervised anomaly detection (MUAD) methods rely on training encoder-decoder models to reconstruct anomaly-free features. We first show these approaches have an inherent fidelity-stability dilemma in how they detect anomalies via reconstruction residuals. We then abandon the reconstruction paradigm entirely and propose Retrieval-based Anomaly Detection (RAD). RAD is a training-free approach that stores anomaly-free features in a memory and detects anomalies through multi-level retrieval, matching test patches against the memory. Experiments demonstrate that RAD achieves state-of-the-art performance across four established benchmarks (MVTec-AD, VisA, Real-IAD, 3D-ADAM) under both standard and few-shot settings. On MVTec-AD, RAD reaches 96.7\% Pixel AUROC with just a single anomaly-free image compared to 98.5\% of RAD's full-data performance. We further prove that retrieval-based scores theoretically upper-bound reconstruction-residual scores. Collectively, these findings overturn the assumption that MUAD requires task-specific training, showing that state-of-the-art anomaly detection is feasible with memory-based retrieval. Our code is available at https://github.com/longkukuhi/RAD.

</details>


### [54] [Color Matters: Demosaicing-Guided Color Correlation Training for Generalizable AI-Generated Image Detection](https://arxiv.org/abs/2601.22778)
*Nan Zhong,Yiran Xu,Mian Zou*

Main category: cs.CV

TL;DR: DCCT framework uses camera imaging pipeline properties (CFA/demosaicing color correlations) to detect AI-generated images via self-supervised U-Net modeling, achieving SOTA generalization across unseen generators.


<details>
  <summary>Details</summary>
Motivation: Address generalization failure of existing AI-generated image detectors by exploiting intrinsic camera imaging pipeline properties rather than relying on transient generative artifacts that quickly become obsolete.

Method: Demosaicing-guided Color Correlation Training (DCCT): simulates CFA sampling to decompose images into single-channel input and remaining channels as targets, trains self-supervised U-Net with mixture of logistic parameterization to model conditional distribution of missing channels.

Result: Achieves state-of-the-art generalization and robustness, significantly outperforming prior methods across over 20 unseen generators, with theoretical analysis showing provable distributional differences in color-correlation features.

Conclusion: Exploiting intrinsic camera imaging pipeline properties (CFA/demosaicing color correlations) provides a robust foundation for AI-generated image detection that generalizes well across diverse unseen generators.

Abstract: As realistic AI-generated images threaten digital authenticity, we address the generalization failure of generative artifact-based detectors by exploiting the intrinsic properties of the camera imaging pipeline. Concretely, we investigate color correlations induced by the color filter array (CFA) and demosaicing, and propose a Demosaicing-guided Color Correlation Training (DCCT) framework for AI-generated image detection. By simulating the CFA sampling pattern, we decompose each color image into a single-channel input (as the condition) and the remaining two channels as the ground-truth targets (for prediction). A self-supervised U-Net is trained to model the conditional distribution of the missing channels from the given one, parameterized via a mixture of logistic functions. Our theoretical analysis reveals that DCCT targets a provable distributional difference in color-correlation features between photographic and AI-generated images. By leveraging these distinct features to construct a binary classifier, DCCT achieves state-of-the-art generalization and robustness, significantly outperforming prior methods across over 20 unseen generators.

</details>


### [55] [Diachronic Stereo Matching for Multi-Date Satellite Imagery](https://arxiv.org/abs/2601.22808)
*Elías Masquil,Luca Savant Aira,Roger Marí,Thibaud Ehret,Pablo Musé,Gabriele Facciolo*

Main category: cs.CV

TL;DR: First diachronic stereo matching method for satellite imagery that enables 3D reconstruction from temporally distant image pairs with seasonal/illumination changes.


<details>
  <summary>Details</summary>
Motivation: Existing stereo pipelines fail when satellite images are captured months apart due to seasonal, illumination, and shadow changes that violate standard stereoscopic assumptions. Multi-date NeRF/Gaussian-splatting approaches work with many observations, but classical stereo fails with temporally distant pairs.

Method: Fine-tune state-of-the-art deep stereo network (MonSter) that leverages monocular depth priors on a curated dataset of diachronic image pairs from DFC2019 remote sensing challenge. The approach combines monocular depth priors with stereo matching adapted to temporal variations.

Result: Method consistently surpasses classical pipelines and unadapted deep stereo models on both synchronic and diachronic settings. Achieves 1.23m mean altitude error vs 3.99m for zero-shot methods on winter-autumn pairs, demonstrating accurate geometry recovery despite strong appearance changes.

Conclusion: Fine-tuning on temporally diverse images with monocular priors enables 3D reconstruction from previously incompatible acquisition dates, bridging the gap between multi-date and classical stereo approaches for satellite imagery.

Abstract: Recent advances in image-based satellite 3D reconstruction have progressed along two complementary directions. On one hand, multi-date approaches using NeRF or Gaussian-splatting jointly model appearance and geometry across many acquisitions, achieving accurate reconstructions on opportunistic imagery with numerous observations. On the other hand, classical stereoscopic reconstruction pipelines deliver robust and scalable results for simultaneous or quasi-simultaneous image pairs. However, when the two images are captured months apart, strong seasonal, illumination, and shadow changes violate standard stereoscopic assumptions, causing existing pipelines to fail. This work presents the first Diachronic Stereo Matching method for satellite imagery, enabling reliable 3D reconstruction from temporally distant pairs. Two advances make this possible: (1) fine-tuning a state-of-the-art deep stereo network that leverages monocular depth priors, and (2) exposing it to a dataset specifically curated to include a diverse set of diachronic image pairs. In particular, we start from a pretrained MonSter model, trained initially on a mix of synthetic and real datasets such as SceneFlow and KITTI, and fine-tune it on a set of stereo pairs derived from the DFC2019 remote sensing challenge. This dataset contains both synchronic and diachronic pairs under diverse seasonal and illumination conditions. Experiments on multi-date WorldView-3 imagery demonstrate that our approach consistently surpasses classical pipelines and unadapted deep stereo models on both synchronic and diachronic settings. Fine-tuning on temporally diverse images, together with monocular priors, proves essential for enabling 3D reconstruction from previously incompatible acquisition dates. Left image (winter) Right image (autumn) DSM geometry Ours (1.23 m) Zero-shot (3.99 m) LiDAR GT Figure 1. Output geometry for a winter-autumn image pair from Omaha (OMA 331 test scene). Our method recovers accurate geometry despite the diachronic nature of the pair, exhibiting strong appearance changes, which cause existing zero-shot methods to fail. Missing values due to perspective shown in black.  Mean altitude error in parentheses; lower is better.

</details>


### [56] [FarmMind: Reasoning-Query-Driven Dynamic Segmentation for Farmland Remote Sensing Images](https://arxiv.org/abs/2601.22809)
*Haiyang Wu,Weiliang Mu,Jipeng Zhang,Zhong Dandan,Zhuofei Du,Haifeng Li,Tao Chao*

Main category: cs.CV

TL;DR: FarmMind introduces a dynamic segmentation framework for farmland remote sensing images that uses reasoning-query mechanisms to actively request auxiliary images when segmentation ambiguity occurs, mimicking human expert behavior.


<details>
  <summary>Details</summary>
Motivation: Existing static segmentation methods for farmland remote sensing images rely only on limited information from single input patches, making them inadequate for complex scenes with ambiguity and visual uncertainty. Human experts actively query auxiliary images for cross-verification in such cases.

Method: FarmMind introduces a reasoning-query-driven dynamic segmentation framework that analyzes root causes of segmentation ambiguities through reasoning, then determines what type of auxiliary image (higher-resolution, larger-scale, or temporally adjacent data) needs to be queried to compensate for insufficient information.

Result: Extensive experiments demonstrate that FarmMind achieves superior segmentation performance and stronger generalization ability compared with existing methods.

Conclusion: The proposed framework breaks through limitations of static segmentation paradigms by simulating human expert thinking processes when faced with segmentation ambiguity, enabling more comprehensive reasoning through dynamic, on-demand queries of external auxiliary images.

Abstract: Existing methods for farmland remote sensing image (FRSI) segmentation generally follow a static segmentation paradigm, where analysis relies solely on the limited information contained within a single input patch. Consequently, their reasoning capability is limited when dealing with complex scenes characterized by ambiguity and visual uncertainty. In contrast, human experts, when interpreting remote sensing images in such ambiguous cases, tend to actively query auxiliary images (such as higher-resolution, larger-scale, or temporally adjacent data) to conduct cross-verification and achieve more comprehensive reasoning. Inspired by this, we propose a reasoning-query-driven dynamic segmentation framework for FRSIs, named FarmMind. This framework breaks through the limitations of the static segmentation paradigm by introducing a reasoning-query mechanism, which dynamically and on-demand queries external auxiliary images to compensate for the insufficient information in a single input image. Unlike direct queries, this mechanism simulates the thinking process of human experts when faced with segmentation ambiguity: it first analyzes the root causes of segmentation ambiguities through reasoning, and then determines what type of auxiliary image needs to be queried based on this analysis. Extensive experiments demonstrate that FarmMind achieves superior segmentation performance and stronger generalization ability compared with existing methods. The source code and dataset used in this work are publicly available at: https://github.com/WithoutOcean/FarmMind.

</details>


### [57] [NativeTok: Native Visual Tokenization for Improved Image Generation](https://arxiv.org/abs/2601.22837)
*Bin Wu,Mengqi Huang,Weinan Jia,Zhendong Mao*

Main category: cs.CV

TL;DR: NativeTok is a VQ-based image generation framework that introduces native visual tokenization to enforce causal dependencies during tokenization, improving coherence by embedding relational constraints within token sequences.


<details>
  <summary>Details</summary>
Motivation: Current VQ-based image generation suffers from a mismatch between tokenization and generation stages - improved tokenization doesn't necessarily enhance generation because existing methods fail to constrain token dependencies, forcing generative models to learn from unordered distributions leading to bias and weak coherence.

Method: Proposes NativeTok framework with native visual tokenization that enforces causal dependencies. Consists of: (1) Meta Image Transformer (MIT) for latent image modeling, and (2) Mixture of Causal Expert Transformer (MoCET) where each lightweight expert block generates a single token conditioned on prior tokens and latent features. Uses Hierarchical Native Training strategy that updates only new expert blocks for efficiency.

Result: Extensive experiments demonstrate the effectiveness of NativeTok in achieving efficient reconstruction while embedding relational constraints within token sequences.

Conclusion: Native visual tokenization with enforced causal dependencies addresses the mismatch between tokenization and generation stages in VQ-based image generation, improving coherence and reducing bias through relational constraints in token sequences.

Abstract: VQ-based image generation typically follows a two-stage pipeline: a tokenizer encodes images into discrete tokens, and a generative model learns their dependencies for reconstruction. However, improved tokenization in the first stage does not necessarily enhance the second-stage generation, as existing methods fail to constrain token dependencies. This mismatch forces the generative model to learn from unordered distributions, leading to bias and weak coherence. To address this, we propose native visual tokenization, which enforces causal dependencies during tokenization. Building on this idea, we introduce NativeTok, a framework that achieves efficient reconstruction while embedding relational constraints within token sequences. NativeTok consists of: (1) a Meta Image Transformer (MIT) for latent image modeling, and (2) a Mixture of Causal Expert Transformer (MoCET), where each lightweight expert block generates a single token conditioned on prior tokens and latent features. We further design a Hierarchical Native Training strategy that updates only new expert blocks, ensuring training efficiency. Extensive experiments demonstrate the effectiveness of NativeTok.

</details>


### [58] [Neural Clothing Tryer: Customized Virtual Try-On via Semantic Enhancement and Controlling Diffusion Model](https://arxiv.org/abs/2601.22838)
*Zhijing Yang,Weiwei Zhang,Mingliang Yang,Siyuan Peng,Yukai Shi,Junpeng Tan,Tianshui Chen,Liruo Zhong*

Main category: cs.CV

TL;DR: NCT framework enables customized virtual try-on with flexible editing of model appearance, posture, and attributes using diffusion models with semantic enhancement.


<details>
  <summary>Details</summary>
Motivation: To enhance virtual fitting experience by enabling users to customize digital avatars with individual preferences in appearance, posture, and attributes, going beyond traditional VTON limitations.

Method: Neural Clothing Tryer (NCT) framework uses diffusion models with semantic enhancement and controlling modules. Includes semantic-enhanced module with visual-language encoder for aligned cross-modal features, and semantic controlling module for maintaining garment details while editing model attributes.

Result: Extensive experiments on open benchmarks demonstrate superior performance of NCT framework compared to existing methods.

Conclusion: NCT successfully addresses the novel Customized VTON task, providing flexible avatar customization while preserving garment semantics and details through advanced diffusion model techniques.

Abstract: This work aims to address a novel Customized Virtual Try-ON (Cu-VTON) task, enabling the superimposition of a specified garment onto a model that can be customized in terms of appearance, posture, and additional attributes. Compared with traditional VTON task, it enables users to tailor digital avatars to their individual preferences, thereby enhancing the virtual fitting experience with greater flexibility and engagement. To address this task, we introduce a Neural Clothing Tryer (NCT) framework, which exploits the advanced diffusion models equipped with semantic enhancement and controlling modules to better preserve semantic characterization and textural details of the garment and meanwhile facilitating the flexible editing of the model's postures and appearances. Specifically, NCT introduces a semantic-enhanced module to take semantic descriptions of garments and utilizes a visual-language encoder to learn aligned features across modalities. The aligned features are served as condition input to the diffusion model to enhance the preservation of the garment's semantics. Then, a semantic controlling module is designed to take the garment image, tailored posture image, and semantic description as input to maintain garment details while simultaneously editing model postures, expressions, and various attributes. Extensive experiments on the open available benchmark demonstrate the superior performance of the proposed NCT framework.

</details>


### [59] [How Much of a Model Do We Need? Redundancy and Slimmability in Remote Sensing Foundation Models](https://arxiv.org/abs/2601.22841)
*Leonard Hackel,Tom Burgert,Begüm Demir*

Main category: cs.CV

TL;DR: RS foundation models become overparameterized much earlier than CV models, maintaining high accuracy even when drastically slimmed down due to redundant representations.


<details>
  <summary>Details</summary>
Motivation: To challenge the direct transfer of scaling assumptions from computer vision to remote sensing, hypothesizing that RS models become overparameterized at much smaller scales with redundant representations.

Method: Used post-hoc slimming (uniformly reducing pretrained encoder width) to measure representational redundancy across six state-of-the-art RS FMs on four classification tasks, plus learned slimmable training and feature analysis.

Result: RS FMs maintain over 71% relative accuracy at 1% FLOPs vs. CV MAE's <10%, showing 7x difference. Learned slimmable training improves both MoCo- and MAE-based models.

Conclusion: Post-hoc slimmability serves as both practical deployment strategy for resource-constrained environments and diagnostic tool challenging RS scaling paradigms, with RS FMs distributing task information with high redundancy.

Abstract: Large-scale foundation models (FMs) in remote sensing (RS) are developed based on the paradigms established in computer vision (CV) and have shown promise for various Earth observation applications. However, the direct transfer of scaling assumptions from CV to RS has not been adequately examined. We hypothesize that RS FMs enter an overparameterized regime at substantially smaller scales than their CV counterparts, where increasing parameter count primarily induces redundant representations rather than qualitatively new abstractions. To test this hypothesis, we use post-hoc slimming, where we uniformly reduce the width of pretrained encoder, as a tool to measure representational redundancy across six state-of-the-art RS FMs on four downstream classification tasks. Our findings reveal a significant contrast with those in the CV domain: while a post-hoc slimmed masked autoencoder (MAE) trained on ImageNet retains less than 10% accuracy at 1% FLOPs, RS FMs maintain over 71% relative accuracy at the same budget. This sevenfold difference provides strong empirical support for our hypothesis. We further demonstrate that learned slimmable training can improve both Momentum Contrast (MoCo)- and MAE- based models. In addition, through the explained variance ratio and the feature correlation analysis, we provide mechanistic explanations showing that RS FMs distribute task-relevant information with high redundancy. Our findings establish post-hoc slimmability as both a practical deployment strategy for resource-constrained environments and a diagnostic tool that challenges the prevailing scaling paradigm in RS. Upon acceptance, we will publish all code.

</details>


### [60] [Inference-Time Dynamic Modality Selection for Incomplete Multimodal Classification](https://arxiv.org/abs/2601.22853)
*Siyi Du,Xinzhe Luo,Declan P. O'Regan,Chen Qin*

Main category: cs.CV

TL;DR: DyMo is a dynamic modality selection framework that adaptively chooses reliable recovered modalities at inference time to overcome the discarding-imputation dilemma in incomplete multimodal deep learning.


<details>
  <summary>Details</summary>
Motivation: Existing incomplete MDL methods face a fundamental dilemma: discarding missing modalities loses valuable task-relevant information, while imputing them risks introducing irrelevant noise. This discarding-imputation dilemma hinders practical deployment of multimodal systems.

Method: DyMo uses a novel inference-time dynamic modality selection algorithm that maximizes multimodal task-relevant information. It establishes a theoretical connection between information and task loss, creates a principled reward function for selection, and employs a flexible network architecture compatible with arbitrary modality combinations with tailored training.

Result: Extensive experiments on diverse natural and medical image datasets show DyMo significantly outperforms state-of-the-art incomplete/dynamic MDL methods across various missing-data scenarios.

Conclusion: DyMo successfully addresses the discarding-imputation dilemma by adaptively selecting reliable recovered modalities at inference time, enabling more effective utilization of multimodal information in incomplete data scenarios.

Abstract: Multimodal deep learning (MDL) has achieved remarkable success across various domains, yet its practical deployment is often hindered by incomplete multimodal data. Existing incomplete MDL methods either discard missing modalities, risking the loss of valuable task-relevant information, or recover them, potentially introducing irrelevant noise, leading to the discarding-imputation dilemma. To address this dilemma, in this paper, we propose DyMo, a new inference-time dynamic modality selection framework that adaptively identifies and integrates reliable recovered modalities, fully exploring task-relevant information beyond the conventional discard-or-impute paradigm. Central to DyMo is a novel selection algorithm that maximizes multimodal task-relevant information for each test sample. Since direct estimation of such information at test time is intractable due to the unknown data distribution, we theoretically establish a connection between information and the task loss, which we compute at inference time as a tractable proxy. Building on this, a novel principled reward function is proposed to guide modality selection. In addition, we design a flexible multimodal network architecture compatible with arbitrary modality combinations, alongside a tailored training strategy for robust representation learning. Extensive experiments on diverse natural and medical image datasets show that DyMo significantly outperforms state-of-the-art incomplete/dynamic MDL methods across various missing-data scenarios. Our code is available at https://github.com//siyi-wind/DyMo.

</details>


### [61] [Under-Canopy Terrain Reconstruction in Dense Forests Using RGB Imaging and Neural 3D Reconstruction](https://arxiv.org/abs/2601.22861)
*Refael Sheffer,Chen Pinchover,Haim Zisman,Dror Ozeri,Roee Litman*

Main category: cs.CV

TL;DR: NeRF-based method using conventional RGB images to reconstruct canopy-free ground views for forest applications like search/rescue and inventory, without specialized sensors.


<details>
  <summary>Details</summary>
Motivation: Existing solutions for mapping terrain under dense forest canopies require specialized, expensive sensors like airborne LiDAR or thermal AOS. There's a need for cost-effective alternatives using conventional RGB cameras for applications like search/rescue, trail mapping, and forest inventory.

Method: Uses Neural Radiance Fields (NeRF) with RGB images only. Includes specific image capture considerations for proper illumination under canopy. Employs low light loss to handle poorly lit understory. Proposes two complementary approaches to remove occluding canopy elements by controlling per-ray integration.

Result: Enables person detection for search/rescue with promising results compared to thermal AOS. Shows potential for forest inventory tasks like tree counting. Provides cost-effective, high-resolution alternative to specialized sensors.

Conclusion: The approach offers a practical, cost-effective solution for various forest applications using only conventional RGB cameras, positioning it as a viable alternative to expensive specialized sensors for SAR, trail mapping, and forest inventory.

Abstract: Mapping the terrain and understory hidden beneath dense forest canopies is of great interest for numerous applications such as search and rescue, trail mapping, forest inventory tasks, and more. Existing solutions rely on specialized sensors: either heavy, costly airborne LiDAR, or Airborne Optical Sectioning (AOS), which uses thermal synthetic aperture photography and is tailored for person detection.
  We introduce a novel approach for the reconstruction of canopy-free, photorealistic ground views using only conventional RGB images. Our solution is based on the celebrated Neural Radiance Fields (NeRF), a recent 3D reconstruction method. Additionally, we include specific image capture considerations, which dictate the needed illumination to successfully expose the scene beneath the canopy. To better cope with the poorly lit understory, we employ a low light loss. Finally, we propose two complementary approaches to remove occluding canopy elements by controlling per-ray integration procedure.
  To validate the value of our approach, we present two possible downstream tasks. For the task of search and rescue (SAR), we demonstrate that our method enables person detection which achieves promising results compared to thermal AOS (using only RGB images). Additionally, we show the potential of our approach for forest inventory tasks like tree counting. These results position our approach as a cost-effective, high-resolution alternative to specialized sensors for SAR, trail mapping, and forest-inventory tasks.

</details>


### [62] [When Anomalies Depend on Context: Learning Conditional Compatibility for Anomaly Detection](https://arxiv.org/abs/2601.22868)
*Shashank Mishra,Didier Stricker,Jason Rambach*

Main category: cs.CV

TL;DR: The paper introduces contextual anomaly detection in vision, where abnormality depends on subject-context compatibility rather than intrinsic appearance, and proposes a benchmark (CAAD-3K) and conditional compatibility learning framework.


<details>
  <summary>Details</summary>
Motivation: Traditional anomaly detection assumes abnormality is intrinsic to observations, but this breaks down in real-world settings where the same object/action can be normal or anomalous depending on context (e.g., running on track vs highway).

Method: Proposes a conditional compatibility learning framework that leverages vision-language representations to model subject-context relationships under limited supervision, and introduces CAAD-3K benchmark to isolate contextual anomalies by controlling subject identity while varying context.

Result: The method substantially outperforms existing approaches on CAAD-3K and achieves state-of-the-art performance on MVTec-AD and VisA, demonstrating that modeling context dependence complements traditional structural anomaly detection.

Conclusion: Contextual anomaly detection is important for real-world applications, and modeling subject-context compatibility using vision-language representations effectively addresses this problem, complementing traditional structural anomaly detection approaches.

Abstract: Anomaly detection is often formulated under the assumption that abnormality is an intrinsic property of an observation, independent of context. This assumption breaks down in many real-world settings, where the same object or action may be normal or anomalous depending on latent contextual factors (e.g., running on a track versus on a highway). We revisit \emph{contextual anomaly detection}, classically defined as context-dependent abnormality, and operationalize it in the visual domain, where anomaly labels depend on subject--context compatibility rather than intrinsic appearance. To enable systematic study of this setting, we introduce CAAD-3K, a benchmark that isolates contextual anomalies by controlling subject identity while varying context. We further propose a conditional compatibility learning framework that leverages vision--language representations to model subject--context relationships under limited supervision. Our method substantially outperforms existing approaches on CAAD-3K and achieves state-of-the-art performance on MVTec-AD and VisA, demonstrating that modeling context dependence complements traditional structural anomaly detection. Our code and dataset will be publicly released.

</details>


### [63] [DINO-SAE: DINO Spherical Autoencoder for High-Fidelity Image Reconstruction and Generation](https://arxiv.org/abs/2601.22904)
*Hun Chang,Byunghee Cha,Jong Chul Ye*

Main category: cs.CV

TL;DR: DINO-SAE is a generative autoencoder framework that bridges semantic representation from pretrained vision foundation models with pixel-level reconstruction by using hierarchical convolutional patch embedding and cosine similarity alignment, achieving state-of-the-art reconstruction quality on ImageNet-1K.


<details>
  <summary>Details</summary>
Motivation: Existing approaches using pretrained Vision Foundation Models (VFMs) like DINO for generative autoencoders often suffer from limited reconstruction fidelity due to loss of high-frequency details, as they force strict magnitude matching which hinders preservation of fine-grained details.

Method: Proposes DINO Spherical Autoencoder (DINO-SAE) with: 1) Hierarchical Convolutional Patch Embedding module to enhance local structure and texture preservation, 2) Cosine Similarity Alignment objective that enforces semantic consistency while allowing flexible feature magnitudes, and 3) Riemannian Flow Matching to train a Diffusion Transformer (DiT) directly on the spherical latent manifold of SSL-based foundation model representations.

Result: Achieves state-of-the-art reconstruction quality on ImageNet-1K with 0.37 rFID and 26.2 dB PSNR, while maintaining strong semantic alignment to the pretrained VFM. The Riemannian Flow Matching-based DiT exhibits efficient convergence, achieving a gFID of 3.47 at 80 epochs.

Conclusion: DINO-SAE successfully bridges semantic representation from pretrained vision foundation models with high-fidelity pixel-level reconstruction by leveraging the spherical nature of SSL representations and allowing flexible feature magnitude matching, achieving superior reconstruction quality and efficient training convergence.

Abstract: Recent studies have explored using pretrained Vision Foundation Models (VFMs) such as DINO for generative autoencoders, showing strong generative performance. Unfortunately, existing approaches often suffer from limited reconstruction fidelity due to the loss of high-frequency details. In this work, we present the DINO Spherical Autoencoder (DINO-SAE), a framework that bridges semantic representation and pixel-level reconstruction. Our key insight is that semantic information in contrastive representations is primarily encoded in the direction of feature vectors, while forcing strict magnitude matching can hinder the encoder from preserving fine-grained details. To address this, we introduce Hierarchical Convolutional Patch Embedding module that enhances local structure and texture preservation, and Cosine Similarity Alignment objective that enforces semantic consistency while allowing flexible feature magnitudes for detail retention. Furthermore, leveraging the observation that SSL-based foundation model representations intrinsically lie on a hypersphere, we employ Riemannian Flow Matching to train a Diffusion Transformer (DiT) directly on this spherical latent manifold. Experiments on ImageNet-1K demonstrate that our approach achieves state-of-the-art reconstruction quality, reaching 0.37 rFID and 26.2 dB PSNR, while maintaining strong semantic alignment to the pretrained VFM. Notably, our Riemannian Flow Matching-based DiT exhibits efficient convergence, achieving a gFID of 3.47 at 80 epochs.

</details>


### [64] [Multi-Cue Anomaly Detection and Localization under Data Contamination](https://arxiv.org/abs/2601.22913)
*Anindya Sundar Das,Monowar Bhuyan*

Main category: cs.CV

TL;DR: A robust anomaly detection framework that integrates limited anomaly supervision with adaptive deviation learning, using a composite scoring mechanism for improved detection and localization under data contamination.


<details>
  <summary>Details</summary>
Motivation: Real-world industrial anomaly detection faces two key limitations: 1) existing methods assume clean normal training data (no contamination), which is rarely satisfied in practice, and 2) they lack access to labeled anomaly samples, preventing discriminative learning of true anomalies. This leads to poor detection and localization performance when training data contains anomalies.

Method: Proposes a robust anomaly detection framework that integrates limited anomaly supervision into adaptive deviation learning. Uses a composite anomaly score combining three components: deviation score (statistical irregularity), entropy-based uncertainty score (predictive inconsistency), and segmentation-based score (spatial abnormality). Incorporates a small set of labeled anomalies during training while mitigating contaminated samples through adaptive instance weighting.

Result: Extensive experiments on MVTec and VisA benchmarks show the framework outperforms state-of-the-art baselines, achieving strong detection and localization performance, interpretability, and robustness under various levels of data contamination.

Conclusion: The proposed framework effectively addresses real-world industrial anomaly detection challenges by combining limited anomaly supervision with adaptive learning, providing reliable performance even when training data contains anomalies, and offering explainable visual evidence through gradient-based localization.

Abstract: Visual anomaly detection in real-world industrial settings faces two major limitations. First, most existing methods are trained on purely normal data or on unlabeled datasets assumed to be predominantly normal, presuming the absence of contamination, an assumption that is rarely satisfied in practice. Second, they assume no access to labeled anomaly samples, limiting the model from learning discriminative characteristics of true anomalies. Therefore, these approaches often struggle to distinguish anomalies from normal instances, resulting in reduced detection and weak localization performance. In real-world applications, where training data are frequently contaminated with anomalies, such methods fail to deliver reliable performance. In this work, we propose a robust anomaly detection framework that integrates limited anomaly supervision into the adaptive deviation learning paradigm. We introduce a composite anomaly score that combines three complementary components: a deviation score capturing statistical irregularity, an entropy-based uncertainty score reflecting predictive inconsistency, and a segmentation-based score highlighting spatial abnormality. This unified scoring mechanism enables accurate detection and supports gradient-based localization, providing intuitive and explainable visual evidence of anomalous regions. Following the few-anomaly paradigm, we incorporate a small set of labeled anomalies during training while simultaneously mitigating the influence of contaminated samples through adaptive instance weighting. Extensive experiments on the MVTec and VisA benchmarks demonstrate that our framework outperforms state-of-the-art baselines and achieves strong detection and localization performance, interpretability, and robustness under various levels of data contamination.

</details>


### [65] [Deep in the Jungle: Towards Automating Chimpanzee Population Estimation](https://arxiv.org/abs/2601.22917)
*Tom Raynes,Otto Brookes,Timm Haucke,Lukas Bösch,Anne-Sophie Crunchant,Hjalmar Kühl,Sara Beery,Majid Mirmehdi,Tilo Burghardt*

Main category: cs.CV

TL;DR: Computer vision-based monocular depth estimation can automate distance measurements for great ape population surveys, achieving results within 22% of manual methods despite systematic biases.


<details>
  <summary>Details</summary>
Motivation: Manual distance measurement from camera trap videos is labor-intensive, creating a need for automated alternatives to estimate animal-to-camera distances for population density calculations.

Method: Combined two MDE models (DPT and Depth Anything) with multiple distance sampling strategies on 220 chimpanzee camera trap videos, comparing automated distance estimates against manual ground-truth measurements.

Result: Calibrated DPT outperformed Depth Anything in distance estimation accuracy and downstream population inference, though both models showed systematic overestimation of distances leading to underestimation of density and abundance.

Conclusion: MDE-driven camera trap distance sampling is a viable practical alternative to manual methods, producing population estimates within 22% of traditional approaches, with animal detection failures being the primary accuracy limitation.

Abstract: The estimation of abundance and density in unmarked populations of great apes relies on statistical frameworks that require animal-to-camera distance measurements. In practice, acquiring these distances depends on labour-intensive manual interpretation of animal observations across large camera trap video corpora. This study introduces and evaluates an only sparsely explored alternative: the integration of computer vision-based monocular depth estimation (MDE) pipelines directly into ecological camera trap workflows for great ape conservation. Using a real-world dataset of 220 camera trap videos documenting a wild chimpanzee population, we combine two MDE models, Dense Prediction Transformers and Depth Anything, with multiple distance sampling strategies. These components are used to generate detection distance estimates, from which population density and abundance are inferred. Comparative analysis against manually derived ground-truth distances shows that calibrated DPT consistently outperforms Depth Anything. This advantage is observed in both distance estimation accuracy and downstream density and abundance inference. Nevertheless, both models exhibit systematic biases. We show that, given complex forest environments, they tend to overestimate detection distances and consequently underestimate density and abundance relative to conventional manual approaches. We further find that failures in animal detection across distance ranges are a primary factor limiting estimation accuracy. Overall, this work provides a case study that shows MDE-driven camera trap distance sampling is a viable and practical alternative to manual distance estimation. The proposed approach yields population estimates within 22% of those obtained using traditional methods.

</details>


### [66] [Q-Hawkeye: Reliable Visual Policy Optimization for Image Quality Assessment](https://arxiv.org/abs/2601.22920)
*Wulin Xie,Rui Dai,Ruidong Ding,Kaikui Liu,Xiangxiang Chu,Xinwen Hou,Jie Wen*

Main category: cs.CV

TL;DR: Q-Hawkeye is an RL-based IQA framework that addresses reliability limitations through uncertainty-aware optimization and perception-aware constraints, outperforming SOTA methods.


<details>
  <summary>Details</summary>
Motivation: Existing RL-based IQA methods have two key reliability limitations: (1) uniform advantage weighting amplifies noisy signals from unstable samples, and (2) overemphasis on text-grounded reasoning while overlooking visual perception ability for image content.

Method: Proposes Q-Hawkeye with two components: Uncertainty-Aware Dynamic Optimization (estimates predictive uncertainty via score variance across rollouts to reweight sample updates) and Perception-Aware Optimization (uses paired degraded/original images with Implicit Perception Loss to ground quality judgments in visual evidence).

Result: Extensive experiments show Q-Hawkeye outperforms state-of-the-art methods and generalizes better across multiple datasets.

Conclusion: Q-Hawkeye provides a more reliable RL-based IQA framework by addressing both uncertainty handling and visual perception limitations, with code and models to be released.

Abstract: Image Quality Assessment (IQA) predicts perceptual quality scores consistent with human judgments. Recent RL-based IQA methods built on MLLMs focus on generating visual quality descriptions and scores, ignoring two key reliability limitations: (i) although the model's prediction stability varies significantly across training samples, existing GRPO-based methods apply uniform advantage weighting, thereby amplifying noisy signals from unstable samples in gradient updates; (ii) most works emphasize text-grounded reasoning over images while overlooking the model's visual perception ability of image content. In this paper, we propose Q-Hawkeye, an RL-based reliable visual policy optimization framework that redesigns the learning signal through unified Uncertainty-Aware Dynamic Optimization and Perception-Aware Optimization. Q-Hawkeye estimates predictive uncertainty using the variance of predicted scores across multiple rollouts and leverages this uncertainty to reweight each sample's update strength, stabilizing policy optimization. To strengthen perceptual reliability, we construct paired inputs of degraded images and their original images and introduce an Implicit Perception Loss that constrains the model to ground its quality judgments in genuine visual evidence. Extensive experiments demonstrate that Q-Hawkeye outperforms state-of-the-art methods and generalizes better across multiple datasets. The code and models will be made available.

</details>


### [67] [Semantic Leakage from Image Embeddings](https://arxiv.org/abs/2601.22929)
*Yiyi Chen,Qiongkai Xu,Desmond Eliott,Qiongxiu Li,Johannes Bjerva*

Main category: cs.CV

TL;DR: SLImE framework reveals semantic information from compressed image embeddings by exploiting preserved neighborhood structures, challenging assumptions about embedding privacy.


<details>
  <summary>Details</summary>
Motivation: Challenge the assumption that image embeddings pose limited privacy risk by showing semantic leakage can occur even without exact image reconstruction.

Method: Propose SLImE - Semantic Leakage from Image Embeddings framework using locally trained semantic retriever with off-the-shelf models, without task-specific decoders.

Result: Consistent recovery of semantic information across diverse inference tasks for various embedding models (GEMINI, COHERE, NOMIC, CLIP), validating semantic leakage vulnerability.

Conclusion: Reveals fundamental vulnerability in image embeddings where preservation of semantic neighborhoods enables semantic leakage, highlighting privacy preservation challenges.

Abstract: Image embeddings are generally assumed to pose limited privacy risk. We challenge this assumption by formalizing semantic leakage as the ability to recover semantic structures from compressed image embeddings. Surprisingly, we show that semantic leakage does not require exact reconstruction of the original image. Preserving local semantic neighborhoods under embedding alignment is sufficient to expose the intrinsic vulnerability of image embeddings. Crucially, this preserved neighborhood structure allows semantic information to propagate through a sequence of lossy mappings. Based on this conjecture, we propose Semantic Leakage from Image Embeddings (SLImE), a lightweight inference framework that reveals semantic information from standalone compressed image embeddings, incorporating a locally trained semantic retriever with off-the-shelf models, without training task-specific decoders. We thoroughly validate each step of the framework empirically, from aligned embeddings to retrieved tags, symbolic representations, and grammatical and coherent descriptions. We evaluate SLImE across a range of open and closed embedding models, including GEMINI, COHERE, NOMIC, and CLIP, and demonstrate consistent recovery of semantic information across diverse inference tasks. Our results reveal a fundamental vulnerability in image embeddings, whereby the preservation of semantic neighborhoods under alignment enables semantic leakage, highlighting challenges for privacy preservation.1

</details>


### [68] [Triage: Hierarchical Visual Budgeting for Efficient Video Reasoning in Vision-Language Models](https://arxiv.org/abs/2601.22959)
*Anmin Wang,Nan Zhang,Wei Tao,Xiaoyang Qu,Guokuan Li,Jiguang Wan,Jianzong Wang*

Main category: cs.CV

TL;DR: Triage is a training-free framework that improves video processing efficiency for Vision-Language Models by treating video reasoning as a resource allocation problem with hierarchical visual budgeting.


<details>
  <summary>Details</summary>
Motivation: VLMs face computational challenges in video processing due to massive data redundancy and prohibitively long token sequences, which slow down inference and increase memory usage.

Method: Two-stage hierarchical visual budgeting: 1) Frame-Level Budgeting identifies keyframes based on visual dynamics and relevance, 2) Token-Level Budgeting allocates tokens in two phases (Core Tokens for high-relevance content, Context Tokens selected via batched Maximal Marginal Relevance algorithm).

Result: Extensive experiments show Triage improves inference speed, reduces memory footprint, and maintains or surpasses baseline performance on various video reasoning benchmarks.

Conclusion: Triage provides an effective training-free, plug-and-play solution for efficient video processing in VLMs by reframing video reasoning as a resource allocation problem with hierarchical visual budgeting.

Abstract: Vision-Language Models (VLMs) face significant computational challenges in video processing due to massive data redundancy, which creates prohibitively long token sequences. To address this, we introduce Triage, a training-free, plug-and-play framework that reframes video reasoning as a resource allocation problem via hierarchical visual budgeting. Its first stage, Frame-Level Budgeting, identifies keyframes by evaluating their visual dynamics and relevance, generating a strategic prior based on their importance scores. Guided by this prior, the second stage, Token-Level Budgeting, allocates tokens in two phases: it first secures high-relevance Core Tokens, followed by diverse Context Tokens selected with an efficient batched Maximal Marginal Relevance (MMR) algorithm. Extensive experiments demonstrate that Triage improves inference speed and reduces memory footprint, while maintaining or surpassing the performance of baselines and other methods on various video reasoning benchmarks.

</details>


### [69] [Improving Supervised Machine Learning Performance in Optical Quality Control via Generative AI for Dataset Expansion](https://arxiv.org/abs/2601.22961)
*Dennis Sprute,Hanna Senke,Holger Flatt*

Main category: cs.CV

TL;DR: Using generative AI (Stable Diffusion and CycleGAN) to expand imbalanced thermal image datasets for combine harvester defect detection improves segmentation performance by 4.6%.


<details>
  <summary>Details</summary>
Motivation: Industrial optical quality control suffers from imbalanced datasets where defective parts are rare, limiting supervised ML model performance. Traditional solutions like specialized loss functions or basic data augmentation have limitations in hyperparameter tuning and feature alteration.

Method: Explored generative AI (Stable Diffusion and CycleGAN) as alternative data augmentation methods for thermal images of combine harvester components, focusing on segmentation for subsequent defect detection.

Result: Dataset expansion using Stable Diffusion yielded the most significant improvement, enhancing segmentation performance by 4.6% with Mean IoU of 84.6%.

Conclusion: Generative AI, particularly Stable Diffusion, is an effective alternative for expanding limited datasets in industrial quality control, overcoming limitations of traditional methods and improving supervised ML performance for rare defect detection.

Abstract: Supervised machine learning algorithms play a crucial role in optical quality control within industrial production. These approaches require representative datasets for effective model training. However, while non-defective components are frequent, defective parts are rare in production, resulting in highly imbalanced datasets that adversely impact model performance. Existing strategies to address this challenge, such as specialized loss functions or traditional data augmentation techniques, have limitations, including the need for careful hyperparameter tuning or the alteration of only simple image features. Therefore, this work explores the potential of generative artificial intelligence (GenAI) as an alternative method for expanding limited datasets and enhancing supervised machine learning performance. Specifically, we investigate Stable Diffusion and CycleGAN as image generation models, focusing on the segmentation of combine harvester components in thermal images for subsequent defect detection. Our results demonstrate that dataset expansion using Stable Diffusion yields the most significant improvement, enhancing segmentation performance by 4.6 %, resulting in a Mean Intersection over Union (Mean IoU) of 84.6 %.

</details>


### [70] [Self-Supervised Slice-to-Volume Reconstruction with Gaussian Representations for Fetal MRI](https://arxiv.org/abs/2601.22990)
*Yinsong Wang,Thomas Fletcher,Xinzhe Luo,Aine Travers Dineen,Rhodri Cusack,Chen Qin*

Main category: cs.CV

TL;DR: GaussianSVR: Self-supervised 3D fetal MRI reconstruction using 3D Gaussian representations, eliminating need for ground truth volumes through simulated acquisition model and multi-resolution training.


<details>
  <summary>Details</summary>
Motivation: Conventional slice-to-volume reconstruction (SVR) for fetal MRI is time-consuming and requires multiple orthogonal stacks. Learning-based SVR methods need ground truth volumes for training, which are inaccessible in practice.

Method: Uses 3D Gaussian representations for target volume, simulated forward slice acquisition model for self-supervised training (no ground truth needed), and multi-resolution training strategy to jointly optimize Gaussian parameters and spatial transformations.

Result: Outperforms baseline methods on fetal MR volumetric reconstruction, achieving high-fidelity reconstruction with improved accuracy and efficiency.

Conclusion: GaussianSVR provides an effective self-supervised framework for fetal MRI reconstruction that eliminates dependency on ground truth data while maintaining high reconstruction quality.

Abstract: Reconstructing 3D fetal MR volumes from motion-corrupted stacks of 2D slices is a crucial and challenging task. Conventional slice-to-volume reconstruction (SVR) methods are time-consuming and require multiple orthogonal stacks for reconstruction. While learning-based SVR approaches have significantly reduced the time required at the inference stage, they heavily rely on ground truth information for training, which is inaccessible in practice. To address these challenges, we propose GaussianSVR, a self-supervised framework for slice-to-volume reconstruction. GaussianSVR represents the target volume using 3D Gaussian representations to achieve high-fidelity reconstruction. It leverages a simulated forward slice acquisition model to enable self-supervised training, alleviating the need for ground-truth volumes. Furthermore, to enhance both accuracy and efficiency, we introduce a multi-resolution training strategy that jointly optimizes Gaussian parameters and spatial transformations across different resolution levels. Experiments show that GaussianSVR outperforms the baseline methods on fetal MR volumetric reconstruction. Code will be available upon acceptance.

</details>


### [71] [Leveraging Multi-Rater Annotations to Calibrate Object Detectors in Microscopy Imaging](https://arxiv.org/abs/2601.23007)
*Francesco Campi,Lucrezia Tondo,Ekin Karabati,Johannes Betge,Marie Piraud*

Main category: cs.CV

TL;DR: Multi-rater ensemble approach improves calibration of deep learning object detectors in biomedical imaging by training separate models on individual expert annotations and aggregating predictions.


<details>
  <summary>Details</summary>
Motivation: Deep learning object detectors in microscopy imaging often have poorly calibrated confidence estimates, limiting their reliability for biomedical applications where trustworthiness is crucial.

Method: Train separate models on annotations from single experts, then aggregate their predictions to emulate consensus, capturing inter-rater variability more effectively than label sampling strategies that mix annotations.

Result: Experiments on colorectal organoid dataset annotated by two experts show the rater-specific ensemble strategy improves calibration performance while maintaining comparable detection accuracy.

Conclusion: Explicitly modeling rater disagreement leads to more trustworthy object detectors in biomedical imaging by improving confidence calibration.

Abstract: Deep learning-based object detectors have achieved impressive performance in microscopy imaging, yet their confidence estimates often lack calibration, limiting their reliability for biomedical applications. In this work, we introduce a new approach to improve model calibration by leveraging multi-rater annotations. We propose to train separate models on the annotations from single experts and aggregate their predictions to emulate consensus. This improves upon label sampling strategies, where models are trained on mixed annotations, and offers a more principled way to capture inter-rater variability. Experiments on a colorectal organoid dataset annotated by two experts demonstrate that our rater-specific ensemble strategy improves calibration performance while maintaining comparable detection accuracy. These findings suggest that explicitly modelling rater disagreement can lead to more trustworthy object detectors in biomedical imaging.

</details>


### [72] [One-shot Optimized Steering Vector for Hallucination Mitigation for VLMs](https://arxiv.org/abs/2601.23041)
*Youxu Shi,Suorong Yang,Dong Liu*

Main category: cs.CV

TL;DR: OSGA is a one-shot steering framework that learns a single steering vector from one informative sample to improve VLM reliability on hallucination and safety, applicable universally at inference without model changes.


<details>
  <summary>Details</summary>
Motivation: VLMs suffer from hallucination and safety failures even at scale, and while steering offers lightweight improvement, existing methods struggle with efficiency-effectiveness trade-offs. The authors observed that steering vectors can generalize across inputs when tasks share semantic intent.

Method: OSGA uses variance-based data selection to pick one informative sample, then learns a single steering vector with contrastive objective and generative anchor regularization. This vector can be universally applied at a specific layer during inference without modifying model parameters.

Result: Experiments across multiple benchmarks show that a single OSGA-optimized steering vector consistently improves hallucination mitigation and safety enhancement with negligible overhead.

Conclusion: One-shot steering with OSGA provides a practical and scalable solution for improving VLM reliability, demonstrating that effective steering vectors can be learned from minimal data and applied universally.

Abstract: Vision Language Models (VLMs) achieve strong performance on multimodal tasks but still suffer from hallucination and safety-related failures that persist even at scale. Steering offers a lightweight technique to improve model performance. However, steering, whether input-dependent or input-independent, achieves a meaningful trade-off between efficiency and effectiveness. In this work, we observe that steering vectors can generalize across inputs when tasks share aligned semantic intent. Based on this insight, we propose \textbf{OSGA} (\textbf{O}ne-shot \textbf{S}teering with \textbf{G}enerative \textbf{A}nchor), an input-independent framework that improves model performance with a single optimization instance. OSGA first selects an informative sample via a variance-based data selection strategy and learns a single steering vector with a contrastive objective with generative anchor regularization. The resulting vector can be universally applied at a certain layer during inference time without modifying model parameters. Experiments across multiple benchmarks show that a single OSGA-optimized steering vector consistently improves hallucination mitigation and safety enhancement with negligible overhead, highlighting one-shot steering as a practical and scalable solution for reliable VLMs.

</details>


### [73] [HierLoc: Hyperbolic Entity Embeddings for Hierarchical Visual Geolocation](https://arxiv.org/abs/2601.23064)
*Hari Krishna Gadi,Daniel Matos,Hongyi Luo,Lu Liu,Yongliang Wang,Yanfeng Zhang,Liqiu Meng*

Main category: cs.CV

TL;DR: Hierarchical entity-based geolocation using hyperbolic embeddings with geo-weighted contrastive learning outperforms retrieval and classification methods.


<details>
  <summary>Details</summary>
Motivation: Current geolocation methods have limitations: retrieval requires massive storage, grid classifiers ignore geographic continuity, and generative models struggle with fine detail. Need a scalable, interpretable approach that respects geographic hierarchy.

Method: Entity-centric formulation with hierarchical geographic entities (country, region, subregion, city) embedded in Hyperbolic space. Uses Geo-Weighted Hyperbolic contrastive learning that incorporates haversine distance directly into the contrastive objective.

Result: State-of-the-art on OSV5M benchmark: reduces mean geodesic error by 19.5%, improves fine-grained subregion accuracy by 43%. Uses only 240k entity embeddings vs 5M+ image embeddings in retrieval methods.

Conclusion: Geometry-aware hierarchical embeddings provide a scalable, conceptually new alternative for global image geolocation that is efficient, interpretable, and respects geographic structure.

Abstract: Visual geolocalization, the task of predicting where an image was taken, remains challenging due to global scale, visual ambiguity, and the inherently hierarchical structure of geography. Existing paradigms rely on either large-scale retrieval, which requires storing a large number of image embeddings, grid-based classifiers that ignore geographic continuity, or generative models that diffuse over space but struggle with fine detail. We introduce an entity-centric formulation of geolocation that replaces image-to-image retrieval with a compact hierarchy of geographic entities embedded in Hyperbolic space. Images are aligned directly to country, region, subregion, and city entities through Geo-Weighted Hyperbolic contrastive learning by directly incorporating haversine distance into the contrastive objective. This hierarchical design enables interpretable predictions and efficient inference with 240k entity embeddings instead of over 5 million image embeddings on the OSV5M benchmark, on which our method establishes a new state-of-the-art performance. Compared to the current methods in the literature, it reduces mean geodesic error by 19.5\%, while improving the fine-grained subregion accuracy by 43%. These results demonstrate that geometry-aware hierarchical embeddings provide a scalable and conceptually new alternative for global image geolocation.

</details>


### [74] [Rethinking Transferable Adversarial Attacks on Point Clouds from a Compact Subspace Perspective](https://arxiv.org/abs/2601.23102)
*Keke Tang,Xianheng Liu,Weilong Peng,Xiaofei Wang,Daizong Liu,Peican Zhu,Can Lu,Zhihong Tian*

Main category: cs.CV

TL;DR: CoSA: A transferable adversarial attack framework for point clouds that operates in a low-dimensional semantic space using class-specific prototypes to improve cross-model generalization.


<details>
  <summary>Details</summary>
Motivation: Existing transferable adversarial attacks on point clouds rely on model-specific gradients or heuristics that limit generalization to unseen architectures, creating a need for more architecture-agnostic approaches.

Method: Represents point clouds as compact combinations of class-specific prototypes in a shared low-dimensional semantic space, optimizes adversarial perturbations within a low-rank subspace to induce coherent variations, and suppresses model-dependent noise while constraining perturbations to semantically meaningful directions.

Result: Extensive experiments on multiple datasets and network architectures show CoSA consistently outperforms state-of-the-art transferable attacks while maintaining competitive imperceptibility and robustness under common defense strategies.

Conclusion: Operating in a compact semantic subspace enables more effective transferable adversarial attacks on point clouds by focusing on architecture-agnostic semantic variations rather than model-specific artifacts.

Abstract: Transferable adversarial attacks on point clouds remain challenging, as existing methods often rely on model-specific gradients or heuristics that limit generalization to unseen architectures. In this paper, we rethink adversarial transferability from a compact subspace perspective and propose CoSA, a transferable attack framework that operates within a shared low-dimensional semantic space. Specifically, each point cloud is represented as a compact combination of class-specific prototypes that capture shared semantic structure, while adversarial perturbations are optimized within a low-rank subspace to induce coherent and architecture-agnostic variations. This design suppresses model-dependent noise and constrains perturbations to semantically meaningful directions, thereby improving cross-model transferability without relying on surrogate-specific artifacts. Extensive experiments on multiple datasets and network architectures demonstrate that CoSA consistently outperforms state-of-the-art transferable attacks, while maintaining competitive imperceptibility and robustness under common defense strategies. Codes will be made public upon paper acceptance.

</details>


### [75] [Segment Any Events with Language](https://arxiv.org/abs/2601.23159)
*Seungjun Lee,Gim Hee Lee*

Main category: cs.CV

TL;DR: SEAL is the first framework for Open-Vocabulary Event Instance Segmentation (OV-EIS) that supports both event segmentation and open-vocabulary mask classification at instance and part levels.


<details>
  <summary>Details</summary>
Motivation: While scene understanding with free-form language exists for images, point clouds, and LiDAR, event sensor studies are scarce or limited to semantic-level understanding, creating a gap for open-vocabulary event instance segmentation.

Method: SEAL presents a unified framework using visual prompts to support event segmentation and open-vocabulary mask classification at multiple granularity levels (instance-level and part-level). The architecture is parameter-efficient.

Result: SEAL significantly outperforms baselines in both performance and inference speed across four curated benchmarks covering coarse to fine class configurations and instance to part-level understanding.

Conclusion: SEAL successfully addresses the OV-EIS task with a parameter-efficient framework, and a variant achieves generic spatiotemporal OV-EIS without requiring visual prompts during inference.

Abstract: Scene understanding with free-form language has been widely explored within diverse modalities such as images, point clouds, and LiDAR. However, related studies on event sensors are scarce or narrowly centered on semantic-level understanding. We introduce SEAL, the first Semantic-aware Segment Any Events framework that addresses Open-Vocabulary Event Instance Segmentation (OV-EIS). Given the visual prompt, our model presents a unified framework to support both event segmentation and open-vocabulary mask classification at multiple levels of granularity, including instance-level and part-level. To enable thorough evaluation on OV-EIS, we curate four benchmarks that cover label granularity from coarse to fine class configurations and semantic granularity from instance-level to part-level understanding. Extensive experiments show that our SEAL largely outperforms proposed baselines in terms of performance and inference speed with a parameter-efficient architecture. In the Appendix, we further present a simple variant of our SEAL achieving generic spatiotemporal OV-EIS that does not require any visual prompts from users in the inference. Check out our project page in https://0nandon.github.io/SEAL

</details>


### [76] [Hi-Light: A Path to high-fidelity, high-resolution video relighting with a Novel Evaluation Paradigm](https://arxiv.org/abs/2601.23167)
*Xiangrui Liu,Haoxiang Li,Yezhou Yang*

Main category: cs.CV

TL;DR: Hi-Light is a training-free framework for high-fidelity video relighting that addresses flickering, detail loss, and lack of evaluation metrics through three innovations: guided relighting diffusion, motion-adaptive filtering, and detail fusion, plus a new Light Stability Score metric.


<details>
  <summary>Details</summary>
Motivation: Video relighting has creative and commercial value but faces three main challenges: 1) no adequate evaluation metric for lighting consistency, 2) severe light flickering in edited videos, and 3) degradation of fine-grained details during editing.

Method: Three technical innovations: 1) Lightness prior anchored guided relighting diffusion to stabilize intermediate relit video, 2) Hybrid Motion-Adaptive Lighting Smoothing Filter using optical flow for temporal stability without motion blur, and 3) LAB-based Detail Fusion module to preserve high-frequency details from original video.

Result: Extensive experiments show Hi-Light significantly outperforms state-of-the-art methods in both qualitative and quantitative comparisons, producing stable, highly detailed relit videos.

Conclusion: Hi-Light successfully addresses key challenges in video relighting through its training-free framework, three technical innovations, and the introduction of the Light Stability Score metric, enabling high-fidelity, stable video relighting.

Abstract: Video relighting offers immense creative potential and commercial value but is hindered by challenges, including the absence of an adequate evaluation metric, severe light flickering, and the degradation of fine-grained details during editing. To overcome these challenges, we introduce Hi-Light, a novel, training-free framework for high-fidelity, high-resolution, robust video relighting. Our approach introduces three technical innovations: lightness prior anchored guided relighting diffusion that stabilises intermediate relit video, a Hybrid Motion-Adaptive Lighting Smoothing Filter that leverages optical flow to ensure temporal stability without introducing motion blur, and a LAB-based Detail Fusion module that preserves high-frequency detail information from the original video. Furthermore, to address the critical gap in evaluation, we propose the Light Stability Score, the first quantitative metric designed to specifically measure lighting consistency. Extensive experiments demonstrate that Hi-Light significantly outperforms state-of-the-art methods in both qualitative and quantitative comparisons, producing stable, highly detailed relit videos.

</details>


### [77] [Med-Scout: Curing MLLMs' Geometric Blindness in Medical Perception via Geometry-Aware RL Post-Training](https://arxiv.org/abs/2601.23220)
*Anglin Liu,Ruichao Chen,Yi Lu,Hongxia Xu,Jintai Chen*

Main category: cs.CV

TL;DR: Med-Scout is an RL framework that cures geometric blindness in MLLMs by using proxy tasks on unlabeled medical images, improving geometric perception by 40+% and enhancing overall medical VQA performance.


<details>
  <summary>Details</summary>
Motivation: State-of-the-art MLLMs suffer from geometric blindness in medical diagnosis, prioritizing linguistic fluency over geometric fidelity, leading to plausible but factually incorrect hallucinations due to training paradigm limitations.

Method: Introduces Med-Scout framework using Reinforcement Learning with three proxy tasks on unlabeled medical images: Hierarchical Scale Localization, Topological Jigsaw Reconstruction, and Anomaly Consistency Detection, plus Med-Scout-Bench benchmark for evaluation.

Result: Med-Scout significantly mitigates geometric blindness, outperforming leading proprietary and open-source MLLMs by over 40% on the Med-Scout-Bench benchmark, with enhanced geometric perception generalizing to superior performance on radiological and comprehensive medical VQA tasks.

Conclusion: The Med-Scout framework successfully addresses geometric blindness in MLLMs through RL-based geometric perception enhancement using unlabeled medical images, demonstrating substantial improvements in both geometric reasoning and broader medical understanding tasks.

Abstract: Despite recent Multimodal Large Language Models (MLLMs)' linguistic prowess in medical diagnosis, we find even state-of-the-art MLLMs suffer from a critical perceptual deficit: geometric blindness. This failure to ground outputs in objective geometric constraints leads to plausible yet factually incorrect hallucinations, rooted in training paradigms that prioritize linguistic fluency over geometric fidelity. This paper introduces Med-Scout, a novel framework that "cures" this blindness via Reinforcement Learning (RL) that leverages the intrinsic geometric logic latent within unlabeled medical images. Instead of relying on costly expert annotations, Med-Scout derives verifiable supervision signals through three strategic proxy tasks: Hierarchical Scale Localization, Topological Jigsaw Reconstruction, and Anomaly Consistency Detection. To rigorously quantify this deficit, we present Med-Scout-Bench, a new benchmark specifically designed to evaluate geometric perception. Extensive evaluations show that Med-Scout significantly mitigates geometric blindness, outperforming leading proprietary and open-source MLLMs by over 40% on our benchmark. Furthermore, this enhanced geometric perception generalizes to broader medical understanding, achieving superior results on radiological and comprehensive medical VQA tasks.

</details>


### [78] [Region-Normalized DPO for Medical Image Segmentation under Noisy Judges](https://arxiv.org/abs/2601.23222)
*Hamza Kalisch,Constantin Seibold,Jens Kleesiek,Ken Herrmann,Frederic Jonske*

Main category: cs.CV

TL;DR: RN-DPO improves segmentation fine-tuning using noisy quality-control signals by normalizing preference updates by disagreement region size, stabilizing training and outperforming standard DPO without additional annotations.


<details>
  <summary>Details</summary>
Motivation: Medical image segmentation requires costly pixel-wise annotations, but deployed systems already produce inexpensive automatic quality-control signals (model agreement, uncertainty, mask-quality scores). These signals can be noisy and biased, making preference-based fine-tuning susceptible to harmful updates.

Method: Proposes Region-Normalized DPO (RN-DPO), a segmentation-aware objective that normalizes preference updates by the size of the disagreement region between masks. Uses proposals from a supervised base segmenter trained on small labeled set, with preference pairs mined from noisy QC judges.

Result: RN-DPO improves sustained performance and stabilizes preference-based fine-tuning across two medical datasets and multiple regimes. Outperforms standard DPO and strong baselines without requiring additional pixel annotations. Reduces leverage of harmful comparisons and improves optimization stability.

Conclusion: RN-DPO enables effective use of noisy quality-control signals for medical image segmentation fine-tuning, addressing limitations of standard DPO by incorporating segmentation-aware normalization that accounts for disagreement region size.

Abstract: While dense pixel-wise annotations remain the gold standard for medical image segmentation, they are costly to obtain and limit scalability. In contrast, many deployed systems already produce inexpensive automatic quality-control (QC) signals like model agreement, uncertainty measures, or learned mask-quality scores which can be used for further model training without additional ground-truth annotation. However, these signals can be noisy and biased, making preference-based fine-tuning susceptible to harmful updates. We study Direct Preference Optimization (DPO) for segmentation from such noisy judges using proposals generated by a supervised base segmenter trained on a small labeled set. We find that outcomes depend strongly on how preference pairs are mined: selecting the judge's top-ranked proposal can improve peak performance when the judge is reliable, but can amplify harmful errors under weaker judges. We propose Region-Normalized DPO (RN-DPO), a segmentation-aware objective which normalizes preference updates by the size of the disagreement region between masks, reducing the leverage of harmful comparisons and improving optimization stability. Across two medical datasets and multiple regimes, RN-DPO improves sustained performance and stabilizes preference-based fine-tuning, outperforming standard DPO and strong baselines without requiring additional pixel annotations.

</details>


### [79] [ShotFinder: Imagination-Driven Open-Domain Video Shot Retrieval via Web Search](https://arxiv.org/abs/2601.23232)
*Tao Yu,Haopeng Jin,Hao Wang,Shenghua Chai,Yujia Yang,Junhao Gong,Jiaming Guo,Minghui Zhang,Xinlong Chen,Zhenghao Zhang,Yuxuan Zhou,Yanpei Gong,YuanCheng Liu,Yiming Ding,Kangwei Zeng,Pengfei Yang,Zhongtian Luo,Yufei Xiong,Shanbin Zhang,Shaoxiong Cheng,Huang Ruilin,Li Shuo,Yuxi Niu,Xinyuan Zhang,Yueya Xu,Jie Mao,Ruixuan Ji,Yaru Zhao,Mingchen Zhang,Jiabing Yang,Jiaqi Liu,YiFan Zhang,Hongzhu Yi,Xinming Wang,Cheng Zhong,Xiao Ma,Zhang Zhang,Yan Huang,Liang Wang*

Main category: cs.CV

TL;DR: ShotFinder introduces a benchmark for open-domain video shot retrieval with controllable constraints, revealing significant gaps in current multimodal models' capabilities.


<details>
  <summary>Details</summary>
Motivation: Existing LLM research focuses on text or static multimodal settings, but open-domain video shot retrieval with temporal structure and complex semantics lacks systematic benchmarks and analysis.

Method: Created ShotFinder benchmark with 1,210 samples from YouTube across 20 categories, formalizing editing requirements as keyframe-oriented shot descriptions with five controllable constraints. Proposed a three-stage retrieval pipeline: query expansion via video imagination, candidate retrieval with search engine, and description-guided temporal localization.

Result: Experiments show significant gap between current models and human performance, with clear imbalance across constraints - temporal localization is relatively tractable while color and visual style remain major challenges.

Conclusion: Open-domain video shot retrieval is a critical capability that multimodal large models have yet to overcome, highlighting the need for further research in this area.

Abstract: In recent years, large language models (LLMs) have made rapid progress in information retrieval, yet existing research has mainly focused on text or static multimodal settings. Open-domain video shot retrieval, which involves richer temporal structure and more complex semantics, still lacks systematic benchmarks and analysis. To fill this gap, we introduce ShotFinder, a benchmark that formalizes editing requirements as keyframe-oriented shot descriptions and introduces five types of controllable single-factor constraints: Temporal order, Color, Visual style, Audio, and Resolution. We curate 1,210 high-quality samples from YouTube across 20 thematic categories, using large models for generation with human verification. Based on the benchmark, we propose ShotFinder, a text-driven three-stage retrieval and localization pipeline: (1) query expansion via video imagination, (2) candidate video retrieval with a search engine, and (3) description-guided temporal localization. Experiments on multiple closed-source and open-source models reveal a significant gap to human performance, with clear imbalance across constraints: temporal localization is relatively tractable, while color and visual style remain major challenges. These results reveal that open-domain video shot retrieval is still a critical capability that multimodal large models have yet to overcome.

</details>


### [80] [Video-o3: Native Interleaved Clue Seeking for Long Video Multi-Hop Reasoning](https://arxiv.org/abs/2601.23224)
*Xiangyu Zeng,Zhiqiu Zhang,Yuhan Zhu,Xinhao Li,Zikang Wang,Changlian Ma,Qingyu Zhang,Zizheng Huang,Kun Ouyang,Tianxiang Jiang,Ziang Yan,Yi Wang,Hongjie Zhang,Yali Wang,Limin Wang*

Main category: cs.CV

TL;DR: Video-o3 is a novel framework for long-video understanding that uses iterative tool invocation to discover sparse critical evidence, addressing attention dispersion and context growth challenges through specialized attention masking and reward mechanisms.


<details>
  <summary>Details</summary>
Motivation: Existing multimodal LLMs for long-video understanding rely on uniform sampling and single-turn inference, which limits their ability to identify sparse but critical evidence amid extensive redundancy in long videos.

Method: Video-o3 introduces iterative discovery of salient visual clues with fine-grained inspection of key segments and adaptive termination. It uses Task-Decoupled Attention Masking to isolate per-step concentration while preserving global context, and a Verifiable Trajectory-Guided Reward to balance exploration coverage with reasoning efficiency. The framework is trained on Seeker-173K, a dataset of 173K high-quality tool-interaction trajectories.

Result: Video-o3 substantially outperforms state-of-the-art methods, achieving 72.1% accuracy on MLVU and 46.5% on Video-Holmes benchmarks, demonstrating strong multi-hop evidence-seeking and reasoning capabilities.

Conclusion: The results validate the effectiveness of native tool invocation in long-video scenarios and show that Video-o3's iterative evidence-seeking approach successfully addresses the limitations of existing uniform sampling methods.

Abstract: Existing multimodal large language models for long-video understanding predominantly rely on uniform sampling and single-turn inference, limiting their ability to identify sparse yet critical evidence amid extensive redundancy. We introduce Video-o3, a novel framework that supports iterative discovery of salient visual clues, fine-grained inspection of key segments, and adaptive termination once sufficient evidence is acquired. Technically, we address two core challenges in interleaved tool invocation. First, to mitigate attention dispersion induced by the heterogeneity of reasoning and tool-calling, we propose Task-Decoupled Attention Masking, which isolates per-step concentration while preserving shared global context. Second, to control context length growth in multi-turn interactions, we introduce a Verifiable Trajectory-Guided Reward that balances exploration coverage with reasoning efficiency. To support training at scale, we further develop a data synthesis pipeline and construct Seeker-173K, comprising 173K high-quality tool-interaction trajectories for effective supervised and reinforcement learning. Extensive experiments show that Video-o3 substantially outperforms state-of-the-art methods, achieving 72.1% accuracy on MLVU and 46.5% on Video-Holmes. These results demonstrate Video-o3's strong multi-hop evidence-seeking and reasoning capabilities, and validate the effectiveness of native tool invocation in long-video scenarios.

</details>


### [81] [Structured Over Scale: Learning Spatial Reasoning from Educational Video](https://arxiv.org/abs/2601.23251)
*Bishoy Galoaa,Xiangyu Bai,Sarah Ostadabbas*

Main category: cs.CV

TL;DR: VLMs trained on structured educational videos (Dora the Explorer) show significant improvements in basic reasoning tasks where current models fail, achieving SOTA on multiple benchmarks despite limited training data.


<details>
  <summary>Details</summary>
Motivation: Current vision-language models perform well on standard benchmarks but fail at simple reasoning tasks that preschool children can solve (counting, spatial reasoning, compositional understanding). The authors hypothesize that pedagogically-structured educational content provides an ideal training signal for improving these capabilities.

Method: Created DoraVQA dataset (5,344 QA pairs) automatically extracted from 8 seasons of Dora the Explorer with precise timestamp alignment. Fine-tuned Qwen2 and Qwen3 using Group Relative Policy Optimization (GRPO), leveraging the clear correctness signals and structured reasoning traces inherent in educational content's "context-question-pause-answer" structure.

Result: Despite training on only 38 hours of children's educational videos, achieved 8-14 point improvements on DoraVQA and state-of-the-art 86.16% on CVBench, with strong transfer to Video-MME and NExT-QA. Models demonstrated effective generalization from narrow pedagogical content to broad multimodal understanding.

Conclusion: VLMs can perform tasks requiring robust reasoning when trained on structured educational content, suggesting that content structure matters as much as content scale. Pedagogical structure provides valuable training signals for improving fundamental reasoning capabilities in multimodal models.

Abstract: Vision-language models (VLMs) demonstrate impressive performance on standard video understanding benchmarks yet fail systematically on simple reasoning tasks that preschool children can solve, including counting, spatial reasoning, and compositional understanding. We hypothesize that the pedagogically-structured content of educational videos provides an ideal training signal for improving these capabilities. We introduce DoraVQA, a dataset of 5,344 question-answer pairs automatically extracted from 8 seasons of Dora the Explorer with precise timestamp alignment. Each episode follows a consistent \textit{context-question-pause-answer} structure that creates a self-contained learning environment analogous to interactive tutoring. We fine-tune both Qwen2 and Qwen3 using Group Relative Policy Optimization (GRPO), leveraging the clear correctness signals and structured reasoning traces inherent in educational content. Despite training exclusively on 38 hours of children's educational videos, our approach achieves improvements of 8-14 points on DoraVQA and state-of-the-art 86.16\% on CVBench, with strong transfer to Video-MME and NExT-QA, demonstrating effective generalization from narrow pedagogical content to broad multimodal understanding. Through cross-domain benchmarks, we show that VLMs can perform tasks that require robust reasoning learned from structured educational content, suggesting that content structure matters as much as content scale.

</details>


### [82] [VideoGPA: Distilling Geometry Priors for 3D-Consistent Video Generation](https://arxiv.org/abs/2601.23286)
*Hongyang Du,Junjie Ye,Xiaoyan Cong,Runhao Li,Jingcheng Ni,Aman Agarwal,Zeqi Zhou,Zekun Li,Randall Balestriero,Yue Wang*

Main category: cs.CV

TL;DR: VideoGPA is a self-supervised framework that uses geometry foundation models to provide dense preference signals for video diffusion models, improving 3D structural consistency without human annotations.


<details>
  <summary>Details</summary>
Motivation: Current video diffusion models struggle with 3D structural consistency, causing object deformation and spatial drift, because standard denoising objectives lack explicit geometric coherence incentives.

Method: VideoGPA leverages a geometry foundation model to automatically generate dense preference signals, then uses Direct Preference Optimization (DPO) to guide video diffusion models toward 3D consistency without human annotations.

Result: VideoGPA significantly enhances temporal stability, physical plausibility, and motion coherence using minimal preference pairs, consistently outperforming state-of-the-art baselines in extensive experiments.

Conclusion: The self-supervised VideoGPA framework effectively addresses 3D consistency issues in video generation by aligning video diffusion models with geometric preferences, achieving superior results with minimal data requirements.

Abstract: While recent video diffusion models (VDMs) produce visually impressive results, they fundamentally struggle to maintain 3D structural consistency, often resulting in object deformation or spatial drift. We hypothesize that these failures arise because standard denoising objectives lack explicit incentives for geometric coherence. To address this, we introduce VideoGPA (Video Geometric Preference Alignment), a data-efficient self-supervised framework that leverages a geometry foundation model to automatically derive dense preference signals that guide VDMs via Direct Preference Optimization (DPO). This approach effectively steers the generative distribution toward inherent 3D consistency without requiring human annotations. VideoGPA significantly enhances temporal stability, physical plausibility, and motion coherence using minimal preference pairs, consistently outperforming state-of-the-art baselines in extensive experiments.

</details>


### [83] [Training-Free Test-Time Adaptation with Brownian Distance Covariance in Vision-Language Models](https://arxiv.org/abs/2601.23253)
*Yi Zhang,Chun-Wun Cheng,Angelica I. Aviles-Rivero,Zhihai He,Liang-Jie Zhang*

Main category: cs.CV

TL;DR: TaTa is a training-free test-time adaptation method for vision-language models that uses Brownian Distance Covariance for efficient domain adaptation without back-propagation.


<details>
  <summary>Details</summary>
Motivation: Vision-language models degrade under domain shift, and existing test-time adaptation methods are computationally intensive, rely on back-propagation, and focus on single modalities.

Method: Uses Brownian Distance Covariance to capture linear/nonlinear dependencies via pairwise distances for dynamic adaptation without training, plus attribute-enhanced prompting, dynamic clustering, and pseudo-label refinement.

Result: Significantly reduces computational cost while achieving state-of-the-art performance in domain and cross-dataset generalization across diverse datasets.

Conclusion: TaTa provides an efficient, stable, and effective solution for adapting vision-language models to new domains without the computational burden of traditional methods.

Abstract: Vision-language models suffer performance degradation under domain shift, limiting real-world applicability. Existing test-time adaptation methods are computationally intensive, rely on back-propagation, and often focus on single modalities. To address these issues, we propose Training-free Test-Time Adaptation with Brownian Distance Covariance (TaTa). TaTa leverages Brownian Distance Covariance-a powerful statistical measure that captures both linear and nonlinear dependencies via pairwise distances-to dynamically adapt VLMs to new domains without training or back-propagation. This not only improves efficiency but also enhances stability by avoiding disruptive weight updates. TaTa further integrates attribute-enhanced prompting to improve vision-language inference with descriptive visual cues. Combined with dynamic clustering and pseudo-label refinement, it effectively recalibrates the model for novel visual contexts. Experiments across diverse datasets show that TaTa significantly reduces computational cost while achieving state-of-the-art performance in domain and cross-dataset generalization.

</details>


### [84] [User Prompting Strategies and Prompt Enhancement Methods for Open-Set Object Detection in XR Environments](https://arxiv.org/abs/2601.23281)
*Junfeng Lin,Yanming Xiu,Maria Gorlatova*

Main category: cs.CV

TL;DR: OSOD models (GroundingDINO & YOLO-E) show stable performance with standard/underdetailed prompts but degrade with ambiguous prompts; overdetailed prompts mainly affect GroundingDINO. Prompt enhancement improves robustness significantly.


<details>
  <summary>Details</summary>
Motivation: While OSOD models perform well on benchmarks, their behavior under realistic user prompting in interactive XR settings remains underexplored, especially when prompts are ambiguous, underspecified, or overly detailed.

Method: Evaluate two OSOD models on real-world XR images, simulate diverse user prompting behaviors using vision-language models (four prompt types: standard, underdetailed, overdetailed, pragmatically ambiguous), and examine impact of two enhancement strategies.

Result: Both models show stable performance under underdetailed and standard prompts, degrade under ambiguous prompts, with overdetailed prompts primarily affecting GroundingDINO. Prompt enhancement substantially improves robustness under ambiguity (exceeding 55% mIoU and 41% average confidence gains).

Conclusion: Propose several prompting strategies and prompt enhancement methods for OSOD models in XR environments based on findings about prompt-conditioned robustness.

Abstract: Open-set object detection (OSOD) localizes objects while identifying and rejecting unknown classes at inference. While recent OSOD models perform well on benchmarks, their behavior under realistic user prompting remains underexplored. In interactive XR settings, user-generated prompts are often ambiguous, underspecified, or overly detailed. To study prompt-conditioned robustness, we evaluate two OSOD models, GroundingDINO and YOLO-E, on real-world XR images and simulate diverse user prompting behaviors using vision-language models. We consider four prompt types: standard, underdetailed, overdetailed, and pragmatically ambiguous, and examine the impact of two enhancement strategies on these prompts. Results show that both models exhibit stable performance under underdetailed and standard prompts, while they suffer degradation under ambiguous prompts. Overdetailed prompts primarily affect GroundingDINO. Prompt enhancement substantially improves robustness under ambiguity, yielding gains exceeding 55% mIoU and 41% average confidence. Based on the findings, we propose several prompting strategies and prompt enhancement methods for OSOD models in XR environments.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [85] [Advanced techniques and applications of LiDAR Place Recognition in Agricultural Environments: A Comprehensive Survey](https://arxiv.org/abs/2601.22198)
*Judith Vilella-Cantos,Mónica Ballesta,David Valiente,María Flores,Luis Payá*

Main category: cs.RO

TL;DR: Survey paper reviewing deep learning applications for LiDAR place recognition in agricultural environments, focusing on challenges, approaches, datasets, and future directions.


<details>
  <summary>Details</summary>
Motivation: Agricultural environments lack distinctive features and are unstructured, making LiDAR place recognition challenging compared to urban settings. Precision agriculture needs accurate localization for autonomous robotic systems.

Method: Comprehensive review of state-of-the-art deep learning applications and LPR techniques for agricultural environments, analyzing existing approaches, datasets, and evaluation metrics.

Result: First survey focusing on LiDAR-based localization in agricultural settings, providing thorough understanding of current techniques and identifying challenges specific to these environments.

Conclusion: The survey aims to foster further research in agricultural LiDAR place recognition by highlighting limitations and future directions in this specialized domain.

Abstract: An optimal solution to the localization problem is essential for developing autonomous robotic systems. Apart from autonomous vehicles, precision agriculture is one of the elds that can bene t most from these systems. Although LiDAR place recognition is a widely used technique in recent years to achieve accurate localization, it is mostly used in urban settings. However, the lack of distinctive features and the unstructured nature of agricultural environments make place recognition challenging. This work presents a comprehensive review of state-of-the-art the latest deep learning applications for agricultural environments and LPR techniques. We focus on the challenges that arise in these environments. We analyze the existing approaches, datasets, and metrics used to evaluate LPR system performance and discuss the limitations and future directions of research in this eld. This is the rst survey that focuses on LiDAR based localization in agricultural settings, with the aim of providing a thorough understanding and fostering further research in this specialized domain.

</details>


### [86] [Game-Based and Gamified Robotics Education: A Comparative Systematic Review and Design Guidelines](https://arxiv.org/abs/2601.22199)
*Syed T. Mubarrat,Byung-Cheol Min,Tianyu Shao,E. Cho Smith,Bedrich Benes,Alejandra J. Magana,Christos Mousas,Dominic Kao*

Main category: cs.RO

TL;DR: First systematic review comparing game-based learning vs gamification in robotics education, analyzing 95 studies to identify patterns and propose design guidelines.


<details>
  <summary>Details</summary>
Motivation: Robotics education is challenging due to technical complexity, and while game-based learning and gamification offer engagement benefits, their comparative impact remains unclear, necessitating systematic review.

Method: PRISMA-aligned systematic review of 95 studies from 12,485 records across four databases (2014-2025), with coding of approach, context, skill level, modality, pedagogy, and outcomes (k = .918).

Result: Three key patterns: 1) approach-context-pedagogy coupling (GBL more in informal settings, gamification dominates formal classrooms), 2) emphasis on introductory programming with limited advanced tech adoption, 3) short study horizons relying on self-report.

Conclusion: Proposes eight research directions and a design space with best practices/pitfalls, offering actionable guidance for robotics education based on comparative analysis of GBL and gamification approaches.

Abstract: Robotics education fosters computational thinking, creativity, and problem-solving, but remains challenging due to technical complexity. Game-based learning (GBL) and gamification offer engagement benefits, yet their comparative impact remains unclear. We present the first PRISMA-aligned systematic review and comparative synthesis of GBL and gamification in robotics education, analyzing 95 studies from 12,485 records across four databases (2014-2025). We coded each study's approach, learning context, skill level, modality, pedagogy, and outcomes (k = .918). Three patterns emerged: (1) approach-context-pedagogy coupling (GBL more prevalent in informal settings, while gamification dominated formal classrooms [p < .001] and favored project-based learning [p = .009]); (2) emphasis on introductory programming and modular kits, with limited adoption of advanced software (~17%), advanced hardware (~5%), or immersive technologies (~22%); and (3) short study horizons, relying on self-report. We propose eight research directions and a design space outlining best practices and pitfalls, offering actionable guidance for robotics education.

</details>


### [87] [ReloPush-BOSS: Optimization-guided Nonmonotone Rearrangement Planning for a Car-like Robot Pusher](https://arxiv.org/abs/2601.22289)
*Jeeho Ahn,Christoforos Mavrogiannis*

Main category: cs.RO

TL;DR: ReloPush-BOSS: A framework for multi-object rearrangement planning in cluttered environments using a car-like robot pusher that optimizes temporary object displacements (prerelocations) using Dubins path classification to avoid local minima and generate feasible, low-cost pushing sequences.


<details>
  <summary>Details</summary>
Motivation: Multi-object rearrangement in densely cluttered environments with car-like robot pushers presents challenging nonmonotone problems due to kinematic, geometric, and physics constraints. Existing approaches using temporary object displacements (prerelocations) struggle with local minima that lead to infeasible or high-cost paths.

Method: The framework optimizes prerelocations using Dubins path classification to steer away from local minima, integrates these optimized prerelocations into an object traversability graph encoding kinematic, geometric, and pushing constraints, and searches this graph in depth-first fashion to generate rearrangement sequences.

Result: In densely cluttered scenarios with up to 13 objects, ReloPush-BOSS achieves consistently highest success rates and shortest pushing paths compared to state-of-the-art baselines. Hardware experiments on a 1/10 car-like pusher demonstrate robustness.

Conclusion: The proposed ReloPush-BOSS framework effectively addresses multi-object rearrangement challenges in cluttered environments by optimizing temporary object displacements using Dubins path classification, resulting in efficient, feasible solutions that outperform existing methods.

Abstract: We focus on multi-object rearrangement planning in densely cluttered environments using a car-like robot pusher. The combination of kinematic, geometric and physics constraints underlying this domain results in challenging nonmonotone problem instances which demand breaking each manipulation action into multiple parts to achieve a desired object rearrangement. Prior work tackles such instances by planning prerelocations, temporary object displacements that enable constraint satisfaction, but deciding where to prerelocate remains difficult due to local minima leading to infeasible or high-cost paths. Our key insight is that these minima can be avoided by steering a prerelocation optimization toward low-cost regions informed by Dubins path classification. These optimized prerelocations are integrated into an object traversability graph that encodes kinematic, geometric, and pushing constraints. Searching this graph in a depth-first fashion results in efficient, feasible rearrangement sequences. Across a series of densely cluttered scenarios with up to 13 objects, our framework, ReloPush-BOSS, exhibits consistently highest success rates and shortest pushing paths compared to state-of-the-art baselines. Hardware experiments on a 1/10 car-like pusher demonstrate the robustness of our approach. Code and footage from our experiments can be found at: https://fluentrobotics.com/relopushboss.

</details>


### [88] [Lantern: A Minimalist Robotic Object Platform](https://arxiv.org/abs/2601.22381)
*Victor Nikhil Antony,Zhili Gong,Guanchen Li,Clara Jeon,Chien-Ming Huang*

Main category: cs.RO

TL;DR: Lantern is a low-cost (~$40), minimalist robotic object platform designed to enable exploration of human-robot interaction scenarios by leveraging humans' tendency to assign social meaning to simple forms.


<details>
  <summary>Details</summary>
Motivation: To create an accessible, low-cost robotic platform that can facilitate exploration of human-robot interaction (HRI) scenarios by leveraging the human tendency to anthropomorphize simple objects, thereby lowering barriers to HRI research and application development.

Method: Designed and engineered Lantern's mechatronic architecture through iterative development, then evaluated through multiple approaches: 1) co-design workshop, 2) sensory room case study, 3) distribution to external HRI labs, 4) integration into graduate HRI course, and 5) public exhibitions with older adults and children.

Result: Lantern effectively evokes user engagement, supports versatile applications ranging from emotion regulation to focused work, and serves as a viable platform for lowering barriers to entry in HRI research and development.

Conclusion: Lantern successfully demonstrates that minimalist robotic objects can serve as effective platforms for exploring diverse HRI scenarios while maintaining low cost and accessibility, making HRI research more approachable for various stakeholders including researchers, students, and end-users.

Abstract: Robotic objects are simple actuated systems that subtly blend into human environments. We design and introduce Lantern, a minimalist robotic object platform to enable building simple robotic artifacts. We conducted in-depth design and engineering iterations of Lantern's mechatronic architecture to meet specific design goals while maintaining a low build cost (~40 USD). As an extendable, open-source platform, Lantern aims to enable exploration of a range of HRI scenarios by leveraging human tendency to assign social meaning to simple forms. To evaluate Lantern's potential for HRI, we conducted a series of explorations: 1) a co-design workshop, 2) a sensory room case study, 3) distribution to external HRI labs, 4) integration into a graduate-level HRI course, and 5) public exhibitions with older adults and children. Our findings show that Lantern effectively evokes engagement, can support versatile applications ranging from emotion regulation to focused work, and serves as a viable platform for lowering barriers to HRI as a field.

</details>


### [89] [Plant-Inspired Robot Design Metaphors for Ambient HRI](https://arxiv.org/abs/2601.22387)
*Victor Nikhil Antony,Adithya R N,Sarah Derrick,Zhili Gong,Peter M. Donley,Chien-Ming Huang*

Main category: cs.RO

TL;DR: Using plants as inspiration for human-robot interaction design to create ambient, low-demand robotic forms instead of overt anthropomorphic designs.


<details>
  <summary>Details</summary>
Motivation: Current HRI relies heavily on anthropomorphic/zoomorphic paradigms that create high-demand engagement, while plants offer alternative models of ambient, subtle interaction through temporal rhythms and expressions.

Method: Research through Design methodology with iterative cycles of ideation, prototyping, and reflection; prototype-centered workshops to explore perceptions of plant-inspired robots.

Result: Developed suite of speculative open-source prototypes exploring plant-inspired presence, temporality, form, and gestures; gained insights on how people perceive plant-inspired robots.

Conclusion: Plants provide valuable metaphors for reshaping HRI toward more ambient, low-demand interactions, with contributions including robotic artifacts, designerly insights, and design considerations.

Abstract: Plants offer a paradoxical model for interaction: they are ambient, low-demand presences that nonetheless shape atmosphere, routines, and relationships through temporal rhythms and subtle expressions. In contrast, most human-robot interaction (HRI) has been grounded in anthropomorphic and zoomorphic paradigms, producing overt, high-demand forms of engagement. Using a Research through Design (RtD) methodology, we explore plants as metaphoric inspiration for HRI; we conducted iterative cycles of ideation, prototyping, and reflection to investigate what design primitives emerge from plant metaphors and morphologies, and how these primitives can be combined into expressive robotic forms. We present a suite of speculative, open-source prototypes that help probe plant-inspired presence, temporality, form, and gestures. We deepened our learnings from design and prototyping through prototype-centered workshops that explored people's perceptions and imaginaries of plant-inspired robots. This work contributes: (1) Set of plant-inspired robotic artifacts; (2) Designerly insights on how people perceive plant-inspired robots; and (3) Design consideration to inform how to use plant metaphors to reshape HRI.

</details>


### [90] [Accurate Pedestrian Tracking in Urban Canyons: A Multi-Modal Fusion Approach](https://arxiv.org/abs/2601.22406)
*Shahar Dubiner,Peng Ren,Roberto Manduchi*

Main category: cs.RO

TL;DR: Particle filter fusion of GNSS and inertial data with map priors improves pedestrian navigation accuracy in urban environments, especially for blind users needing precise street-side identification.


<details>
  <summary>Details</summary>
Motivation: Improve localization accuracy in urban environments where GNSS performance is degraded, which is critical for blind or low-vision users who depend on precise guidance like identifying the correct side of a street.

Method: Particle filter-based fusion of GNSS and inertial data (using RoNIN machine learning method) that incorporates spatial priors from maps (impassable buildings, unlikely walking areas) as probabilistic map matching.

Result: Fused approach (GNSS+RoNIN+PF) significantly outperforms GNSS-only localization on most metrics; inertial-only localization with particle filtering also surpasses GNSS alone for critical measures like sidewalk assignment and across-street error.

Conclusion: The proposed fusion approach effectively addresses GNSS limitations in urban environments, providing more accurate pedestrian navigation that is particularly valuable for blind and low-vision users requiring precise street-side guidance.

Abstract: The contribution describes a pedestrian navigation approach designed to improve localization accuracy in urban environments where GNSS performance is degraded, a problem that is especially critical for blind or low-vision users who depend on precise guidance such as identifying the correct side of a street. To address GNSS limitations and the impracticality of camera-based visual positioning, the work proposes a particle filter based fusion of GNSS and inertial data that incorporates spatial priors from maps, such as impassable buildings and unlikely walking areas, functioning as a probabilistic form of map matching. Inertial localization is provided by the RoNIN machine learning method, and fusion with GNSS is achieved by weighting particles based on their consistency with GNSS estimates and uncertainty. The system was evaluated on six challenging walking routes in downtown San Francisco using three metrics related to sidewalk correctness and localization error. Results show that the fused approach (GNSS+RoNIN+PF) significantly outperforms GNSS only localization on most metrics, while inertial-only localization with particle filtering also surpasses GNSS alone for critical measures such as sidewalk assignment and across street error.

</details>


### [91] [High-Definition 5MP Stereo Vision Sensing for Robotics](https://arxiv.org/abs/2601.22445)
*Leaf Jiang,Matthew Holzel,Bernhard Kaplan,Hsiou-Yuan Liu,Sabyasachi Paul,Karen Rankin,Piotr Swierczynski*

Main category: cs.RO

TL;DR: High-resolution stereo vision needs better calibration and faster processing; this paper introduces improved calibration/matching methods for 5MP+ cameras and a real-time evaluation approach.


<details>
  <summary>Details</summary>
Motivation: High-resolution (5MP+) stereo vision systems are crucial for robotics but require higher calibration accuracy and faster processing than conventional methods provide.

Method: Novel frame-to-frame calibration and stereo matching methodology for 5MP imagery, plus a new approach to evaluate real-time performance by comparing real-time disparity maps with ground-truth from intensive algorithms.

Result: Demonstrates that high-pixel-count cameras produce high-quality point clouds only when combined with high-accuracy calibration methods.

Conclusion: Advanced calibration and processing methods are essential to realize the full potential of high-resolution stereo vision systems in robotics applications.

Abstract: High-resolution (5MP+) stereo vision systems are essential for advancing robotic capabilities, enabling operation over longer ranges and generating significantly denser and accurate 3D point clouds. However, realizing the full potential of high-angular-resolution sensors requires a commensurately higher level of calibration accuracy and faster processing -- requirements often unmet by conventional methods. This study addresses that critical gap by processing 5MP camera imagery using a novel, advanced frame-to-frame calibration and stereo matching methodology designed to achieve both high accuracy and speed. Furthermore, we introduce a new approach to evaluate real-time performance by comparing real-time disparity maps with ground-truth disparity maps derived from more computationally intensive stereo matching algorithms. Crucially, the research demonstrates that high-pixel-count cameras yield high-quality point clouds only through the implementation of high-accuracy calibration.

</details>


### [92] [CARE: Multi-Task Pretraining for Latent Continuous Action Representation in Robot Control](https://arxiv.org/abs/2601.22467)
*Jiaqi Shi,Xulong Zhang,Xiaoyang Qu,Jianzong Wang*

Main category: cs.RO

TL;DR: CARE is a VLA framework for robot control that eliminates action supervision during pretraining, using only video-text pairs to learn latent actions, then fine-tuning with minimal labeled data for control.


<details>
  <summary>Details</summary>
Motivation: Current VLA models for robot control depend on action supervision, which limits scalability and generalization. There's a need for methods that can learn from more readily available weakly aligned data (video-text pairs) rather than requiring expensive action annotations.

Method: CARE uses only video-text pairs during pretraining to learn continuous latent action representations through a novel multi-task objective. During fine-tuning, a small set of labeled data trains the action head for control, eliminating the need for explicit action labels during pretraining.

Result: CARE achieves superior success rates across various simulation tasks, demonstrates better semantic interpretability, and avoids shortcut learning compared to existing methods that require action supervision.

Conclusion: CARE provides a scalable, interpretable, and effective approach to robotic control with weak supervision, showing that VLA models can learn effective control policies without explicit action annotations during pretraining.

Abstract: Recent advances in Vision-Language-Action (VLA) models have shown promise for robot control, but their dependence on action supervision limits scalability and generalization. To address this challenge, we introduce CARE, a novel framework designed to train VLA models for robotic task execution. Unlike existing methods that depend on action annotations during pretraining, CARE eliminates the need for explicit action labels by leveraging only video-text pairs. These weakly aligned data sources enable the model to learn continuous latent action representations through a newly designed multi-task pretraining objective. During fine-tuning, a small set of labeled data is used to train the action head for control. Experimental results across various simulation tasks demonstrate CARE's superior success rate, semantic interpretability, and ability to avoid shortcut learning. These results underscore CARE's scalability, interpretability, and effectiveness in robotic control with weak supervision.

</details>


### [93] [RoboStriker: Hierarchical Decision-Making for Autonomous Humanoid Boxing](https://arxiv.org/abs/2601.22517)
*Kangning Yin,Zhe Cao,Wentao Dong,Weishuai Zeng,Tianyi Zhang,Qiang Zhang,Jingbo Wang,Jiangmiao Pang,Ming Zhou,Weinan Zhang*

Main category: cs.RO

TL;DR: RoboStriker: A hierarchical three-stage framework for autonomous humanoid boxing that decouples high-level strategic reasoning from low-level physical execution using motion capture, latent space distillation, and multi-agent reinforcement learning.


<details>
  <summary>Details</summary>
Motivation: Humanoid robots struggle with competitive intelligence and physical agility in contact-rich dynamic tasks like boxing. Direct application of Multi-Agent Reinforcement Learning (MARL) is hindered by high-dimensional contact dynamics and lack of physical motion priors.

Method: Three-stage hierarchical framework: 1) Learn boxing skills from human motion capture data using single-agent motion tracking, 2) Distill skills into structured latent manifold with Gaussian distributions projected onto unit hypersphere for physical plausibility, 3) Latent-Space Neural Fictitious Self-Play (LS-NFSP) where agents learn competitive tactics in latent action space rather than raw motor space.

Result: RoboStriker achieves superior competitive performance in simulation and exhibits successful sim-to-real transfer, demonstrating autonomous humanoid boxing capabilities.

Conclusion: The hierarchical approach effectively addresses challenges in humanoid boxing by separating strategic reasoning from physical execution, with latent space regularization enabling stable multi-agent training and physically plausible motion generation.

Abstract: Achieving human-level competitive intelligence and physical agility in humanoid robots remains a major challenge, particularly in contact-rich and highly dynamic tasks such as boxing. While Multi-Agent Reinforcement Learning (MARL) offers a principled framework for strategic interaction, its direct application to humanoid control is hindered by high-dimensional contact dynamics and the absence of strong physical motion priors. We propose RoboStriker, a hierarchical three-stage framework that enables fully autonomous humanoid boxing by decoupling high-level strategic reasoning from low-level physical execution. The framework first learns a comprehensive repertoire of boxing skills by training a single-agent motion tracker on human motion capture data. These skills are subsequently distilled into a structured latent manifold, regularized by projecting the Gaussian-parameterized distribution onto a unit hypersphere. This topological constraint effectively confines exploration to the subspace of physically plausible motions. In the final stage, we introduce Latent-Space Neural Fictitious Self-Play (LS-NFSP), where competing agents learn competitive tactics by interacting within the latent action space rather than the raw motor space, significantly stabilizing multi-agent training. Experimental results demonstrate that RoboStriker achieves superior competitive performance in simulation and exhibits sim-to-real transfer. Our website is available at RoboStriker.

</details>


### [94] [Adapting Reinforcement Learning for Path Planning in Constrained Parking Scenarios](https://arxiv.org/abs/2601.22545)
*Feng Tao,Luca Paparusso,Chenyi Gu,Robin Koehler,Chenxu Wu,Xinyu Huang,Christian Juette,David Paz,Ren Liu*

Main category: cs.RO

TL;DR: DRL framework for real-time parking path planning outperforms classical planners by +96% success rate and +52% efficiency, with lightweight forward-pass inference suitable for real-time deployment.


<details>
  <summary>Details</summary>
Motivation: Classical path planners are computationally expensive, sensitive to perception constraints, and struggle with real-time deployment in complex constrained environments like tight parking scenarios requiring many reversal maneuvers.

Method: Deep Reinforcement Learning framework formulated as sequential decision-making problem using bicycle model dynamics, enabling direct learning of navigation policies respecting vehicle kinematics and environmental constraints in closed-loop setting.

Result: Achieves state-of-the-art performance with +96% higher success rate and +52% higher efficiency compared to classical planner baselines, with lightweight single forward-pass inference at test time.

Conclusion: DRL-based approach provides practical real-time path planning solution for constrained parking scenarios, eliminating need for ideal perception and additional modules like localization/tracking, with open-source benchmark released for community research.

Abstract: Real-time path planning in constrained environments remains a fundamental challenge for autonomous systems. Traditional classical planners, while effective under perfect perception assumptions, are often sensitive to real-world perception constraints and rely on online search procedures that incur high computational costs. In complex surroundings, this renders real-time deployment prohibitive. To overcome these limitations, we introduce a Deep Reinforcement Learning (DRL) framework for real-time path planning in parking scenarios. In particular, we focus on challenging scenes with tight spaces that require a high number of reversal maneuvers and adjustments. Unlike classical planners, our solution does not require ideal and structured perception, and in principle, could avoid the need for additional modules such as localization and tracking, resulting in a simpler and more practical implementation. Also, at test time, the policy generates actions through a single forward pass at each step, which is lightweight enough for real-time deployment. The task is formulated as a sequential decision-making problem grounded in a bicycle model dynamics, enabling the agent to directly learn navigation policies that respect vehicle kinematics and environmental constraints in the closed-loop setting. A new benchmark is developed to support both training and evaluation, capturing diverse and challenging scenarios. Our approach achieves state-of-the-art success rates and efficiency, surpassing classical planner baselines by +96% in success rate and +52% in efficiency. Furthermore, we release our benchmark as an open-source resource for the community to foster future research in autonomous systems. The benchmark and accompanying tools are available at https://github.com/dqm5rtfg9b-collab/Constrained_Parking_Scenarios.

</details>


### [95] [Exo-Plore: Exploring Exoskeleton Control Space through Human-aligned Simulation](https://arxiv.org/abs/2601.22550)
*Geonho Leem,Jaedong Lee,Jehee Lee,Seungmoon Song,Jungdam Won*

Main category: cs.RO

TL;DR: Exo-plore: A simulation framework using neuromechanical simulation and deep RL to optimize hip exoskeleton assistance without real human experiments.


<details>
  <summary>Details</summary>
Motivation: Current exoskeleton optimization requires extensive human experiments that exclude those who need assistance most (people with mobility impairments), creating a paradox in assistive technology development.

Method: Combines neuromechanical simulation with deep reinforcement learning to optimize hip exoskeleton assistance, generating realistic gait data that captures human adaptation to assistive forces.

Result: Framework can generate realistic gait data, produce reliable optimization despite gait stochasticity, and generalize to pathological gaits with strong linear relationships between pathology severity and optimal assistance.

Conclusion: Exo-plore enables exoskeleton optimization without demanding human experiments, making assistive technology development more accessible to those who need it most.

Abstract: Exoskeletons show great promise for enhancing mobility, but providing appropriate assistance remains challenging due to the complexity of human adaptation to external forces. Current state-of-the-art approaches for optimizing exoskeleton controllers require extensive human experiments in which participants must walk for hours, creating a paradox: those who could benefit most from exoskeleton assistance, such as individuals with mobility impairments, are rarely able to participate in such demanding procedures. We present Exo-plore, a simulation framework that combines neuromechanical simulation with deep reinforcement learning to optimize hip exoskeleton assistance without requiring real human experiments. Exo-plore can (1) generate realistic gait data that captures human adaptation to assistive forces, (2) produce reliable optimization results despite the stochastic nature of human gait, and (3) generalize to pathological gaits, showing strong linear relationships between pathology severity and optimal assistance.

</details>


### [96] [Postural Virtual Fixtures for Ergonomic Physical Interactions with Supernumerary Robotic Bodies](https://arxiv.org/abs/2601.22672)
*Theodora Kastritsi,Marta Lagomarsino,Arash Ajoudani*

Main category: cs.RO

TL;DR: A control framework for supernumerary robotic bodies that provides kinesthetic feedback to discourage non-ergonomic postures during human-robot physical interaction.


<details>
  <summary>Details</summary>
Motivation: Supernumerary robotic bodies can enhance human load tolerance, but users may still adopt awkward, non-ergonomic postures during physical interaction tasks, which can lead to discomfort or injury over time.

Method: A novel control framework using virtual fixtures integrated with continuous online ergonomic posture assessment, providing kinesthetic feedback resistance when non-ergonomic postures are detected. Also includes floating base position adjustment for better operator-SRB coordination.

Result: Experimental results demonstrate functionality and efficacy through two user studies with 14 subjects performing practical loco-manipulation tasks, comparing against a baseline control framework without ergonomic considerations.

Conclusion: The proposed ergonomics-driven control framework successfully discourages non-ergonomic behaviors and promotes proper posture during physical human-robot interaction, aiming to foster long-term learning of ergonomic habits.

Abstract: Conjoined collaborative robots, functioning as supernumerary robotic bodies (SRBs), can enhance human load tolerance abilities. However, in tasks involving physical interaction with humans, users may still adopt awkward, non-ergonomic postures, which can lead to discomfort or injury over time. In this paper, we propose a novel control framework that provides kinesthetic feedback to SRB users when a non-ergonomic posture is detected, offering resistance to discourage such behaviors. This approach aims to foster long-term learning of ergonomic habits and promote proper posture during physical interactions. To achieve this, a virtual fixture method is developed, integrated with a continuous, online ergonomic posture assessment framework. Additionally, to improve coordination between the operator and the SRB, which consists of a robotic arm mounted on a floating base, the position of the floating base is adjusted as needed. Experimental results demonstrate the functionality and efficacy of the ergonomics-driven control framework, including two user studies involving practical loco-manipulation tasks with 14 subjects, comparing the proposed framework with a baseline control framework that does not account for human ergonomics.

</details>


### [97] [FlyAware: Inertia-Aware Aerial Manipulation via Vision-Based Estimation and Post-Grasp Adaptation](https://arxiv.org/abs/2601.22686)
*Biyu Ye,Na Fan,Zhengping Fan,Weiliang Deng,Hongming Chen,Qifeng Chen,Ximin Lyu*

Main category: cs.RO

TL;DR: Aerial manipulators need robust control for varying payloads; new framework combines pre-grasp inertia estimation with post-grasp adaptation using gain scheduling control.


<details>
  <summary>Details</summary>
Motivation: Aerial manipulators have superior dexterity for transportation/emergency services but face practical deployment challenges due to time-varying inertial parameters that are sensitive to payload variations and manipulator configurations.

Method: Proposes an onboard framework integrating vision-based pre-grasp inertia estimation with post-grasp adaptation mechanism, using inertia-aware adaptive control based on gain scheduling, with robustness assessed via frequency-domain system identification.

Result: Real-world experiments validate the effectiveness and feasibility of the proposed framework, providing new insights into post-grasp control for aerial manipulators.

Conclusion: The integrated framework enables robust aerial manipulation through real-time estimation and adaptation of inertial dynamics, addressing key challenges in practical deployment of aerial manipulators with varying payloads.

Abstract: Aerial manipulators (AMs) are gaining increasing attention in automated transportation and emergency services due to their superior dexterity compared to conventional multirotor drones. However, their practical deployment is challenged by the complexity of time-varying inertial parameters, which are highly sensitive to payload variations and manipulator configurations. Inspired by human strategies for interacting with unknown objects, this letter presents a novel onboard framework for robust aerial manipulation. The proposed system integrates a vision-based pre-grasp inertia estimation module with a post-grasp adaptation mechanism, enabling real-time estimation and adaptation of inertial dynamics. For control, we develop an inertia-aware adaptive control strategy based on gain scheduling, and assess its robustness via frequency-domain system identification. Our study provides new insights into post-grasp control for AMs, and real-world experiments validate the effectiveness and feasibility of the proposed framework.

</details>


### [98] [Robust Rigid Body Assembly via Contact-Implicit Optimal Control with Exact Second-Order Derivatives](https://arxiv.org/abs/2601.22849)
*Christian Dietz,Sebastian Albrecht,Gianluca Frison,Moritz Diehl,Armin Nurkanović*

Main category: cs.RO

TL;DR: Differentiable physics simulation with second-order derivatives enables sample-efficient robust optimal control for assembly motions, achieving over 99% success in real-world peg-in-hole tasks.


<details>
  <summary>Details</summary>
Motivation: Traditional assembly motion planning requires extensive physics simulations through RL or sampling-based methods, which is computationally expensive. The paper aims to develop a more sample-efficient approach using derivative information.

Method: Constructs a differentiable physics simulation with second-order analytic derivatives using smoothing inspired by interior-point methods for collision detection and contact resolution. Proposes modified optimization-based collision detection as a linear program and implements efficient first- and second-order derivatives. Uses multi-scenario trajectory optimization for robustness against sim-to-real mismatches.

Result: Achieves over 99% successful executions in real-world experiments. Shows benefits of exact Hessians over approximations in various peg-in-hole problems. Investigates effects of smooth contact approximations and robust modeling on success rates.

Conclusion: The differentiable physics simulation with second-order derivatives enables sample-efficient robust optimal control for assembly motions, significantly reducing required simulation steps while maintaining high real-world success rates.

Abstract: Efficient planning of assembly motions is a long standing challenge in the field of robotics that has been primarily tackled with reinforcement learning and sampling-based methods by using extensive physics simulations. This paper proposes a sample-efficient robust optimal control approach for the determination of assembly motions, which requires significantly less physics simulation steps during planning through the efficient use of derivative information. To this end, a differentiable physics simulation is constructed that provides second-order analytic derivatives to the numerical solver and allows one to traverse seamlessly from informative derivatives to accurate contact simulation. The solution of the physics simulation problem is made differentiable by using smoothing inspired by interior-point methods applied to both the collision detection as well as the contact resolution problem. We propose a modified variant of an optimization-based formulation of collision detection formulated as a linear program and present an efficient implementation for the nominal evaluation and corresponding first- and second-order derivatives. Moreover, a multi-scenario-based trajectory optimization problem that ensures robustness with respect to sim-to-real mismatches is derived. The capability of the considered formulation is illustrated by results where over 99\% successful executions are achieved in real-world experiments. Thereby, we carefully investigate the effect of smooth approximations of the contact dynamics and robust modeling on the success rates. Furthermore, the method's capability is tested on different peg-in-hole problems in simulation to show the benefit of using exact Hessians over commonly used Hessian approximations.

</details>


### [99] [Toward Fully Autonomous Driving: AI, Challenges, Opportunities, and Needs](https://arxiv.org/abs/2601.22927)
*Lars Ullrich,Michael Buchholz,Klaus Dietmayer,Knut Graichen*

Main category: cs.RO

TL;DR: AI shows promise for advancing autonomous driving but faces safety and transferability challenges that need addressing for full autonomy.


<details>
  <summary>Details</summary>
Motivation: To understand how AI can overcome classical approaches in autonomous driving while addressing safety and transferability concerns in real-world applications.

Method: Analysis of current autonomous driving state, identification of limitations, and examination of foreseeable technological possibilities in the context of AI advancements.

Result: AI demonstrates ability to handle higher complexities and reach new autonomy levels, but raises safety and transferability questions that require further research.

Conclusion: The paper reconsiders fully autonomous driving in light of AI advancements and identifies specific needs and research questions for achieving safe, transferable autonomous systems.

Abstract: Automated driving (AD) is promising, but the transition to fully autonomous driving is, among other things, subject to the real, ever-changing open world and the resulting challenges. However, research in the field of AD demonstrates the ability of artificial intelligence (AI) to outperform classical approaches, handle higher complexities, and reach a new level of autonomy. At the same time, the use of AI raises further questions of safety and transferability. To identify the challenges and opportunities arising from AI concerning autonomous driving functionalities, we have analyzed the current state of AD, outlined limitations, and identified foreseeable technological possibilities. Thereby, various further challenges are examined in the context of prospective developments. In this way, this article reconsiders fully autonomous driving with respect to advancements in the field of AI and carves out the respective needs and resulting research questions.

</details>


### [100] [MTDrive: Multi-turn Interactive Reinforcement Learning for Autonomous Driving](https://arxiv.org/abs/2601.22930)
*Xidong Li,Mingyu Guo,Chenchao Xu,Bailin Li,Wenjing Zhu,Yangang Zou,Rui Chen,Zehuan Wang*

Main category: cs.RO

TL;DR: MTDrive: A multi-turn framework combining MLLMs with RL for iterative trajectory refinement in autonomous driving, using mtGRPO to address reward sparsity and achieving superior performance on NAVSIM benchmark.


<details>
  <summary>Details</summary>
Motivation: Existing MLLM+RL methods for autonomous driving trajectory planning are limited to single-turn reasoning, which restricts their ability to handle complex scenarios requiring iterative refinement. Current approaches struggle with long-tail scenarios and lack the capability for progressive improvement based on environmental feedback.

Method: MTDrive introduces a multi-turn framework where MLLMs iteratively refine trajectories based on environmental feedback. The method includes Multi-Turn Group Relative Policy Optimization (mtGRPO) to mitigate reward sparsity by computing relative advantages across turns. The authors also construct an interactive trajectory understanding dataset from closed-loop simulation and implement system-level optimizations to reduce data transfer overhead.

Result: Experiments on the NAVSIM benchmark demonstrate superior performance compared to existing methods. The framework achieves 2.5x training throughput through system-level optimizations that reduce data transfer overhead from high-resolution images and multi-turn sequences.

Conclusion: MTDrive validates the effectiveness of multi-turn reasoning paradigms for autonomous driving trajectory planning, showing that iterative refinement with MLLMs and RL can better handle complex scenarios. The approach addresses limitations of single-turn methods and provides a scalable framework with practical system optimizations.

Abstract: Trajectory planning is a core task in autonomous driving, requiring the prediction of safe and comfortable paths across diverse scenarios. Integrating Multi-modal Large Language Models (MLLMs) with Reinforcement Learning (RL) has shown promise in addressing "long-tail" scenarios. However, existing methods are constrained to single-turn reasoning, limiting their ability to handle complex tasks requiring iterative refinement. To overcome this limitation, we present MTDrive, a multi-turn framework that enables MLLMs to iteratively refine trajectories based on environmental feedback. MTDrive introduces Multi-Turn Group Relative Policy Optimization (mtGRPO), which mitigates reward sparsity by computing relative advantages across turns. We further construct an interactive trajectory understanding dataset from closed-loop simulation to support multi-turn training. Experiments on the NAVSIM benchmark demonstrate superior performance compared to existing methods, validating the effectiveness of our multi-turn reasoning paradigm. Additionally, we implement system-level optimizations to reduce data transfer overhead caused by high-resolution images and multi-turn sequences, achieving 2.5x training throughput. Our data, models, and code will be made available soon.

</details>


### [101] [Self-Imitated Diffusion Policy for Efficient and Robust Visual Navigation](https://arxiv.org/abs/2601.22965)
*Runhua Zhang,Junyi Hou,Changxu Cheng,Qiyi Chen,Tao Wang,Wuyue Zhao*

Main category: cs.RO

TL;DR: SIDP is a self-imitation diffusion policy framework that improves visual navigation by selectively imitating its own high-quality trajectories, eliminating the need for post-filtering and enabling faster, more efficient real-time deployment.


<details>
  <summary>Details</summary>
Motivation: Standard diffusion policies trained via imitation learning inherit sub-optimality from expert demonstrations, requiring computationally intensive "generate-then-filter" pipelines with auxiliary selectors during inference.

Method: Introduces reward-guided self-imitation mechanism that encourages consistent high-quality trajectory generation, reward-driven curriculum learning for efficient data utility, and goal-agnostic exploration for trajectory augmentation.

Result: Significantly outperforms previous methods in simulation benchmarks, achieves 2.5× faster inference than baseline NavDP (110ms vs 273ms) on Jetson Orin Nano, and demonstrates effectiveness across multiple robotic platforms in real-world experiments.

Conclusion: SIDP provides an efficient framework for visual navigation that reduces reliance on extensive sampling and post-filtering while enabling real-time deployment through improved planning quality and inference speed.

Abstract: Diffusion policies (DP) have demonstrated significant potential in visual navigation by capturing diverse multi-modal trajectory distributions. However, standard imitation learning (IL), which most DP methods rely on for training, often inherits sub-optimality and redundancy from expert demonstrations, thereby necessitating a computationally intensive "generate-then-filter" pipeline that relies on auxiliary selectors during inference. To address these challenges, we propose Self-Imitated Diffusion Policy (SIDP), a novel framework that learns improved planning by selectively imitating a set of trajectories sampled from itself. Specifically, SIDP introduces a reward-guided self-imitation mechanism that encourages the policy to consistently produce high-quality trajectories efficiently, rather than outputs of inconsistent quality, thereby reducing reliance on extensive sampling and post-filtering. During training, we employ a reward-driven curriculum learning paradigm to mitigate inefficient data utility, and goal-agnostic exploration for trajectory augmentation to improve planning robustness. Extensive evaluations on a comprehensive simulation benchmark show that SIDP significantly outperforms previous methods, with real-world experiments confirming its effectiveness across multiple robotic platforms. On Jetson Orin Nano, SIDP delivers a 2.5$\times$ faster inference than the baseline NavDP, i.e., 110ms VS 273ms, enabling efficient real-time deployment.

</details>


### [102] [Learning Geometrically-Grounded 3D Visual Representations for View-Generalizable Robotic Manipulation](https://arxiv.org/abs/2601.22988)
*Di Zhang,Weicheng Duan,Dasen Gu,Hongye Lu,Hai Zhang,Hang Yu,Junqiao Zhao,Guang Chen*

Main category: cs.RO

TL;DR: MethodName: A unified representation-policy learning framework for view-generalizable robotic manipulation that learns holistic 3D geometric representations from single-view inputs and transfers them to manipulation skills via multi-step distillation.


<details>
  <summary>Details</summary>
Motivation: Real-world robotic manipulation requires visuomotor policies with robust spatial understanding and strong generalization across diverse camera viewpoints. Current 3D-aware visual representations have limitations: they rely on multi-view observations during inference (impractical for single-view scenarios), have incomplete scene modeling that fails to capture holistic and fine-grained geometric structures, and lack effective policy training strategies to retain and exploit 3D knowledge.

Method: MethodName introduces a single-view 3D pretraining paradigm using point cloud reconstruction and feed-forward Gaussian splatting under multi-view supervision to learn holistic geometric representations. During policy learning, it performs multi-step distillation to preserve pretrained geometric understanding and effectively transfer it to manipulation skills.

Result: On 12 RLBench tasks, MethodName outperforms previous state-of-the-art by 12.7% in average success rate. For zero-shot view generalization on six representative tasks, it shows only 22.0% and 29.7% success rate drops under moderate and large viewpoint shifts, compared to 41.6% and 51.5% drops for the state-of-the-art method.

Conclusion: MethodName addresses key limitations in 3D-aware visual representations for robotic manipulation by providing a unified framework that learns holistic geometric understanding from single-view inputs and effectively transfers this knowledge to manipulation policies, achieving superior performance and strong view generalization capabilities.

Abstract: Real-world robotic manipulation demands visuomotor policies capable of robust spatial scene understanding and strong generalization across diverse camera viewpoints. While recent advances in 3D-aware visual representations have shown promise, they still suffer from several key limitations, including reliance on multi-view observations during inference which is impractical in single-view restricted scenarios, incomplete scene modeling that fails to capture holistic and fine-grained geometric structures essential for precise manipulation, and lack of effective policy training strategies to retain and exploit the acquired 3D knowledge. To address these challenges, we present MethodName, a unified representation-policy learning framework for view-generalizable robotic manipulation. MethodName introduces a single-view 3D pretraining paradigm that leverages point cloud reconstruction and feed-forward gaussian splatting under multi-view supervision to learn holistic geometric representations. During policy learning, MethodName performs multi-step distillation to preserve the pretrained geometric understanding and effectively transfer it to manipulation skills. We conduct experiments on 12 RLBench tasks, where our approach outperforms the previous state-of-the-art method by 12.7% in average success rate. Further evaluation on six representative tasks demonstrates strong zero-shot view generalization, with success rate drops of only 22.0% and 29.7% under moderate and large viewpoint shifts respectively, whereas the state-of-the-art method suffers larger decreases of 41.6% and 51.5%.

</details>


### [103] [MOSAIC: Modular Scalable Autonomy for Intelligent Coordination of Heterogeneous Robotic Teams](https://arxiv.org/abs/2601.23038)
*David Oberacker,Julia Richer,Philip Arm,Marvin Grosse Besselmann,Lennart Puck,William Talbot,Maximilian Schik,Sabine Bellmann,Tristan Schnell,Hendrik Kolvenbach,Rüdiger Dillmann,Marco Hutter,Arne Roennau*

Main category: cs.RO

TL;DR: MOSAIC is a scalable autonomy framework for multi-robot scientific exploration that uses Points of Interest and layered autonomy to enable single-operator supervision of heterogeneous robot teams.


<details>
  <summary>Details</summary>
Motivation: Current mobile robots in hostile environments like space or disaster relief are limited to teleoperation, requiring near-continuous low-latency communication and restricting deployment scale. There's a need for scalable autonomy that reduces operator burden while maintaining mission effectiveness.

Method: MOSAIC uses a unified mission abstraction based on Points of Interest (POIs) with multiple layers of autonomy. It dynamically allocates exploration and measurement tasks based on each robot's capabilities, leveraging team-level redundancy and specialization for continuous operation.

Result: In a space-analog lunar prospecting experiment with 5 heterogeneous robots and one operator, the team completed 82.3% of assigned tasks at 86% Autonomy Ratio, despite one robot failure. Operator workload remained at only 78.2%.

Conclusion: MOSAIC enables robust, scalable multi-robot scientific exploration with limited operator intervention. The framework provides practical lessons for robot interoperability, networking, team composition, and workload management for future missions.

Abstract: Mobile robots have become indispensable for exploring hostile environments, such as in space or disaster relief scenarios, but often remain limited to teleoperation by a human operator. This restricts the deployment scale and requires near-continuous low-latency communication between the operator and the robot. We present MOSAIC: a scalable autonomy framework for multi-robot scientific exploration using a unified mission abstraction based on Points of Interest (POIs) and multiple layers of autonomy, enabling supervision by a single operator. The framework dynamically allocates exploration and measurement tasks based on each robot's capabilities, leveraging team-level redundancy and specialization to enable continuous operation. We validated the framework in a space-analog field experiment emulating a lunar prospecting scenario, involving a heterogeneous team of five robots and a single operator. Despite the complete failure of one robot during the mission, the team completed 82.3% of assigned tasks at an Autonomy Ratio of 86%, while the operator workload remained at only 78.2%. These results demonstrate that the proposed framework enables robust, scalable multi-robot scientific exploration with limited operator intervention. We further derive practical lessons learned in robot interoperability, networking architecture, team composition, and operator workload management to inform future multi-robot exploration missions.

</details>


### [104] [Robust and Generalized Humanoid Motion Tracking](https://arxiv.org/abs/2601.23080)
*Yubiao Ma,Han Yu,Jiayin Xie,Changtai Lv,Qiang Luo,Chi Zhang,Yunpeng Yin,Boyang Xing,Xuemei Ren,Dongdong Zheng*

Main category: cs.RO

TL;DR: A dynamics-conditioned command aggregation framework for humanoid whole-body control that uses causal temporal encoding and cross-attention to handle noisy reference motions, with fall recovery curriculum for robustness.


<details>
  <summary>Details</summary>
Motivation: Learning general humanoid controllers is challenging due to noise/inconsistencies in transferred reference motions and amplification of local defects in closed-loop execution, causing drift/failure in dynamic, contact-rich behaviors.

Method: Proposes dynamics-conditioned command aggregation with causal temporal encoder for recent proprioception summary and multi-head cross-attention command encoder for selective context aggregation. Integrates fall recovery curriculum with random unstable initialization and annealed upward assistance force.

Result: Policy requires only ~3.5 hours of motion data, supports single-stage end-to-end training without distillation. Demonstrates zero-shot transfer to unseen motions and robust sim-to-real transfer on physical humanoid robot.

Conclusion: The framework effectively handles noisy reference motions and enables robust humanoid whole-body control with minimal data requirements and successful real-world deployment.

Abstract: Learning a general humanoid whole-body controller is challenging because practical reference motions can exhibit noise and inconsistencies after being transferred to the robot domain, and local defects may be amplified by closed-loop execution, causing drift or failure in highly dynamic and contact-rich behaviors. We propose a dynamics-conditioned command aggregation framework that uses a causal temporal encoder to summarize recent proprioception and a multi-head cross-attention command encoder to selectively aggregate a context window based on the current dynamics. We further integrate a fall recovery curriculum with random unstable initialization and an annealed upward assistance force to improve robustness and disturbance rejection. The resulting policy requires only about 3.5 hours of motion data and supports single-stage end-to-end training without distillation. The proposed method is evaluated under diverse reference inputs and challenging motion regimes, demonstrating zero-shot transfer to unseen motions as well as robust sim-to-real transfer on a physical humanoid robot.

</details>


### [105] [Temporally Coherent Imitation Learning via Latent Action Flow Matching for Robotic Manipulation](https://arxiv.org/abs/2601.23087)
*Wu Songwei,Jiang Zhiduo,Xie Guanghu,Liu Yang,Liu Hong*

Main category: cs.RO

TL;DR: LG-Flow Policy is a trajectory-level imitation learning framework that uses flow matching in a continuous latent action space to achieve fast inference and stable execution for long-horizon robotic manipulation.


<details>
  <summary>Details</summary>
Motivation: Existing generative policies struggle to balance expressive modeling, real-time inference, and stable execution for long-horizon robotic manipulation. Diffusion models have high latency, while flow matching in raw action space leads to unstable execution.

Method: Encodes action sequences into temporally regularized latent trajectories, learns explicit latent-space flow matching, incorporates geometry-aware point cloud conditioning, and uses execution-time multimodal modulation with visual cues.

Result: Achieves near single-step inference, substantially improves trajectory smoothness and task success over flow-based baselines in raw action space, and remains significantly more efficient than diffusion-based policies in simulation and physical robot experiments.

Conclusion: LG-Flow Policy successfully decouples global motion structure from low-level control noise, enabling smooth and reliable long-horizon robotic manipulation with fast inference and stable execution.

Abstract: Learning long-horizon robotic manipulation requires jointly achieving expressive behavior modeling, real-time inference, and stable execution, which remains challenging for existing generative policies. Diffusion-based approaches provide strong modeling capacity but typically incur high inference latency, while flow matching enables fast one-step generation yet often leads to unstable execution when applied directly in the raw action space.
  We propose LG-Flow Policy, a trajectory-level imitation learning framework that performs flow matching in a continuous latent action space. By encoding action sequences into temporally regularized latent trajectories and learning an explicit latent-space flow, the proposed approach decouples global motion structure from low-level control noise, resulting in smooth and reliable long-horizon execution.
  LG-Flow Policy further incorporates geometry-aware point cloud conditioning and execution-time multimodal modulation, with visual cues evaluated as a representative modality in real-world settings. Experimental results in simulation and on physical robot platforms demonstrate that LG-Flow Policy achieves near single-step inference, substantially improves trajectory smoothness and task success over flow-based baselines operating in the raw action space, and remains significantly more efficient than diffusion-based policies.

</details>


### [106] [IRL-DAL: Safe and Adaptive Trajectory Planning for Autonomous Driving via Energy-Guided Diffusion Models](https://arxiv.org/abs/2601.23266)
*Seyed Ahmad Hosseini Miangoleh,Amin Jalal Aghdasian,Farzaneh Abdollahi*

Main category: cs.RO

TL;DR: IRL-DAL: A diffusion-based inverse reinforcement learning framework for autonomous vehicles that combines imitation learning, IRL, and safety-supervised planning to achieve expert-level safe navigation.


<details>
  <summary>Details</summary>
Motivation: To develop a robust autonomous driving system that can safely navigate complex environments while aligning with expert driving behaviors, particularly in handling unsafe conditions and maintaining lane discipline.

Method: Combines FSM-based imitation learning for initialization, IRL with discriminator signals for expert goal alignment, RL with hybrid rewards, conditional diffusion model for safety-supervised path planning, and learnable adaptive mask for perception enhancement, fine-tuned with PPO in Webots simulator.

Result: Achieves 96% success rate, reduces collisions to 0.05 per 1k steps, sets new benchmark for safe navigation, and demonstrates expert-level handling of unsafe conditions while maintaining lane discipline.

Conclusion: The proposed IRL-DAL framework effectively combines multiple learning approaches to create a robust autonomous driving system that achieves expert-level performance in safe navigation, with publicly available code for reproducibility.

Abstract: This paper proposes a novel inverse reinforcement learning framework using a diffusion-based adaptive lookahead planner (IRL-DAL) for autonomous vehicles. Training begins with imitation from an expert finite state machine (FSM) controller to provide a stable initialization. Environment terms are combined with an IRL discriminator signal to align with expert goals. Reinforcement learning (RL) is then performed with a hybrid reward that combines diffuse environmental feedback and targeted IRL rewards. A conditional diffusion model, which acts as a safety supervisor, plans safe paths. It stays in its lane, avoids obstacles, and moves smoothly. Then, a learnable adaptive mask (LAM) improves perception. It shifts visual attention based on vehicle speed and nearby hazards. After FSM-based imitation, the policy is fine-tuned with Proximal Policy Optimization (PPO). Training is run in the Webots simulator with a two-stage curriculum. A 96\% success rate is reached, and collisions are reduced to 0.05 per 1k steps, marking a new benchmark for safe navigation. By applying the proposed approach, the agent not only drives in lane but also handles unsafe conditions at an expert level, increasing robustness.We make our code publicly available.

</details>


### [107] [End-to-end Optimization of Belief and Policy Learning in Shared Autonomy Paradigms](https://arxiv.org/abs/2601.23285)
*MH Farhadi,Ali Rabiee,Sima Ghafoori,Anna Cetera,Andrew Fisher,Reza Abiri*

Main category: cs.RO

TL;DR: BRACE is a new shared autonomy framework that integrates Bayesian intent inference with context-adaptive assistance through end-to-end gradient flow, outperforming state-of-the-art methods in success rates and path efficiency.


<details>
  <summary>Details</summary>
Motivation: Shared autonomy systems need better methods for inferring user intent and determining appropriate assistance levels while respecting user agency. Previous approaches used static blending or separated goal inference from assistance arbitration, leading to suboptimal performance in unstructured environments.

Method: BRACE (Bayesian Reinforcement Assistance with Context Encoding) fine-tunes Bayesian intent inference and context-adaptive assistance through an architecture enabling end-to-end gradient flow between intent inference and assistance arbitration. The pipeline conditions collaborative control policies on environmental context and complete goal probability distributions.

Result: BRACE achieved 6.3% higher success rates and 41% increased path efficiency over SOTA methods (IDA, DQN), and 36.3% success rate and 87% path efficiency improvement over unassisted control. The framework was validated across three evaluation scenarios: 2D cursor task, robotic arm dynamics, and integrated manipulation under goal ambiguity.

Conclusion: Integrated optimization of intent inference and assistance arbitration is most beneficial in complex, goal-ambiguous scenarios and generalizes across robotic domains requiring goal-directed assistance, advancing the state-of-the-art for adaptive shared autonomy.

Abstract: Shared autonomy systems require principled methods for inferring user intent and determining appropriate assistance levels. This is a central challenge in human-robot interaction, where systems must be successful while being mindful of user agency. Previous approaches relied on static blending ratios or separated goal inference from assistance arbitration, leading to suboptimal performance in unstructured environments. We introduce BRACE (Bayesian Reinforcement Assistance with Context Encoding), a novel framework that fine-tunes Bayesian intent inference and context-adaptive assistance through an architecture enabling end-to-end gradient flow between intent inference and assistance arbitration. Our pipeline conditions collaborative control policies on environmental context and complete goal probability distributions. We provide analysis showing (1) optimal assistance levels should decrease with goal uncertainty and increase with environmental constraint severity, and (2) integrating belief information into policy learning yields a quadratic expected regret advantage over sequential approaches. We validated our algorithm against SOTA methods (IDA, DQN) using a three-part evaluation progressively isolating distinct challenges of end-effector control: (1) core human-interaction dynamics in a 2D human-in-the-loop cursor task, (2) non-linear dynamics of a robotic arm, and (3) integrated manipulation under goal ambiguity and environmental constraints. We demonstrate improvements over SOTA, achieving 6.3% higher success rates and 41% increased path efficiency, and 36.3% success rate and 87% path efficiency improvement over unassisted control. Our results confirmed that integrated optimization is most beneficial in complex, goal-ambiguous scenarios, and is generalizable across robotic domains requiring goal-directed assistance, advancing the SOTA for adaptive shared autonomy.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [108] [JAF: Judge Agent Forest](https://arxiv.org/abs/2601.22269)
*Sahil Garg,Brad Cheezum,Sridhar Dutta,Vishal Agarwal*

Main category: cs.AI

TL;DR: JAF (Judge Agent Forest) is a framework where judge agents evaluate multiple query-response pairs collectively rather than individually, enabling holistic learning and iterative improvement of primary agents through cross-instance pattern recognition.


<details>
  <summary>Details</summary>
Motivation: Current judge agents evaluate query-response pairs in isolation, missing opportunities to learn from cross-instance patterns and inconsistencies. This limits their ability to provide holistic feedback for iterative self-refinement of reasoning processes.

Method: JAF uses joint inference across cohorts of query-response pairs, creating overlapping in-context neighborhoods that form a knowledge-graph structure for critique propagation. It employs a flexible LSH algorithm that integrates semantic embeddings, LLM-driven hash predicates, categorical supervision, and side information to select diverse exemplars efficiently.

Result: The framework enables judge agents to transition from local evaluators to holistic learners, supporting efficient, interpretable, and relation-aware exemplar selection while optimizing exploration of chain-of-thought reasoning paths.

Conclusion: JAF bridges belief propagation and ensemble-learning principles, providing a scalable approach for automated evaluation and iterative self-refinement in agentic AI frameworks, validated through empirical study on cloud misconfiguration triage tasks.

Abstract: Judge agents are fundamental to agentic AI frameworks: they provide automated evaluation, and enable iterative self-refinement of reasoning processes. We introduce JAF: Judge Agent Forest, a framework in which the judge agent conducts joint inference across a cohort of query--response pairs generated by a primary agent, rather than evaluating each in isolation. This paradigm elevates the judge from a local evaluator to a holistic learner: by simultaneously assessing related responses, the judge discerns cross-instance patterns and inconsistencies, whose aggregate feedback enables the primary agent to improve by viewing its own outputs through the judge's collective perspective.
  Conceptually, JAF bridges belief propagation and ensemble-learning principles: overlapping in-context neighborhoods induce a knowledge-graph structure that facilitates propagation of critique, and repeated, randomized evaluations yield a robust ensemble of context-sensitive judgments. JAF can be instantiated entirely via ICL, with the judge prompted for each query using its associated primary-agent response plus a small, possibly noisy set of peer exemplars. While kNN in embedding space is a natural starting point for exemplars, this approach overlooks categorical structure, domain metadata, or nuanced distinctions accessible to modern LLMs.
  To overcome these limitations, we develop a flexible locality-sensitive hashing (LSH) algorithm that learns informative binary codes by integrating semantic embeddings, LLM-driven hash predicates, supervision from categorical labels, and relevant side information. These hash codes support efficient, interpretable, and relation-aware selection of diverse exemplars, and further optimize exploration of CoT reasoning paths. We validate JAF with an empirical study on the demanding task of cloud misconfigs triage in large-scale cloud environments.

</details>


### [109] [The Six Sigma Agent: Achieving Enterprise-Grade Reliability in LLM Systems Through Consensus-Driven Decomposed Execution](https://arxiv.org/abs/2601.22290)
*Khush Patel,Siva Surendira,Jithin George,Shreyas Kapale*

Main category: cs.AI

TL;DR: Six Sigma Agent architecture achieves enterprise-grade AI reliability through task decomposition, parallel micro-agent sampling, and consensus voting, reducing error rates exponentially while cutting costs.


<details>
  <summary>Details</summary>
Motivation: LLMs have reliability challenges for enterprise deployment due to their probabilistic nature, requiring solutions that go beyond model scaling to achieve consistent, dependable performance.

Method: Three-component architecture: (1) task decomposition into dependency tree of atomic actions, (2) micro-agent sampling executing each task n times in parallel across diverse LLMs, (3) consensus voting with dynamic scaling that clusters outputs and selects answer from winning cluster.

Result: Exponential reliability gains: sampling n independent outputs with error rate p achieves system error O(p^{ceil(n/2)}). With 5% per-action error, 5 agents reduce error to 0.11%; 13 agents achieve 3.4 DPMO (Six Sigma standard). 14,700x reliability improvement over single-agent execution with 80% cost reduction.

Conclusion: Enterprise AI reliability emerges from principled redundancy and consensus rather than model scaling alone, enabling dependable deployment through systematic architecture design.

Abstract: Large Language Models demonstrate remarkable capabilities yet remain fundamentally probabilistic, presenting critical reliability challenges for enterprise deployment. We introduce the Six Sigma Agent, a novel architecture that achieves enterprise-grade reliability through three synergistic components: (1) task decomposition into a dependency tree of atomic actions; (2) micro-agent sampling where each task is executed n times in parallel across diverse LLMs to generate independent outputs; and (3) consensus voting with dynamic scaling, clustering outputs and selecting the answer from the winning cluster with maximum votes. We prove that sampling n independent outputs with error rate p achieves system error O(p^{ceil(n/2)}), enabling exponential reliability gains. Even using cheaper models with 5% per-action error, consensus voting with 5 agents reduces error to 0.11%; dynamic scaling to 13 agents achieves 3.4 DPMO (Defects Per Million Opportunities), the Six Sigma standard. Evaluation across three enterprise use cases demonstrates a 14,700x reliability improvement over single-agent execution while reducing costs by 80%. Our work establishes that reliability in AI systems emerges from principled redundancy and consensus rather than model scaling alone.

</details>


### [110] [Why Reasoning Fails to Plan: A Planning-Centric Analysis of Long-Horizon Decision Making in LLM Agents](https://arxiv.org/abs/2601.22311)
*Zehong Wang,Fang Wu,Hongru Wang,Xiangru Tang,Bolian Li,Zhenfei Yin,Yijun Ma,Yiyang Li,Weixiang Sun,Xiusi Chen,Yanfang Ye*

Main category: cs.AI

TL;DR: FLARE improves LLM-based agents' long-horizon planning by adding future-aware lookahead to overcome myopic step-by-step reasoning failures.


<details>
  <summary>Details</summary>
Motivation: LLM-based agents fail at long-horizon planning because step-by-step reasoning induces greedy policies that don't account for delayed consequences, creating myopic commitments that amplify over time.

Method: FLARE (Future-aware Lookahead with Reward Estimation) enforces explicit lookahead, value propagation, and limited commitment in a single model, allowing downstream outcomes to influence early decisions.

Result: FLARE consistently improves task performance across benchmarks, agent frameworks, and LLM backbones, with LLaMA-8B+FLARE often outperforming GPT-4o with standard reasoning.

Conclusion: The paper establishes a clear distinction between reasoning and planning, showing that future-aware planning is essential for long-horizon tasks where step-by-step reasoning fails.

Abstract: Large language model (LLM)-based agents exhibit strong step-by-step reasoning capabilities over short horizons, yet often fail to sustain coherent behavior over long planning horizons. We argue that this failure reflects a fundamental mismatch: step-wise reasoning induces a form of step-wise greedy policy that is adequate for short horizons but fails in long-horizon planning, where early actions must account for delayed consequences. From this planning-centric perspective, we study LLM-based agents in deterministic, fully structured environments with explicit state transitions and evaluation signals. Our analysis reveals a core failure mode of reasoning-based policies: locally optimal choices induced by step-wise scoring lead to early myopic commitments that are systematically amplified over time and difficult to recover from. We introduce FLARE (Future-aware Lookahead with Reward Estimation) as a minimal instantiation of future-aware planning to enforce explicit lookahead, value propagation, and limited commitment in a single model, allowing downstream outcomes to influence early decisions. Across multiple benchmarks, agent frameworks, and LLM backbones, FLARE consistently improves task performance and planning-level behavior, frequently allowing LLaMA-8B with FLARE to outperform GPT-4o with standard step-by-step reasoning. These results establish a clear distinction between reasoning and planning.

</details>


### [111] [Sparks of Rationality: Do Reasoning LLMs Align with Human Judgment and Choice?](https://arxiv.org/abs/2601.22329)
*Ala N. Tak,Amin Banayeeanzade,Anahita Bolourani,Fatemeh Bahrani,Ashutosh Chaubey,Sai Praneeth Karimireddy,Norbert Schwarz,Jonathan Gratch*

Main category: cs.AI

TL;DR: LLMs show improved rationality with deliberate thinking but become more sensitive to emotional steering, creating tension between reasoning and affective biases in decision-making.


<details>
  <summary>Details</summary>
Motivation: As LLMs are increasingly used for high-stakes decisions and as models of human behavior, it's critical to assess whether they exhibit human-like patterns of rationalities and emotional biases in judgment.

Method: Evaluated multiple LLM families on: (1) benchmarks testing core axioms of rational choice, (2) classic decision domains from behavioral economics where emotions shape judgment. Used two emotion-steering methods: in-context priming (ICP) and representation-level steering (RLS).

Result: Deliberate "thinking" improves rationality and pushes models toward expected-value maximization. ICP induces strong directional shifts that are extreme and hard to calibrate, while RLS produces more psychologically plausible patterns but with lower reliability. Mechanisms that improve rationality also amplify sensitivity to affective interventions.

Conclusion: There's a tension between reasoning and affective steering in LLMs, with implications for both human simulation and safe deployment of LLM-based decision systems. Different steering methods trade off controllability against human-aligned behavior.

Abstract: Large Language Models (LLMs) are increasingly positioned as decision engines for hiring, healthcare, and economic judgment, yet real-world human judgment reflects a balance between rational deliberation and emotion-driven bias. If LLMs are to participate in high-stakes decisions or serve as models of human behavior, it is critical to assess whether they exhibit analogous patterns of (ir)rationalities and biases. To this end, we evaluate multiple LLM families on (i) benchmarks testing core axioms of rational choice and (ii) classic decision domains from behavioral economics and social norms where emotions are known to shape judgment and choice. Across settings, we show that deliberate "thinking" reliably improves rationality and pushes models toward expected-value maximization. To probe human-like affective distortions and their interaction with reasoning, we use two emotion-steering methods: in-context priming (ICP) and representation-level steering (RLS). ICP induces strong directional shifts that are often extreme and difficult to calibrate, whereas RLS produces more psychologically plausible patterns but with lower reliability. Our results suggest that the same mechanisms that improve rationality also amplify sensitivity to affective interventions, and that different steering methods trade off controllability against human-aligned behavior. Overall, this points to a tension between reasoning and affective steering, with implications for both human simulation and the safe deployment of LLM-based decision systems.

</details>


### [112] [Learning Provably Correct Distributed Protocols Without Human Knowledge](https://arxiv.org/abs/2601.22369)
*Yujie Hui,Xiaoyi Lu,Andrew Perrault,Yang Wang*

Main category: cs.AI

TL;DR: GGMS: A learning framework that combines Monte Carlo Tree Search with transformers and model checking to automatically design provably correct distributed protocols, with completeness guarantees.


<details>
  <summary>Details</summary>
Motivation: Designing provably correct distributed protocols is extremely challenging and time-consuming, often requiring decades of human effort. Current methods fail to learn correct protocols even for small numbers of agents.

Method: Formulates protocol design as search over strategies in imperfect information games with SMT specifications. GGMS integrates specialized Monte Carlo Tree Search with transformer-based action encoding, global depth-first search to escape local minima, and repeated model checker feedback.

Result: GGMS can learn correct protocols for larger settings than existing methods. Output protocols are verified correct via exhaustive model checking. The framework is proven complete under mild assumptions - if a correct protocol exists, GGMS will eventually find it.

Conclusion: GGMS provides an effective automated approach for designing provably correct distributed protocols with completeness guarantees, addressing a long-standing challenge in distributed systems.

Abstract: Provably correct distributed protocols, which are a critical component of modern distributed systems, are highly challenging to design and have often required decades of human effort. These protocols allow multiple agents to coordinate to come to a common agreement in an environment with uncertainty and failures. We formulate protocol design as a search problem over strategies in a game with imperfect information, and the desired correctness conditions are specified in Satisfiability Modulo Theories (SMT). However, standard methods for solving multi-agent games fail to learn correct protocols in this setting, even when the number of agents is small. We propose a learning framework, GGMS, which integrates a specialized variant of Monte Carlo Tree Search with a transformer-based action encoder, a global depth-first search to break out of local minima, and repeated feedback from a model checker. Protocols output by GGMS are verified correct via exhaustive model checking for all executions within the bounded setting. We further prove that, under mild assumptions, the search process is complete: if a correct protocol exists, GGMS will eventually find it. In experiments, we show that GGMS can learn correct protocols for larger settings than existing methods.

</details>


### [113] [Semi-Autonomous Mathematics Discovery with Gemini: A Case Study on the Erdős Problems](https://arxiv.org/abs/2601.22401)
*Tony Feng,Trieu Trinh,Garrett Bingham,Jiwon Kang,Shengtong Zhang,Sang-hyun Kim,Kevin Barreto,Carl Schildkraut,Junehyuk Jung,Jaehyeon Seo,Carlo Pagano,Yuri Chervonyi,Dawsen Hwang,Kaiying Hou,Sergei Gukov,Cheng-Chiang Tsai,Hyunwoo Choi,Youngbeom Jin,Wei-Yuan Li,Hao-An Wu,Ruey-An Shiu,Yu-Sheng Shih,Quoc V. Le,Thang Luong*

Main category: cs.AI

TL;DR: AI-assisted analysis of 700 open Erdős problems using Gemini identified 13 solvable problems, revealing most were open due to obscurity rather than difficulty, while highlighting challenges in literature identification and AI plagiarism risks.


<details>
  <summary>Details</summary>
Motivation: To explore the potential of AI in semi-autonomous mathematics discovery by systematically evaluating open conjectures in Bloom's Erdős Problems database, addressing the challenge of determining whether problems remain open due to genuine difficulty or simply lack of awareness of existing solutions.

Method: Hybrid approach: First, AI-driven natural language verification using Gemini to narrow the search space of 700 open conjectures; then human expert evaluation to assess correctness and novelty of potential solutions.

Result: Addressed 13 problems marked 'Open': 5 through seemingly novel autonomous solutions, and 8 through identification of previous solutions in existing literature. Found that the 'Open' status was primarily due to obscurity rather than difficulty.

Conclusion: AI can effectively assist in mathematics discovery but faces challenges including difficulty in literature identification and risk of 'subconscious plagiarism' by AI. The study demonstrates that many open problems remain unsolved due to lack of awareness rather than inherent difficulty, highlighting the value of systematic AI-assisted literature review.

Abstract: We present a case study in semi-autonomous mathematics discovery, using Gemini to systematically evaluate 700 conjectures labeled 'Open' in Bloom's Erdős Problems database. We employ a hybrid methodology: AI-driven natural language verification to narrow the search space, followed by human expert evaluation to gauge correctness and novelty. We address 13 problems that were marked 'Open' in the database: 5 through seemingly novel autonomous solutions, and 8 through identification of previous solutions in the existing literature. Our findings suggest that the 'Open' status of the problems was through obscurity rather than difficulty. We also identify and discuss issues arising in applying AI to math conjectures at scale, highlighting the difficulty of literature identification and the risk of ''subconscious plagiarism'' by AI. We reflect on the takeaways from AI-assisted efforts on the Erdős Problems.

</details>


### [114] [AI-Enabled Waste Classification as a Data-Driven Decision Support Tool for Circular Economy and Urban Sustainability](https://arxiv.org/abs/2601.22418)
*Julius Sechang Mboli,Omolara Aderonke Ogungbemi*

Main category: cs.AI

TL;DR: Paper evaluates ML/DL methods for waste image classification, finds DenseNet121 best (91% accuracy), shows transfer learning outperforms traditional methods, and proposes integration into real-time waste sorting system.


<details>
  <summary>Details</summary>
Motivation: Efficient waste sorting is crucial for circular economy and resource recovery in smart cities, requiring accurate automated classification systems.

Method: Evaluated traditional ML (Random Forest, SVM, AdaBoost) and deep learning (custom CNNs, VGG16, ResNet50, plus transfer learning models DenseNet121, EfficientNetB0, InceptionV3) on 25,077 waste images with 80/20 train/test split, augmented and resized to 150x150 px. Also assessed PCA for dimensionality reduction on traditional models.

Result: DenseNet121 achieved highest accuracy (91%) and ROC-AUC (0.98), outperforming best traditional classifier by 20 percentage points. PCA showed negligible benefit for classical methods, while transfer learning substantially improved performance under limited-data conditions.

Conclusion: Transfer learning models, particularly DenseNet121, are most effective for waste classification. The paper outlines integration of these models into a real-time Data-Driven Decision Support System for automated waste sorting, highlighting potential reductions in landfill use and environmental impacts.

Abstract: Efficient waste sorting is crucial for enabling circular-economy practices and resource recovery in smart cities. This paper evaluates both traditional machine-learning (Random Forest, SVM, AdaBoost) and deep-learning techniques including custom CNNs, VGG16, ResNet50, and three transfer-learning models (DenseNet121, EfficientNetB0, InceptionV3) for binary classification of 25 077 waste images (80/20 train/test split, augmented and resized to 150x150 px). The paper assesses the impact of Principal Component Analysis for dimensionality reduction on traditional models. DenseNet121 achieved the highest accuracy (91 %) and ROC-AUC (0.98), outperforming the best traditional classifier by 20 pp. Principal Component Analysis (PCA) showed negligible benefit for classical methods, whereas transfer learning substantially improved performance under limited-data conditions. Finally, we outline how these models integrate into a real-time Data-Driven Decision Support System for automated waste sorting, highlighting potential reductions in landfill use and lifecycle environmental impacts.)

</details>


### [115] [When LLM meets Fuzzy-TOPSIS for Personnel Selection through Automated Profile Analysis](https://arxiv.org/abs/2601.22433)
*Shahria Hoque,Ahmed Akib Jawad Karim,Md. Golam Rabiul Alam,Nirjhar Gope*

Main category: cs.AI

TL;DR: Automated personnel selection system using NLP and fuzzy TOPSIS to rank software engineering applicants from LinkedIn profiles with 91% accuracy.


<details>
  <summary>Details</summary>
Motivation: In competitive employment environments, selecting suitable personnel is crucial for organizational success, requiring improved recruitment procedures that enhance scalability, consistency, and minimize bias.

Method: Created dataset from LinkedIn profiles with education, experience, skills, and self-introduction; developed LLM-TOPSIS framework combining large language models with fuzzy TOPSIS method using triangular fuzzy numbers to handle ambiguity; fine-tuned DistilRoBERTa model for candidate ranking.

Result: Achieved rankings closely aligned with human expert evaluations with up to 91% accuracy for Experience and Overall attributes, demonstrating effective automated candidate assessment.

Conclusion: NLP-driven frameworks combined with fuzzy decision-making methods show promising potential for improving recruitment by enhancing scalability, consistency, and reducing bias, with future work focusing on dataset expansion and real-world validation.

Abstract: In this highly competitive employment environment, the selection of suitable personnel is essential for organizational success. This study presents an automated personnel selection system that utilizes sophisticated natural language processing (NLP) methods to assess and rank software engineering applicants. A distinctive dataset was created by aggregating LinkedIn profiles that include essential features such as education, work experience, abilities, and self-introduction, further enhanced with expert assessments to function as standards. The research combines large language models (LLMs) with multicriteria decision-making (MCDM) theory to develop the LLM-TOPSIS framework. In this context, we utilized the TOPSIS method enhanced by fuzzy logic (Fuzzy TOPSIS) to address the intrinsic ambiguity and subjectivity in human assessments. We utilized triangular fuzzy numbers (TFNs) to describe criteria weights and scores, thereby addressing the ambiguity frequently encountered in candidate evaluations. For candidate ranking, the DistilRoBERTa model was fine-tuned and integrated with the fuzzy TOPSIS method, achieving rankings closely aligned with human expert evaluations and attaining an accuracy of up to 91% for the Experience attribute and the Overall attribute. The study underlines the potential of NLP-driven frameworks to improve recruitment procedures by boosting scalability, consistency, and minimizing prejudice. Future endeavors will concentrate on augmenting the dataset, enhancing model interpretability, and verifying the system in actual recruitment scenarios to better evaluate its practical applicability. This research highlights the intriguing potential of merging NLP with fuzzy decision-making methods in personnel selection, enabling scalable and unbiased solutions to recruitment difficulties.

</details>


### [116] [Anytime Safe PAC Efficient Reasoning](https://arxiv.org/abs/2601.22446)
*Chengyao Yu,Hao Zeng,Youxin Zhu,Jianguo Huang,Huajun Zeng,Bingyi Jing*

Main category: cs.AI

TL;DR: B-PAC reasoning enables safe and efficient online routing between thinking and non-thinking models with anytime-valid performance guarantees under partial feedback.


<details>
  <summary>Details</summary>
Motivation: Large Reasoning Models are computationally expensive, and existing selective thinking approaches suffer from uncontrollable errors in online settings with partial feedback and non-stationary data.

Method: Uses inverse propensity scoring estimators to construct test supermartingales for candidate thresholds, dynamically adjusting routing thresholds based on accumulated statistical evidence of safety.

Result: Reduces computational overhead by up to 81.01% thinking model usage while controlling performance loss below user-specified levels.

Conclusion: B-PAC reasoning provides a principled method for anytime safe and efficient online reasoning with theoretical guarantees and significant practical efficiency gains.

Abstract: Large Reasoning Models (LRMs) have demonstrated remarkable performance on complex tasks but suffer from high computational costs and latency. While selective thinking strategies improve efficiency by routing easy queries to non-thinking models, existing approaches often incur uncontrollable errors, especially in online settings where the performance loss of a non-thinking model is only partially observed and data are non-stationary. To address this, we propose Betting Probably Approximately Correct (B-PAC) reasoning, a principled method that enables anytime safe and efficient online reasoning under partial feedback. Specifically, we utilize inverse propensity scoring estimators to construct test supermartingales for candidate thresholds, and then dynamically adjust the routing threshold based on the accumulated statistical evidence of safety. Theoretically, we establish the anytime-valid performance loss control and the efficiency of B-PAC reasoning. Extensive experiments demonstrate that B-PAC reasoning significantly reduces computational overhead, decreasing thinking model usage by up to 81.01\%, while controlling the performance loss below the user-specified level.

</details>


### [117] [Controllable Information Production](https://arxiv.org/abs/2601.22449)
*Tristan Shah,Stas Tiomkin*

Main category: cs.AI

TL;DR: Introduces Controllable Information Production (CIP), a novel intrinsic motivation principle derived from optimal control that rewards both pursuing and regulating chaos without external utilities or designer-specified variables.


<details>
  <summary>Details</summary>
Motivation: Existing information-theoretic intrinsic motivation methods depend on designer choices about which random variables engage in information transmission. The paper aims to develop an IM principle that avoids both external utilities and designer-specified variables.

Method: Derives the CIP objective from Optimal Control theory, showing it as the gap between open-loop and closed-loop Kolmogorov-Sinai entropies. This formulation simultaneously rewards the pursuit and regulation of chaos.

Result: Establishes key theoretical properties of CIP and demonstrates its effectiveness on standard intrinsic motivation benchmarks.

Conclusion: CIP provides a principled approach to intrinsic motivation that connects extrinsic and intrinsic behaviors through optimal control theory, offering a framework that avoids designer biases while maintaining effectiveness.

Abstract: Intrinsic Motivation (IM) is a paradigm for generating intelligent behavior without external utilities. The existing information-theoretic methods for IM are predominantly based on information transmission, which explicitly depends on the designer's choice of which random variables engage in transmission. In this work, we introduce a novel IM principle, Controllable Information Production (CIP), that avoids both external utilities and designer-specified variables. We derive the CIP objective from Optimal Control, showing a connection between extrinsic and intrinsic behaviors. CIP appears as the gap between open-loop and closed-loop Kolmogorov-Sinai entropies, which simultaneously rewards the pursuit and regulation of chaos. We establish key theoretical properties of CIP and demonstrate its effectiveness on standard IM benchmarks.

</details>


### [118] [Why Self-Rewarding Works: Theoretical Guarantees for Iterative Alignment of Language Models](https://arxiv.org/abs/2601.22513)
*Shi Fu,Yingjie Wang,Shengchao Hu,Peng Wang,Dacheng Tao*

Main category: cs.AI

TL;DR: First theoretical analysis of Self-Rewarding Language Models showing exponential decay of initialization dependence and O(1/√n) convergence rate.


<details>
  <summary>Details</summary>
Motivation: Despite empirical success of Self-Rewarding Language Models, there's a critical gap in theoretical understanding of their core mechanisms and capabilities.

Method: Established theoretical framework with lower bounds for single update step, finite-sample error bounds for iterative paradigm, and instantiation for linear softmax model class.

Result: Performance improves at rate of O(1/√n) with sample size n, and dependence on initial model quality decays exponentially with iterations T.

Conclusion: Self-rewarding succeeds by robustly overcoming poor initialization through steering dynamics toward internal stability and consistency.

Abstract: Self-Rewarding Language Models (SRLMs) achieve notable success in iteratively improving alignment without external feedback. Yet, despite their striking empirical progress, the core mechanisms driving their capabilities remain unelucidated, leaving a critical gap in theoretical understanding. This paper provides the first rigorous theoretical guarantees for SRLMs. We first establish a lower bound that characterizes the fundamental limits of a single update step, revealing a critical dependence on the quality of the initial model. We then derive finite-sample error bounds for the full iterative paradigm, showing that performance improves at a rate of $\widetilde{\mathcal{O}}\left(1/\sqrt{n}\right)$ with sample size $n$. Crucially, our analysis reveals that the dependence on the initial model decays exponentially with the number of iterations $T$. This provides a formal explanation for why self-rewarding succeeds: it robustly overcomes poor initialization by steering the dynamics toward internal stability and consistency. Finally, we instantiate our theoretical framework for the linear softmax model class, yielding tailored guarantees that connect our high-level insights to practical model architectures.

</details>


### [119] [Darwinian Memory: A Training-Free Self-Regulating Memory System for GUI Agent Evolution](https://arxiv.org/abs/2601.22528)
*Hongze Mi,Yibo Feng,WenJie Lu,Song Cao,Jinyuan Li,Yanming Li,Xuelin Zhang,Haotian Luo,Songyang Peng,He Cui,Tengfei Tian,Jun Fang,Hua Chai,Naiqiang Tan*

Main category: cs.AI

TL;DR: DMS is a self-evolving memory system for MLLM GUI agents that uses evolutionary principles to improve performance on long-horizon, cross-application tasks without training costs.


<details>
  <summary>Details</summary>
Motivation: MLLM agents struggle with long-horizon GUI automation tasks due to limited context windows. Existing memory systems fail to adapt to dynamic GUI environments, suffering from granularity mismatch between high-level intent and low-level execution, and context pollution from outdated experiences causing hallucinations.

Method: Proposes Darwinian Memory System (DMS) - a self-evolving architecture that treats memory as a dynamic ecosystem governed by survival of the fittest. It decomposes trajectories into reusable units and implements Utility-driven Natural Selection to track survival value, pruning suboptimal paths and inhibiting high-risk plans.

Result: Extensive experiments on real-world multi-app benchmarks show DMS boosts general-purpose MLLMs without training costs, achieving average gains of 18.0% in success rate and 33.9% in execution stability, while reducing task latency.

Conclusion: DMS establishes itself as an effective self-evolving memory system for GUI tasks, addressing key bottlenecks in MLLM agent performance through evolutionary principles applied to memory management.

Abstract: Multimodal Large Language Model (MLLM) agents facilitate Graphical User Interface (GUI) automation but struggle with long-horizon, cross-application tasks due to limited context windows. While memory systems provide a viable solution, existing paradigms struggle to adapt to dynamic GUI environments, suffering from a granularity mismatch between high-level intent and low-level execution, and context pollution where the static accumulation of outdated experiences drives agents into hallucination. To address these bottlenecks, we propose the Darwinian Memory System (DMS), a self-evolving architecture that constructs memory as a dynamic ecosystem governed by the law of survival of the fittest. DMS decomposes complex trajectories into independent, reusable units for compositional flexibility, and implements Utility-driven Natural Selection to track survival value, actively pruning suboptimal paths and inhibiting high-risk plans. This evolutionary pressure compels the agent to derive superior strategies. Extensive experiments on real-world multi-app benchmarks validate that DMS boosts general-purpose MLLMs without training costs or architectural overhead, achieving average gains of 18.0% in success rate and 33.9% in execution stability, while reducing task latency, establishing it as an effective self-evolving memory system for GUI tasks.

</details>


### [120] [Enhancing TableQA through Verifiable Reasoning Trace Reward](https://arxiv.org/abs/2601.22530)
*Tung Sum Thomas Kwok,Xinyu Wang,Hengzhi He,Xiaofeng Lin,Peng Lu,Liheng Ma,Chunhe Wang,Ying Nian Wu,Lei Ding,Guang Cheng*

Main category: cs.AI

TL;DR: RE-Tab is a plug-and-play framework that improves TableQA performance by providing explicit reward feedback during table transformations, reducing inference costs by 25% while boosting accuracy.


<details>
  <summary>Details</summary>
Motivation: TableQA requires multi-step reasoning through table transformations, unlike static text/image tasks. The paper investigates whether explicit feedback on table transformation actions can improve model reasoning capabilities.

Method: RE-Tab formulates TableQA as a Partially Observable Markov Decision Process and uses lightweight, training-free reward modeling to enhance trajectory search. It provides explicit verifiable rewards during State Transition ("What is the best action?") and Simulative Reasoning ("Am I sure about the output?").

Result: Achieves state-of-the-art TableQA performance with 25% drop in inference cost. Plug-and-play implementation brings up to 41.77% improvement in QA accuracy and 33.33% drop in test-time inference samples for consistent answers. Shows consistent improvement across various LLMs and benchmarks.

Conclusion: Explicit reward feedback during table transformations is crucial for steering agent navigation in table states. RE-Tab's training-free approach effectively enhances reasoning capability while reducing computational costs, demonstrating strong generalizability across models and benchmarks.

Abstract: A major challenge in training TableQA agents, compared to standard text- and image-based agents, is that answers cannot be inferred from a static input but must be reasoned through stepwise transformations of the table state, introducing multi-step reasoning complexity and environmental interaction. This leads to a research question: Can explicit feedback on table transformation action improve model reasoning capability? In this work, we introduce RE-Tab, a plug-and-play framework that architecturally enhances trajectory search via lightweight, training-free reward modeling by formulating the problem as a Partially Observable Markov Decision Process. We demonstrate that providing explicit verifiable rewards during State Transition (``What is the best action?'') and Simulative Reasoning (``Am I sure about the output?'') is crucial to steer the agent's navigation in table states. By enforcing stepwise reasoning with reward feedback in table transformations, RE-Tab achieves state-of-the-art performance in TableQA with almost 25\% drop in inference cost. Furthermore, a direct plug-and-play implementation of RE-Tab brings up to 41.77% improvement in QA accuracy and 33.33% drop in test-time inference samples for consistent answer. Consistent improvement pattern across various LLMs and state-of-the-art benchmarks further confirms RE-Tab's generalisability. The repository is available at https://github.com/ThomasK1018/RE_Tab .

</details>


### [121] [Decoding in Geometry: Alleviating Embedding-Space Crowding for Complex Reasoning](https://arxiv.org/abs/2601.22536)
*Yixin Yang,Qingxiu Dong,Zhifang Sui*

Main category: cs.AI

TL;DR: CraEG is a novel sampling method that addresses embedding-space crowding in LLMs by using geometry-guided reweighting to improve reasoning performance and generation diversity.


<details>
  <summary>Details</summary>
Motivation: Current sampling methods (temperature- and truncation-based) only operate on token probabilities and ignore geometric relationships between tokens in embedding space. The authors discovered "embedding-space crowding" where probability mass concentrates on geometrically close tokens, which correlates with reasoning success in mathematical problem solving.

Method: Proposed CraEG (Crowding-Aware Embedding Geometry), a plug-and-play sampling method that mitigates crowding through geometry-guided reweighting. It's training-free, single-pass, and compatible with standard sampling strategies.

Result: Experiments on multiple models and benchmarks show improved generation performance with gains in robustness and diversity metrics.

Conclusion: Geometry-aware sampling methods like CraEG can effectively address embedding-space crowding and improve LLM reasoning capabilities beyond traditional probability-based approaches.

Abstract: Sampling-based decoding underlies complex reasoning in large language models (LLMs), where decoding strategies critically shape model behavior. Temperature- and truncation-based methods reshape the next-token distribution through global probability reweighting or thresholding to balance the quality-diversity tradeoff. However, they operate solely on token probabilities, ignoring fine-grained relationships among tokens in the embedding space. We uncover a novel phenomenon, embedding-space crowding, where the next-token distribution concentrates its probability mass on geometrically close tokens in the embedding space. We quantify crowding at multiple granularities and find a statistical association with reasoning success in mathematical problem solving. Motivated by this finding, we propose CraEG, a plug-and-play sampling method that mitigates crowding through geometry-guided reweighting. CraEG is training-free, single-pass, and compatible with standard sampling strategies. Experiments on multiple models and benchmarks demonstrate improved generation performance, with gains in robustness and diversity metrics.

</details>


### [122] [PerfGuard: A Performance-Aware Agent for Visual Content Generation](https://arxiv.org/abs/2601.22571)
*Zhipeng Chen,Zhongrui Zhang,Chao Zhang,Yifan Xu,Lan Yang,Jun Liu,Ke Li,Yi-Zhe Song*

Main category: cs.AI

TL;DR: PerfGuard is a performance-aware agent framework for visual content generation that models tool performance boundaries to improve task planning and execution reliability.


<details>
  <summary>Details</summary>
Motivation: Existing LLM-powered agent frameworks assume tool executions are always successful and rely on generic textual descriptions that fail to capture precise performance boundaries or adapt to tool updates, creating uncertainty in planning and execution for visual content generation tasks.

Method: Three core mechanisms: (1) Performance-Aware Selection Modeling (PASM) replaces generic descriptions with multi-dimensional scoring based on fine-grained performance evaluations; (2) Adaptive Preference Update (APU) dynamically optimizes tool selection by comparing theoretical vs. actual execution rankings; (3) Capability-Aligned Planning Optimization (CAPO) guides planners to generate subtasks aligned with performance-aware strategies.

Result: Experimental comparisons show PerfGuard outperforms state-of-the-art methods in tool selection accuracy, execution reliability, and alignment with user intent, demonstrating robustness for complex AIGC tasks.

Conclusion: PerfGuard addresses the performance uncertainty gap in LLM-powered agents for visual content generation by systematically modeling tool performance boundaries and integrating them into planning and scheduling, offering practical utility for complex AIGC tasks.

Abstract: The advancement of Large Language Model (LLM)-powered agents has enabled automated task processing through reasoning and tool invocation capabilities. However, existing frameworks often operate under the idealized assumption that tool executions are invariably successful, relying solely on textual descriptions that fail to distinguish precise performance boundaries and cannot adapt to iterative tool updates. This gap introduces uncertainty in planning and execution, particularly in domains like visual content generation (AIGC), where nuanced tool performance significantly impacts outcomes. To address this, we propose PerfGuard, a performance-aware agent framework for visual content generation that systematically models tool performance boundaries and integrates them into task planning and scheduling. Our framework introduces three core mechanisms: (1) Performance-Aware Selection Modeling (PASM), which replaces generic tool descriptions with a multi-dimensional scoring system based on fine-grained performance evaluations; (2) Adaptive Preference Update (APU), which dynamically optimizes tool selection by comparing theoretical rankings with actual execution rankings; and (3) Capability-Aligned Planning Optimization (CAPO), which guides the planner to generate subtasks aligned with performance-aware strategies. Experimental comparisons against state-of-the-art methods demonstrate PerfGuard's advantages in tool selection accuracy, execution reliability, and alignment with user intent, validating its robustness and practical utility for complex AIGC tasks. The project code is available at https://github.com/FelixChan9527/PerfGuard.

</details>


### [123] [WED-Net: A Weather-Effect Disentanglement Network with Causal Augmentation for Urban Flow Prediction](https://arxiv.org/abs/2601.22586)
*Qian Hong,Siyuan Chang,Xiao Zhou*

Main category: cs.AI

TL;DR: WED-Net is a dual-branch Transformer that disentangles intrinsic and weather-induced traffic patterns using self/cross-attention, memory banks, and adaptive gating, with causal data augmentation for better generalization under extreme weather.


<details>
  <summary>Details</summary>
Motivation: Urban spatio-temporal prediction under extreme weather (e.g., heavy rain) is challenging due to event rarity and dynamics. Existing approaches use coarse weather descriptors and lack mechanisms to capture fine-grained weather effects, while causal methods overlook temporal dynamics or use fixed confounder stratification.

Method: Proposes WED-Net: a dual-branch Transformer architecture that separates intrinsic and weather-induced traffic patterns via self- and cross-attention, enhanced with memory banks and fused through adaptive gating. Includes a discriminator to explicitly distinguish weather conditions, and a causal data augmentation strategy that perturbs non-causal parts while preserving causal structures.

Result: Experiments on taxi-flow datasets from three cities demonstrate robust performance under extreme weather conditions, showing improved generalization under rare scenarios compared to existing methods.

Conclusion: WED-Net effectively disentangles weather effects from intrinsic traffic patterns, enabling better urban spatio-temporal prediction under extreme conditions. The approach supports safer mobility, disaster preparedness, and urban resilience, with publicly available code for real-world applications.

Abstract: Urban spatio-temporal prediction under extreme conditions (e.g., heavy rain) is challenging due to event rarity and dynamics. Existing data-driven approaches that incorporate weather as auxiliary input often rely on coarse-grained descriptors and lack dedicated mechanisms to capture fine-grained spatio-temporal effects. Although recent methods adopt causal techniques to improve out-of-distribution generalization, they typically overlook temporal dynamics or depend on fixed confounder stratification. To address these limitations, we propose WED-Net (Weather-Effect Disentanglement Network), a dual-branch Transformer architecture that separates intrinsic and weather-induced traffic patterns via self- and cross-attention, enhanced with memory banks and fused through adaptive gating. To further promote disentanglement, we introduce a discriminator that explicitly distinguishes weather conditions. Additionally, we design a causal data augmentation strategy that perturbs non-causal parts while preserving causal structures, enabling improved generalization under rare scenarios. Experiments on taxi-flow datasets from three cities demonstrate that WED-Net delivers robust performance under extreme weather conditions, highlighting its potential to support safer mobility, highlighting its potential to support safer mobility, disaster preparedness, and urban resilience in real-world settings. The code is publicly available at https://github.com/HQ-LV/WED-Net.

</details>


### [124] [Learn More with Less: Uncertainty Consistency Guided Query Selection for RLVR](https://arxiv.org/abs/2601.22595)
*Hao Yi,Yulan Hu,Xin Li,Sheng Ouyang,Lizhong Ding,Yong Liu*

Main category: cs.AI

TL;DR: Active learning integration into RLVR for mathematical reasoning reduces annotation costs by selecting more informative samples, achieving full performance with only 30% of data.


<details>
  <summary>Details</summary>
Motivation: Existing RLVR algorithms for LLM mathematical reasoning require large query budgets, making annotation expensive. The paper investigates whether fewer but more informative queries can achieve similar or better performance.

Method: Introduces active learning into RLVR, proposes uncertainty consistency metric to align subjective and objective uncertainty. For offline setting uses Point-Biserial Correlation Coefficient; for online training introduces new variant computed from normalized advantage and subjective uncertainty.

Result: Method consistently outperforms random and classic AL baselines, achieves full-dataset performance while training on only 30% of the data, effectively reducing RLVR costs for reasoning tasks.

Conclusion: Active learning can significantly reduce annotation costs in RLVR for mathematical reasoning by selecting more informative samples through better uncertainty alignment between subjective and objective measures.

Abstract: Large Language Models (LLMs) have recently improved mathematical reasoning through Reinforcement Learning with Verifiable Reward (RLVR). However, existing RLVR algorithms require large query budgets, making annotation costly. We investigate whether fewer but more informative queries can yield similar or superior performance, introducing active learning (AL) into RLVR. We identify that classic AL sampling strategies fail to outperform random selection in this setting, due to ignoring objective uncertainty when only selecting by subjective uncertainty. This work proposes an uncertainty consistency metric to evaluate how well subjective uncertainty aligns with objective uncertainty. In the offline setting, this alignment is measured using the Point-Biserial Correlation Coefficient (PBC). For online training, because of limited sampling and dynamically shifting output distributions, PBC estimation is difficult. Therefore, we introduce a new online variant, computed from normalized advantage and subjective uncertainty. Theoretically, we prove that the online variant is strictly negatively correlated with offline PBC and supports better sample selection. Experiments show our method consistently outperforms random and classic AL baselines, achieving full-dataset performance while training on only 30% of the data, effectively reducing the cost of RLVR for reasoning tasks.

</details>


### [125] [From Self-Evolving Synthetic Data to Verifiable-Reward RL: Post-Training Multi-turn Interactive Tool-Using Agents](https://arxiv.org/abs/2601.22607)
*Jiaxuan Gao,Jiaao Chen,Chuyi He,Wei-Chen Wang,Shusheng Xu,Hanrui Wang,Di Jin,Yi Wu*

Main category: cs.AI

TL;DR: EigenData: A framework combining self-evolving synthetic data generation with verifier-based RL to train tool-using agents without expensive human annotation.


<details>
  <summary>Details</summary>
Motivation: Training interactive tool-using agents is challenging due to difficulty scaling high-quality multi-turn tool-use data synthesis and noisy RL signals from user simulation.

Method: Hierarchical multi-agent system (EigenData) synthesizes tool-grounded dialogues with executable checkers via closed-loop self-evolving process, plus RL recipe with fine-tuned user model, GRPO-style training with trajectory-level advantages and dynamic filtering.

Result: Best model achieves 73.0% pass^1 on Airline and 98.3% pass^1 on Telecom benchmarks, matching or exceeding frontier models.

Conclusion: Proposes scalable pathway for bootstrapping complex tool-using behaviors without expensive human annotation through unified self-evolving data synthesis and verifier-based RL framework.

Abstract: Interactive tool-using agents must solve real-world tasks via multi-turn interaction with both humans and external environments, requiring dialogue state tracking, multi-step tool execution, while following complex instructions. Post-training such agents is challenging because synthesis for high-quality multi-turn tool-use data is difficult to scale, and reinforcement learning (RL) could face noisy signals caused by user simulation, leading to degraded training efficiency. We propose a unified framework that combines a self-evolving data agent with verifier-based RL. Our system, EigenData, is a hierarchical multi-agent engine that synthesizes tool-grounded dialogues together with executable per-instance checkers, and improves generation reliability via closed-loop self-evolving process that updates prompts and workflow. Building on the synthetic data, we develop an RL recipe that first fine-tunes the user model and then applies GRPO-style training with trajectory-level group-relative advantages and dynamic filtering, yielding consistent improvements beyond SFT. Evaluated on tau^2-bench, our best model reaches 73.0% pass^1 on Airline and 98.3% pass^1 on Telecom, matching or exceeding frontier models. Overall, our results suggest a scalable pathway for bootstrapping complex tool-using behaviors without expensive human annotation.

</details>


### [126] [EntroCut: Entropy-Guided Adaptive Truncation for Efficient Chain-of-Thought Reasoning in Small-scale Large Reasoning Models](https://arxiv.org/abs/2601.22617)
*Hongxi Yan,Qingjie Liu,Yunhong Wang*

Main category: cs.AI

TL;DR: EntroCut uses entropy in early reasoning steps to dynamically truncate chain-of-thought generation, reducing token usage by up to 40% with minimal accuracy loss.


<details>
  <summary>Details</summary>
Motivation: Large Reasoning Models (LRMs) rely on lengthy chain-of-thought generation which incurs substantial computational costs, creating a need for more efficient reasoning methods.

Method: EntroCut is a training-free method that monitors output distribution entropy in early reasoning steps to identify high-confidence states where reasoning can be safely terminated early.

Result: Experiments on four benchmarks show EntroCut reduces token usage by up to 40% with minimal accuracy sacrifice, achieving superior efficiency-performance trade-offs compared to existing training-free methods.

Conclusion: Entropy-guided dynamic truncation provides a practical approach to mitigate the inefficiency of Large Reasoning Models while maintaining reasoning accuracy.

Abstract: Large Reasoning Models (LRMs) excel at complex reasoning tasks through extended chain-of-thought generation, but their reliance on lengthy intermediate steps incurs substantial computational cost. We find that the entropy of the model's output distribution in early reasoning steps reliably distinguishes correct from incorrect reasoning. Motivated by this observation, we propose EntroCut, a training-free method that dynamically truncates reasoning by identifying high-confidence states where reasoning can be safely terminated. To comprehensively evaluate the trade-off between efficiency and accuracy, we introduce the Efficiency-Performance Ratio (EPR), a unified metric that quantifies relative token savings per unit accuracy loss. Experiments on four benchmarks show that EntroCut reduces token usage by up to 40\% with minimal accuracy sacrifice, achieving superior efficiency-performance trade-offs compared with existing training-free methods. These results demonstrate that entropy-guided dynamic truncation provides a practical approach to mitigate the inefficiency of LRMs.

</details>


### [127] [SYMPHONY: Synergistic Multi-agent Planning with Heterogeneous Language Model Assembly](https://arxiv.org/abs/2601.22623)
*Wei Zhu,Zhiwen Tang,Kun Yue*

Main category: cs.AI

TL;DR: SYMPHONY: A multi-agent planning framework using heterogeneous LLMs to improve Monte Carlo Tree Search planning diversity and performance.


<details>
  <summary>Details</summary>
Motivation: Existing single-agent LLM approaches for MCTS planning suffer from limited exploration and insufficient diversity in generated search branches, leading to suboptimal planning performance.

Method: Proposes SYMPHONY, a multi-agent planning framework that integrates a pool of heterogeneous language model-based agents to leverage diverse reasoning patterns and enhance rollout diversity during MCTS exploration.

Result: Achieves strong performance with open-source LLMs on consumer hardware, and further improvements with cloud-based LLMs, outperforming state-of-the-art baselines across multiple benchmark tasks.

Conclusion: Heterogeneous multi-agent coordination effectively enhances planning capabilities, demonstrating the superiority of diverse agent assemblies over single-agent approaches in complex problem-solving tasks.

Abstract: Recent advancements have increasingly focused on leveraging large language models (LLMs) to construct autonomous agents for complex problem-solving tasks. However, existing approaches predominantly employ a single-agent framework to generate search branches and estimate rewards during Monte Carlo Tree Search (MCTS) planning. This single-agent paradigm inherently limits exploration capabilities, often resulting in insufficient diversity among generated branches and suboptimal planning performance. To overcome these limitations, we propose Synergistic Multi-agent Planning with Heterogeneous langauge model assembly (SYMPHONY), a novel multi-agent planning framework that integrates a pool of heterogeneous language model-based agents. By leveraging diverse reasoning patterns across agents, SYMPHONY enhances rollout diversity and facilitates more effective exploration. Empirical results across multiple benchmark tasks show that SYMPHONY achieves strong performance even when instantiated with open-source LLMs deployable on consumer-grade hardware. When enhanced with cloud-based LLMs accessible via API, SYMPHONY demonstrates further improvements, outperforming existing state-of-the-art baselines and underscoring the effectiveness of heterogeneous multi-agent coordination in planning tasks.

</details>


### [128] [Statistical Estimation of Adversarial Risk in Large Language Models under Best-of-N Sampling](https://arxiv.org/abs/2601.22636)
*Mingqian Feng,Xiaodong Liu,Weiwei Yang,Chenliang Xu,Christopher White,Jianfeng Gao*

Main category: cs.AI

TL;DR: SABER method predicts large-scale LLM jailbreak risk from small samples using Beta distribution modeling and analytic scaling laws.


<details>
  <summary>Details</summary>
Motivation: Current LLM safety evaluations underestimate real-world risk because they use single-shot or low-budget adversarial prompting, while attackers can use large-scale parallel sampling to repeatedly probe models until harmful responses are produced.

Method: Proposed SABER (scaling-aware Best-of-N estimation of risk) models sample-level success probabilities using a Beta distribution (conjugate prior of Bernoulli distribution) and derives analytic scaling laws to extrapolate large-N attack success rates from small-budget measurements.

Result: Using only n=100 samples, SABER predicts ASR@1000 with mean absolute error of 1.66 (86.2% reduction compared to baseline error of 12.04). Reveals heterogeneous risk scaling profiles showing models appearing robust under standard evaluation can experience rapid nonlinear risk amplification.

Conclusion: Provides low-cost, scalable methodology for realistic LLM safety assessment that accounts for parallel adversarial pressure, enabling better prediction of large-scale jailbreak vulnerability from limited measurements.

Abstract: Large Language Models (LLMs) are typically evaluated for safety under single-shot or low-budget adversarial prompting, which underestimates real-world risk. In practice, attackers can exploit large-scale parallel sampling to repeatedly probe a model until a harmful response is produced. While recent work shows that attack success increases with repeated sampling, principled methods for predicting large-scale adversarial risk remain limited. We propose a scaling-aware Best-of-N estimation of risk, SABER, for modeling jailbreak vulnerability under Best-of-N sampling. We model sample-level success probabilities using a Beta distribution, the conjugate prior of the Bernoulli distribution, and derive an analytic scaling law that enables reliable extrapolation of large-N attack success rates from small-budget measurements. Using only n=100 samples, our anchored estimator predicts ASR@1000 with a mean absolute error of 1.66, compared to 12.04 for the baseline, which is an 86.2% reduction in estimation error. Our results reveal heterogeneous risk scaling profiles and show that models appearing robust under standard evaluation can experience rapid nonlinear risk amplification under parallel adversarial pressure. This work provides a low-cost, scalable methodology for realistic LLM safety assessment. We will release our code and evaluation scripts upon publication to future research.

</details>


### [129] [Beyond Medical Chatbots: Meddollina and the Rise of Continuous Clinical Intelligence](https://arxiv.org/abs/2601.22645)
*Vaibhav Ram S. V. N. S,Swetanshu Agrawal,Samudra Banerjee,Abdul Muhsin*

Main category: cs.AI

TL;DR: Medical AI needs clinical contextual intelligence, not just text generation. Meddollina is a governance-first system that prioritizes clinical appropriateness over generative completeness, showing better behavior under uncertainty.


<details>
  <summary>Details</summary>
Motivation: Current generative medical AI systems show problematic behaviors like premature closure, unjustified certainty, and instability in multi-step decisions despite high benchmark scores. These issues stem from treating medicine as next-token prediction rather than clinical reasoning.

Method: Introduces Meddollina, a governance-first clinical intelligence system that constrains inference before language realization. It acts as a continuous intelligence layer supporting clinical workflows while preserving clinician authority.

Result: Meddollina exhibits calibrated uncertainty, conservative reasoning under underspecification, stable longitudinal constraint adherence, and reduced speculative completion compared to generation-centric baselines across 16,412+ medical queries.

Conclusion: Deployable medical AI requires Clinical Contextual Intelligence, not just scaling. Progress should be measured by clinician-aligned behavior under uncertainty rather than fluency-driven completion.

Abstract: Generative medical AI now appears fluent and knowledgeable enough to resemble clinical intelligence, encouraging the belief that scaling will make it safe. But clinical reasoning is not text generation. It is a responsibility-bound process under ambiguity, incomplete evidence, and longitudinal context. Even as benchmark scores rise, generation-centric systems still show behaviours incompatible with clinical deployment: premature closure, unjustified certainty, intent drift, and instability across multi-step decisions.
  We argue these are structural consequences of treating medicine as next-token prediction. We formalise Clinical Contextual Intelligence (CCI) as a distinct capability class required for real-world clinical use, defined by persistent context awareness, intent preservation, bounded inference, and principled deferral when evidence is insufficient.
  We introduce Meddollina, a governance-first clinical intelligence system designed to constrain inference before language realisation, prioritising clinical appropriateness over generative completeness. Meddollina acts as a continuous intelligence layer supporting clinical workflows while preserving clinician authority. We evaluate Meddollina using a behaviour-first regime across 16,412+ heterogeneous medical queries, benchmarking against general-purpose models, medical-tuned models, and retrieval-augmented systems.
  Meddollina exhibits a distinct behavioural profile: calibrated uncertainty, conservative reasoning under underspecification, stable longitudinal constraint adherence, and reduced speculative completion relative to generation-centric baselines. These results suggest deployable medical AI will not emerge from scaling alone, motivating a shift toward Continuous Clinical Intelligence, where progress is measured by clinician-aligned behaviour under uncertainty rather than fluency-driven completion.

</details>


### [130] [Test-Time Mixture of World Models for Embodied Agents in Dynamic Environments](https://arxiv.org/abs/2601.22647)
*Jinwoo Jang,Minjong Yoo,Sihyung Yoon,Honguk Woo*

Main category: cs.AI

TL;DR: TMoW is a test-time mixture of world models framework that enables embodied agents to adapt to unseen and evolving domains by dynamically updating routing functions and recombining existing models.


<details>
  <summary>Details</summary>
Motivation: Current LM-based embodied agents lack adaptability in dynamic environments where accurate and flexible world models are crucial for effective reasoning and decision-making. Conventional MoE architectures are rigid once deployed, making them ineffective for adapting to unseen domains.

Method: TMoW extends MoE to embodied agents with three key components: (1) multi-granular prototype-based routing that adapts mixtures across object- to scene-level similarities, (2) test-time refinement that aligns unseen domain features with prototypes during inference, and (3) distilled mixture-based augmentation that efficiently constructs new models from few-shot data and existing prototypes.

Result: Evaluation on VirtualHome, ALFWorld, and RLBench benchmarks demonstrates strong performance in both zero-shot adaptation and few-shot expansion scenarios, showing that TMoW enables embodied agents to operate effectively in dynamic environments.

Conclusion: TMoW provides a framework for continual adaptation in dynamic environments by enabling test-time routing updates and model recombination, addressing the limitations of conventional fixed MoE architectures for embodied agents.

Abstract: Language model (LM)-based embodied agents are increasingly deployed in real-world settings. Yet, their adaptability remains limited in dynamic environments, where constructing accurate and flexible world models is crucial for effective reasoning and decision-making. To address this challenge, we extend the Mixture-of-Experts (MoE) paradigm to embodied agents. While conventional MoE architectures modularize knowledge into expert components with pre-trained routing, they remain rigid once deployed, making them less effective for adapting to unseen domains in dynamic environments. We therefore propose Test-time Mixture of World Models (TMoW), a framework that enhances adaptability to unseen and evolving domains. TMoW updates its routing function over world models at test time, unlike conventional MoE where the function remains fixed, enabling agents to recombine existing models and integrate new ones for continual adaptation. It achieves this through (i) multi-granular prototype-based routing, which adapts mixtures across object- to scene-level similarities, (ii) test-time refinement that aligns unseen domain features with prototypes during inference, and (iii) distilled mixture-based augmentation, which efficiently constructs new models from few-shot data and existing prototypes. We evaluate TMoW on VirtualHome, ALFWorld, and RLBench benchmarks, demonstrating strong performance in both zero-shot adaptation and few-shot expansion scenarios, and showing that it enables embodied agents to operate effectively in dynamic environments.

</details>


### [131] [UCPO: Uncertainty-Aware Policy Optimization](https://arxiv.org/abs/2601.22648)
*Xianzhou Zeng,Jing Huang,Chunmei Xie,Gongrui Nan,Siye Chen,Mengyu Lu,Weiqi Xiong,Qixuan Zhou,Junhao Zhang,Qiang Zhu,Yadong Li,Xingzhong Xu*

Main category: cs.AI

TL;DR: UCPO framework addresses advantage bias in RL for LLMs by decoupling deterministic/uncertain rollouts and dynamically adjusting uncertainty rewards, improving reliability and calibration.


<details>
  <summary>Details</summary>
Motivation: Existing RL paradigms for LLMs suffer from Advantage Bias due to binary decision spaces and static uncertainty rewards, causing either excessive conservatism or overconfidence, which limits trustworthy LLM development.

Method: Proposes UnCertainty-Aware Policy Optimization (UCPO) with Ternary Advantage Decoupling to separate and independently normalize deterministic/uncertain rollouts, plus Dynamic Uncertainty Reward Adjustment to calibrate uncertainty weights in real-time based on model evolution and instance difficulty.

Result: Experimental results in mathematical reasoning and general tasks show UCPO effectively resolves reward imbalance, significantly improving model reliability and calibration beyond knowledge boundaries.

Conclusion: UCPO framework successfully addresses reward hacking and overconfidence in RL paradigms with uncertainty-based rewards, enhancing LLM trustworthiness through better uncertainty expression capabilities.

Abstract: The key to building trustworthy Large Language Models (LLMs) lies in endowing them with inherent uncertainty expression capabilities to mitigate the hallucinations that restrict their high-stakes applications. However, existing RL paradigms such as GRPO often suffer from Advantage Bias due to binary decision spaces and static uncertainty rewards, inducing either excessive conservatism or overconfidence. To tackle this challenge, this paper unveils the root causes of reward hacking and overconfidence in current RL paradigms incorporating uncertainty-based rewards, based on which we propose the UnCertainty-Aware Policy Optimization (UCPO) framework. UCPO employs Ternary Advantage Decoupling to separate and independently normalize deterministic and uncertain rollouts, thereby eliminating advantage bias. Furthermore, a Dynamic Uncertainty Reward Adjustment mechanism is introduced to calibrate uncertainty weights in real-time according to model evolution and instance difficulty. Experimental results in mathematical reasoning and general tasks demonstrate that UCPO effectively resolves the reward imbalance, significantly improving the reliability and calibration of the model beyond their knowledge boundaries.

</details>


### [132] [Task-Aware LLM Council with Adaptive Decision Pathways for Decision Support](https://arxiv.org/abs/2601.22662)
*Wei Zhu,Lixing Yu,Hao-Ren Yao,Zhiwen Tang,Kun Yue*

Main category: cs.AI

TL;DR: TALC is a task-adaptive LLM framework that uses a council of specialized models with MCTS for dynamic expert selection and multi-step planning, achieving better performance than uniform approaches.


<details>
  <summary>Details</summary>
Motivation: Current LLM decision-making approaches treat all models as uniformly applicable, ignoring specialization differences that could better adapt to varying reasoning demands and task complexities.

Method: TALC integrates a council of LLMs with Monte Carlo Tree Search, where each model has a structured success memory profile for semantic matching. It uses dual-signal value estimation (model-based evaluations + historical utility) with adaptive weighting based on variance to guide MCTS selection.

Result: Experiments on WebShop, HumanEval, and Game of 24 show TALC achieves superior task success rates and improved search efficiency compared to strong baselines.

Conclusion: The framework validates the benefits of specialization-aware routing and adaptive planning, demonstrating that dynamic expert selection based on contextual matching improves LLM decision-making performance.

Abstract: Large language models (LLMs) have shown strong capabilities across diverse decision-making tasks. However, existing approaches often overlook the specialization differences among available models, treating all LLMs as uniformly applicable regardless of task characteristics. This limits their ability to adapt to varying reasoning demands and task complexities. In this work, we propose Task-Aware LLM Council (TALC), a task-adaptive decision framework that integrates a council of LLMs with Monte Carlo Tree Search (MCTS) to enable dynamic expert selection and efficient multi-step planning. Each LLM is equipped with a structured success memory profile derived from prior task trajectories, enabling semantic matching between current reasoning context and past successes. At each decision point, TALC routes control to the most contextually appropriate model and estimates node value using a dual-signal mechanism that fuses model-based evaluations with historical utility scores. These signals are adaptively weighted based on intra-node variance and used to guide MCTS selection, allowing the system to balance exploration depth with planning confidence. Experiments on WebShop, HumanEval, and the Game of 24 demonstrate that TALC achieves superior task success rates and improved search efficiency compared to strong baselines, validating the benefits of specialization-aware routing and adaptive planning.

</details>


### [133] [Real-Time Aligned Reward Model beyond Semantics](https://arxiv.org/abs/2601.22664)
*Zixuan Huang,Xin Xia,Yuxi Ren,Jianbin Zheng,Xuefeng Xiao,Hongyan Xie,Li Huaqiu,Songshi Liang,Zhongxiang Dai,Fuzhen Zhuang,Jianxin Li,Yikun Ban,Deqing Wang*

Main category: cs.AI

TL;DR: R2M is a lightweight RLHF framework that uses real-time policy feedback to prevent reward overoptimization by aligning reward models with policy distribution shifts during RL training.


<details>
  <summary>Details</summary>
Motivation: Current RLHF approaches suffer from reward overoptimization where policy models overfit to reward models, exploiting spurious patterns instead of capturing true human intent. Existing mitigations rely on surface semantics and fail to address misalignment caused by continuous policy distribution shifts during RL training.

Method: R2M leverages evolving hidden states of the policy model (policy feedback) to align the reward model with real-time distribution shifts during RL training, going beyond vanilla reward models that only use semantic representations from pretrained LLMs.

Result: The framework points to a promising new direction for improving reward model performance through real-time utilization of policy feedback, addressing the core issue of reward overoptimization in RLHF.

Conclusion: R2M represents a novel approach to RLHF that dynamically aligns reward models with policy evolution, potentially solving the persistent problem of reward overoptimization by incorporating real-time policy feedback into reward modeling.

Abstract: Reinforcement Learning from Human Feedback (RLHF) is a pivotal technique for aligning large language models (LLMs) with human preferences, yet it is susceptible to reward overoptimization, in which policy models overfit to the reward model, exploit spurious reward patterns instead of faithfully capturing human intent. Prior mitigations primarily relies on surface semantic information and fails to efficiently address the misalignment between the reward model (RM) and the policy model caused by continuous policy distribution shifts. This inevitably leads to an increasing reward discrepancy, exacerbating reward overoptimization. To address these limitations, we introduce R2M (Real-Time Aligned Reward Model), a novel lightweight RLHF framework. R2M goes beyond vanilla reward models that solely depend on the semantic representations of a pretrained LLM. Instead, it leverages the evolving hidden states of the policy (namely policy feedback) to align with the real-time distribution shift of the policy during the RL process. This work points to a promising new direction for improving the performance of reward models through real-time utilization of feedback from policy models.

</details>


### [134] [Best-of-Q: Improving VLM agents with Q-function Action Ranking at Inference](https://arxiv.org/abs/2601.22701)
*Emilien Biré,María Santos,Kai Yuan*

Main category: cs.AI

TL;DR: A novel inference-time method that enhances VLM agents without retraining by decoupling action proposal from selection, using a frozen VLM to generate candidates and a lightweight Q-function for reranking.


<details>
  <summary>Details</summary>
Motivation: VLMs struggle with fast-changing environments like the web, and fine-tuning requires expensive training and data collection. There's a need for inference-time adaptation without policy retraining.

Method: Decouple VLM's role: keep frozen VLM as action proposer to generate candidate actions, then use lightweight offline-trained Q-function to rerank candidates and select highest-value action at inference time.

Result: Significant improvement on WebVoyager benchmark: Qwen2.5-VL-7B agent improved from 38.8% to 55.7% success rate; proprietary GPT-4.1 agent improved from 82.4% to 88.8%.

Conclusion: The approach enables immediate policy improvement at inference without retraining, demonstrating effective adaptation to dynamic environments by separating action proposal from value-based selection.

Abstract: Vision-Language Models (VLMs) have become powerful backbones for agents to autonomously operate in digital environments like the web and operating systems. However, these models suffer from inadaptability to fast-changing environments like the web, which can be alleviated by fine-tuning requiring expansive model training and data collection. In this work, we introduce a novel paradigm for enhancing agentic VLM policies at inference without policy retraining. Fundamentally, our approach decouples the VLM's role as a high-capacity action proposer from the final action selection mechanism. We keep the VLM policy frozen and use it to generate a set of candidate actions for a given state. Then, a lightweight, offline-trained Q-function reranks these candidates, and the agent executes the action with the highest estimated value. The main contribution is to apply the Q-function directly during inference for immediate policy improvement, and not offline to relabel data for policy retraining. We demonstrate on the academic WebVoyager benchmark that our method significantly boosts agent success rates, improving a Qwen2.5-VL-7B agent from 38.8% to 55.7% and a proprietary GPT-4.1 agent from 82.4% to 88.8%.

</details>


### [135] [A Step Back: Prefix Importance Ratio Stabilizes Policy Optimization](https://arxiv.org/abs/2601.22718)
*Shiye Lei,Zhihao Cheng,Dacheng Tao*

Main category: cs.AI

TL;DR: MinPRO stabilizes RL post-training for LLMs by using minimum token-level ratios instead of cumulative prefix ratios to handle large off-policy drift.


<details>
  <summary>Details</summary>
Motivation: Current RL post-training methods for LLMs use token-level importance sampling ratios for computational simplicity, but these lead to unstable training when there's large discrepancy between sampling and target policies (off-policy drift).

Method: Proposes Minimum Prefix Ratio (MinPRO) which replaces the unstable cumulative prefix importance ratio with a non-cumulative surrogate based on the minimum token-level ratio observed in the preceding prefix.

Result: Extensive experiments on dense and mixture-of-experts LLMs across multiple mathematical reasoning benchmarks show MinPRO substantially improves training stability and peak performance in off-policy regimes.

Conclusion: MinPRO provides a simple yet effective solution to stabilize LLM optimization under large off-policy drift, addressing the limitations of token-level importance sampling approximations in RL post-training.

Abstract: Reinforcement learning (RL) post-training has increasingly demonstrated strong ability to elicit reasoning behaviors in large language models (LLMs). For training efficiency, rollouts are typically generated in an off-policy manner using an older sampling policy and then used to update the current target policy. To correct the resulting discrepancy between the sampling and target policies, most existing RL objectives rely on a token-level importance sampling ratio, primarily due to its computational simplicity and numerical stability. However, we observe that token-level correction often leads to unstable training dynamics when the degree of off-policyness is large. In this paper, we revisit LLM policy optimization under off-policy conditions and show that the theoretically rigorous correction term is the prefix importance ratio, and that relaxing it to a token-level approximation can induce instability in RL post-training. To stabilize LLM optimization under large off-policy drift, we propose a simple yet effective objective, Minimum Prefix Ratio (MinPRO). MinPRO replaces the unstable cumulative prefix ratio with a non-cumulative surrogate based on the minimum token-level ratio observed in the preceding prefix. Extensive experiments on both dense and mixture-of-experts LLMs, across multiple mathematical reasoning benchmarks, demonstrate that MinPRO substantially improves training stability and peak performance in off-policy regimes.

</details>


### [136] [AutoRefine: From Trajectories to Reusable Expertise for Continual LLM Agent Refinement](https://arxiv.org/abs/2601.22758)
*Libin Qiu,Zhirong Gao,Junfu Chen,Yuhang Ye,Weizhi Huang,Xiaobo Xue,Wenkai Qiu,Shuo Tang*

Main category: cs.AI

TL;DR: AutoRefine extracts and maintains dual-form Experience Patterns from agent execution histories to help LLM agents accumulate knowledge, with specialized subagents for procedural tasks and skill patterns for static knowledge, plus continuous maintenance to prevent repository degradation.


<details>
  <summary>Details</summary>
Motivation: LLM agents fail to accumulate knowledge from experience, treating each task independently. Existing methods extract flattened textual knowledge that can't capture procedural logic of complex subtasks and lack maintenance mechanisms, causing repository degradation as experience accumulates.

Method: Extracts dual-form Experience Patterns: (1) specialized subagents with independent reasoning/memory for procedural subtasks, (2) skill patterns as guidelines/code snippets for static knowledge. Includes continuous maintenance mechanism that scores, prunes, and merges patterns to prevent repository degradation.

Result: Achieves 98.4% on ALFWorld, 70.4% on ScienceWorld, and 27.1% on TravelPlanner, with 20-73% step reductions. On TravelPlanner, automatic extraction exceeds manually designed systems (27.1% vs 12.1%), demonstrating ability to capture procedural coordination.

Conclusion: AutoRefine successfully enables LLM agents to accumulate knowledge from experience by extracting and maintaining dual-form Experience Patterns, addressing limitations of existing methods and demonstrating superior performance across multiple domains.

Abstract: Large language model agents often fail to accumulate knowledge from experience, treating each task as an independent challenge. Recent methods extract experience as flattened textual knowledge, which cannot capture procedural logic of complex subtasks. They also lack maintenance mechanisms, causing repository degradation as experience accumulates. We introduce AutoRefine, a framework that extracts and maintains dual-form Experience Patterns from agent execution histories. For procedural subtasks, we extract specialized subagents with independent reasoning and memory. For static knowledge, we extract skill patterns as guidelines or code snippets. A continuous maintenance mechanism scores, prunes, and merges patterns to prevent repository degradation. Evaluated on ALFWorld, ScienceWorld, and TravelPlanner, AutoRefine achieves 98.4%, 70.4%, and 27.1% respectively, with 20-73% step reductions. On TravelPlanner, automatic extraction exceeds manually designed systems (27.1% vs 12.1%), demonstrating its ability to capture procedural coordination.

</details>


### [137] [TSPO: Breaking the Double Homogenization Dilemma in Multi-turn Search Policy Optimization](https://arxiv.org/abs/2601.22776)
*Shichao Ma,Zhiyuan Ma,Ming Yang,Xiaofan Li,Xing Wu,Jintao Du,Yu Cheng,Weiqiang Wang,Qiliang Liu,Zhengyang Zhou,Yang Wang*

Main category: cs.AI

TL;DR: TSPO introduces turn-level stage-aware policy optimization with First-Occurrence Latent Reward to address process and intra-group homogenization in RL for search-augmented reasoning.


<details>
  <summary>Details</summary>
Motivation: Current RL frameworks for search-augmented reasoning suffer from "Double Homogenization Dilemma" - ignoring process-level details (thinking, reasoning, tooling) and having inefficient intra-group advantage estimation due to sparse outcome-level rewards.

Method: Proposes Turn-level Stage-aware Policy Optimization (TSPO) with First-Occurrence Latent Reward (FOLR) mechanism that allocates partial rewards to the step where ground-truth answer first appears, preserving process-level signals and increasing reward variance within groups without external models or annotations.

Result: TSPO significantly outperforms state-of-the-art baselines, achieving average performance gains of 24% on Qwen2.5-3B and 13.6% on Qwen2.5-7B models.

Conclusion: TSPO effectively addresses the double homogenization problem in RL for search-augmented reasoning by introducing turn-level stage-aware optimization with latent reward allocation, leading to substantial performance improvements without additional annotation requirements.

Abstract: Multi-turn tool-integrated reasoning enables Large Language Models (LLMs) to solve complex tasks through iterative information retrieval. However, current reinforcement learning (RL) frameworks for search-augmented reasoning predominantly rely on sparse outcome-level rewards, leading to a "Double Homogenization Dilemma." This manifests as (1) Process homogenization, where the thinking, reasoning, and tooling involved in generation are ignored. (2) Intra-group homogenization, coarse-grained outcome rewards often lead to inefficiencies in intra-group advantage estimation with methods like Group Relative Policy Optimization (GRPO) during sampling. To address this, we propose Turn-level Stage-aware Policy Optimization (TSPO). TSPO introduces the First-Occurrence Latent Reward (FOLR) mechanism, allocating partial rewards to the step where the ground-truth answer first appears, thereby preserving process-level signals and increasing reward variance within groups without requiring external reward models or any annotations. Extensive experiments demonstrate that TSPO significantly outperforms state-of-the-art baselines, achieving average performance gains of 24% and 13.6% on Qwen2.5-3B and 7B models, respectively.

</details>


### [138] [Learning with Challenges: Adaptive Difficulty-Aware Data Generation for Mobile GUI Agent Training](https://arxiv.org/abs/2601.22781)
*Linjia Kang,Zhimin Wang,Yongkang Zhang,Duo Wu,Jinghe Wang,Ming Ma,Haopeng Yan,Zhi Wang*

Main category: cs.AI

TL;DR: MobileGen is a data generation framework for mobile GUI agents that adaptively aligns training difficulty with agent capabilities by profiling structural and semantic difficulty dimensions and generating progressively challenging trajectories.


<details>
  <summary>Details</summary>
Motivation: Existing methods for generating GUI interaction trajectories lack fine-grained control over task difficulty, creating a mismatch between training difficulty and agent capabilities that restricts learning effectiveness. Humans learn through progressively challenging tasks, suggesting a need for capability-aligned data generation.

Method: MobileGen decouples task difficulty into structural (trajectory length) and semantic (task goal) dimensions, profiles agent capabilities across these dimensions, adaptively computes difficulty distributions, samples target difficulty, and uses a multi-agent controllable generator to synthesize high-quality interaction trajectories with instructions.

Result: MobileGen consistently outperforms existing data generation methods, improving average performance of GUI agents by 1.57 times across multiple challenging benchmarks.

Conclusion: Capability-aligned data generation is crucial for effective mobile GUI agent training, and MobileGen's adaptive difficulty alignment framework provides a systematic approach to generating progressively challenging training data that matches agent learning frontiers.

Abstract: Large-scale, high-quality interaction trajectories are essential for advancing mobile Graphical User Interface (GUI) agents. While existing methods typically rely on labor-intensive human demonstrations or automated model exploration to generate GUI trajectories, they lack fine-grained control over task difficulty. This fundamentally restricts learning effectiveness due to the mismatch between the training difficulty and the agent's capabilities. Inspired by how humans acquire skills through progressively challenging tasks, we propose MobileGen, a novel data generation framework that adaptively aligns training difficulty with the GUI agent's capability frontier. Specifically, MobileGen explicitly decouples task difficulty into structural (e.g., trajectory length) and semantic (e.g., task goal) dimensions. It then iteratively evaluates the agent on a curated prior dataset to construct a systematic profile of its capability frontier across these two dimensions. With this profile, the probability distribution of task difficulty is adaptively computed, from which the target difficulty for the next round of training can be sampled. Guided by the sampled difficulty, a multi-agent controllable generator is finally used to synthesize high-quality interaction trajectories along with corresponding task instructions. Extensive experiments show that MobileGen consistently outperforms existing data generation methods by improving the average performance of GUI agents by 1.57 times across multiple challenging benchmarks. This highlights the importance of capability-aligned data generation for effective mobile GUI agent training.

</details>


### [139] [Toward IIT-Inspired Consciousness in LLMs: A Reward-Based Learning Framework](https://arxiv.org/abs/2601.22786)
*Hamid Reza Akbari,Mohammad Hossein Sameti,Amir M. Mansourian,Mohammad Hossein Rohban,Hossein Sameti*

Main category: cs.AI

TL;DR: Optimizing language models with an IIT-inspired reward function reduces output length by up to 31% while maintaining accuracy, offering a simple, efficient post-training method.


<details>
  <summary>Details</summary>
Motivation: To explore how consciousness-inspired processing (via Integrated Information Theory) could improve language models, specifically to achieve more concise and integrated text generation as a step toward AGI development.

Method: Implement IIT principles via a novel reward function that quantifies text causality, coherence, and integration, then use reward-based learning to optimize language models for this signal.

Result: Models optimized with the IIT-inspired reward generate up to 31% more concise text on out-of-domain tasks while preserving comparable accuracy to base models, with additional benefits for confidence calibration and computational scaling.

Conclusion: The IIT-inspired reward framework provides a practical, efficient post-training approach that improves text conciseness without sacrificing accuracy, offering advantages over task-specific heuristics for language model optimization.

Abstract: The pursuit of Artificial General Intelligence (AGI) is a central goal in language model development, in which consciousness-like processing could serve as a key facilitator. While current language models are not conscious, they exhibit behaviors analogous to certain aspects of consciousness. This paper investigates the implementation of a leading theory of consciousness, Integrated Information Theory (IIT), within language models via a reward-based learning paradigm. IIT provides a formal, axiom-based mathematical framework for quantifying consciousness. Drawing inspiration from its core principles, we formulate a novel reward function that quantifies a text's causality, coherence and integration, characteristics associated with conscious processing. Empirically, it is found that optimizing for this IIT-inspired reward leads to more concise text generation. On out of domain tasks, careful tuning achieves up to a 31% reduction in output length while preserving accuracy levels comparable to the base model. In addition to primary task performance, the broader effects of this training methodology on the model's confidence calibration and test-time computational scaling is analyzed. The proposed framework offers significant practical advantages: it is conceptually simple, computationally efficient, requires no external data or auxiliary models, and leverages a general, capability-driven signal rather than task-specific heuristics. Code available at https://github.com/MH-Sameti/LLM_PostTraining.git

</details>


### [140] [Conditional Performance Guarantee for Large Reasoning Models](https://arxiv.org/abs/2601.22790)
*Jianguo Huang,Hao Zeng,Bingyi Jing,Hongxin Wei,Bo An*

Main category: cs.AI

TL;DR: G-PAC reasoning provides group-level statistical guarantees for efficient reasoning by partitioning input space, improving over marginal PAC reasoning with group-conditional risk control and computational savings.


<details>
  <summary>Details</summary>
Motivation: Large reasoning models have high computational costs from chain-of-thought reasoning, and existing PAC reasoning only provides marginal guarantees without exact conditional coverage.

Method: Propose G-PAC reasoning framework with two instantiations: Group PAC (G-PAC) for known group structures and Clustered PAC (C-PAC) for unknown groupings, partitioning input space to achieve group-conditional risk control.

Result: Both G-PAC and C-PAC achieve group-conditional risk control, grouping can strictly improve efficiency over marginal PAC reasoning in heterogeneous settings, and experiments show successful risk control with computational savings.

Conclusion: G-PAC reasoning provides practical PAC-style guarantees at group level, offering both statistical guarantees and computational efficiency improvements for reasoning tasks.

Abstract: Large reasoning models have shown strong performance through extended chain-of-thought reasoning, yet their computational cost remains significant. Probably approximately correct (PAC) reasoning provides statistical guarantees for efficient reasoning by adaptively switching between thinking and non-thinking models, but the guarantee holds only in the marginal case and does not provide exact conditional coverage. We propose G-PAC reasoning, a practical framework that provides PAC-style guarantees at the group level by partitioning the input space. We develop two instantiations: Group PAC (G-PAC) reasoning for known group structures and Clustered PAC (C-PAC) reasoning for unknown groupings. We prove that both G-PAC and C-PAC achieve group-conditional risk control, and that grouping can strictly improve efficiency over marginal PAC reasoning in heterogeneous settings. Our experiments on diverse reasoning benchmarks demonstrate that G-PAC and C-PAC successfully achieve group-conditional risk control while maintaining substantial computational savings.

</details>


### [141] [CVeDRL: An Efficient Code Verifier via Difficulty-aware Reinforcement Learning](https://arxiv.org/abs/2601.22803)
*Ji Shi,Peiming Guo,Meishan Zhang,Miao Zhang,Xuebo Liu,Min Zhang,Weili Guan*

Main category: cs.AI

TL;DR: CVeDRL: A reinforcement learning approach for code verification that uses syntax, functionality, branch coverage, and sample difficulty-aware rewards to improve unit test generation, achieving SOTA performance with only 0.6B parameters.


<details>
  <summary>Details</summary>
Motivation: Existing supervised fine-tuning methods for code verification suffer from data scarcity, high failure rates, and poor inference efficiency. Reinforcement learning offers promise but naive RL with only functionality rewards fails to generate effective unit tests for difficult branches and samples.

Method: Theoretical analysis shows branch coverage, sample difficulty, syntactic and functional correctness can be jointly modeled as RL rewards. Design syntax- and functionality-aware rewards, and propose branch- and sample-difficulty-aware RL using exponential reward shaping and static analysis metrics.

Result: CVeDRL achieves state-of-the-art performance with only 0.6B parameters, yielding up to 28.97% higher pass rate and 15.08% higher branch coverage than GPT-3.5, while delivering over 20× faster inference than competitive baselines.

Conclusion: The proposed multi-faceted RL approach with carefully designed rewards effectively addresses limitations of existing code verification methods, achieving superior performance with significantly fewer parameters and faster inference.

Abstract: Code verifiers play a critical role in post-verification for LLM-based code generation, yet existing supervised fine-tuning methods suffer from data scarcity, high failure rates, and poor inference efficiency. While reinforcement learning (RL) offers a promising alternative by optimizing models through execution-driven rewards without labeled supervision, our preliminary results show that naive RL with only functionality rewards fails to generate effective unit tests for difficult branches and samples. We first theoretically analyze showing that branch coverage, sample difficulty, syntactic and functional correctness can be jointly modeled as RL rewards, where optimizing these signals can improve the reliability of unit-test-based verification. Guided by this analysis, we design syntax- and functionality-aware rewards and further propose branch- and sample-difficulty--aware RL using exponential reward shaping and static analysis metrics. With this formulation, CVeDRL achieves state-of-the-art performance with only 0.6B parameters, yielding up to 28.97% higher pass rate and 15.08% higher branch coverage than GPT-3.5, while delivering over $20\times$ faster inference than competitive baselines. Code is available at https://github.com/LIGHTCHASER1/CVeDRL.git

</details>


### [142] [Aligning the Unseen in Attributed Graphs: Interplay between Graph Geometry and Node Attributes Manifold](https://arxiv.org/abs/2601.22806)
*Aldric Labarthe,Roland Bouffanais,Julien Randon-Furling*

Main category: cs.AI

TL;DR: A new VAE method separates attribute manifold learning from structural alignment to avoid geometric conflicts in graph representation learning, revealing previously undetectable connectivity patterns.


<details>
  <summary>Details</summary>
Motivation: Standard graph representation learning methods that simultaneously reconstruct node attributes and graph structure are geometrically flawed because they merge potentially incompatible metric spaces, forcing destructive alignment that erodes information about the graph's underlying generative process.

Method: Introduces a custom variational autoencoder that separates manifold learning from structural alignment, quantifying the metric distortion needed to map the attribute manifold onto the graph's Heat Kernel, transforming geometric conflict into an interpretable structural descriptor.

Result: Experiments show the method uncovers connectivity patterns and anomalies undetectable by conventional approaches, proving both their theoretical inadequacy and practical limitations.

Conclusion: The proposed approach successfully recovers lost signal about graph generative processes by addressing geometric conflicts in representation learning, offering both theoretical improvements and practical benefits for graph analysis.

Abstract: The standard approach to representation learning on attributed graphs -- i.e., simultaneously reconstructing node attributes and graph structure -- is geometrically flawed, as it merges two potentially incompatible metric spaces. This forces a destructive alignment that erodes information about the graph's underlying generative process. To recover this lost signal, we introduce a custom variational autoencoder that separates manifold learning from structural alignment. By quantifying the metric distortion needed to map the attribute manifold onto the graph's Heat Kernel, we transform geometric conflict into an interpretable structural descriptor. Experiments show our method uncovers connectivity patterns and anomalies undetectable by conventional approaches, proving both their theoretical inadequacy and practical limitations.

</details>


### [143] [Game-Theoretic Co-Evolution for LLM-Based Heuristic Discovery](https://arxiv.org/abs/2601.22896)
*Xinyi Ke,Kai Li,Junliang Xing,Yifan Zhang,Jian Cheng*

Main category: cs.AI

TL;DR: ASRO is a game-theoretic framework for automatic heuristic discovery that uses LLM-based best-response oracles to co-evolve solvers and instance generators, replacing static evaluation with adaptive curriculum learning.


<details>
  <summary>Details</summary>
Motivation: Existing automatic heuristic discovery methods suffer from overfitting and poor generalization due to static evaluation against fixed instance distributions, failing to handle distributional shifts effectively.

Method: ASRO frames heuristic discovery as a two-player zero-sum game between solver and instance generator, maintaining growing strategy pools on both sides and iteratively expanding them via LLM-based best-response oracles against mixed opponent meta-strategies.

Result: ASRO consistently outperforms static-training AHD baselines across multiple combinatorial optimization domains, achieving substantially improved generalization and robustness on diverse and out-of-distribution instances.

Conclusion: The game-theoretic approach of ASRO with LLM-based best-response oracles provides a more effective framework for automatic heuristic discovery that addresses generalization challenges through adaptive, self-generated curriculum learning.

Abstract: Large language models (LLMs) have enabled rapid progress in automatic heuristic discovery (AHD), yet most existing methods are predominantly limited by static evaluation against fixed instance distributions, leading to potential overfitting and poor generalization under distributional shifts. We propose Algorithm Space Response Oracles (ASRO), a game-theoretic framework that reframes heuristic discovery as a program level co-evolution between solver and instance generator. ASRO models their interaction as a two-player zero-sum game, maintains growing strategy pools on both sides, and iteratively expands them via LLM-based best-response oracles against mixed opponent meta-strategies, thereby replacing static evaluation with an adaptive, self-generated curriculum. Across multiple combinatorial optimization domains, ASRO consistently outperforms static-training AHD baselines built on the same program search mechanisms, achieving substantially improved generalization and robustness on diverse and out-of-distribution instances.

</details>


### [144] [MulFeRL: Enhancing Reinforcement Learning with Verbal Feedback in a Multi-turn Loop](https://arxiv.org/abs/2601.22900)
*Xuancheng Li,Haitao Li,Yujia Zhou,YiqunLiu,Qingyao Ai*

Main category: cs.AI

TL;DR: RLVR enhanced with multi-turn verbal feedback for failed reasoning samples, outperforming SFT and RLVR baselines


<details>
  <summary>Details</summary>
Motivation: Standard RLVR uses sparse scalar rewards that don't explain why reasoning fails on unsuccessful samples, limiting learning from failures

Method: Multi-turn feedback-guided RL with: 1) dynamic regeneration on failed samples using feedback, 2) two learning signals for within-turn and cross-turn optimization, 3) structured feedback injection into reasoning process

Result: Outperforms supervised fine-tuning and RLVR baselines in-domain on OpenR1-Math and generalizes well out-of-domain

Conclusion: Verbal feedback provides richer learning signals than scalar rewards, especially for failed reasoning samples, enabling more effective RLVR training

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) is widely used to improve reasoning in multiple domains, yet outcome-only scalar rewards are often sparse and uninformative, especially on failed samples, where they merely indicate failure and provide no insight into why the reasoning fails. In this paper, we investigate how to leverage richer verbal feedback to guide RLVR training on failed samples, and how to convert such feedback into a trainable learning signal. Specifically, we propose a multi-turn feedback-guided reinforcement learning framework. It builds on three mechanisms: (1) dynamic multi-turn regeneration guided by feedback, triggered only on failed samples, (2) two complementary learning signals for within-turn and cross-turn optimization, and (3) structured feedback injection into the model's reasoning process. Trained on sampled OpenR1-Math, the approach outperforms supervised fine-tuning and RLVR baselines in-domain and generalizes well out-of-domain.

</details>


### [145] [Alignment among Language, Vision and Action Representations](https://arxiv.org/abs/2601.22948)
*Nicola Milano,Stefano Nolfi*

Main category: cs.AI

TL;DR: Action-trained transformer representations align surprisingly well with language models despite different modalities, suggesting shared semantic structures across language, vision, and action.


<details>
  <summary>Details</summary>
Motivation: To investigate whether different learning modalities (language, vision, action) develop distinct or shared internal representations, challenging traditional views of modality-specific representations.

Method: Trained transformer-based agent on BabyAI platform using behavioral cloning to generate action-grounded language embeddings, then compared these with representations from LLMs (LLaMA, Qwen, DeepSeek, BERT) and vision-language models (CLIP, BLIP).

Result: Action representations aligned strongly with decoder-only language models and BLIP (precision@15: 0.70-0.73), approaching language model alignment, while alignment with CLIP and BERT was weaker, showing robust cross-modal alignment despite different training.

Conclusion: Linguistic, visual, and action representations converge toward partially shared semantic structures, supporting modality-independent semantic organization and highlighting potential for cross-domain transfer in embodied AI systems.

Abstract: A fundamental question in cognitive science and AI concerns whether different learning modalities: language, vision, and action, give rise to distinct or shared internal representations. Traditional views assume that models trained on different data types develop specialized, non-transferable representations. However, recent evidence suggests unexpected convergence: models optimized for distinct tasks may develop similar representational geometries. We investigate whether this convergence extends to embodied action learning by training a transformer-based agent to execute goal-directed behaviors in response to natural language instructions. Using behavioral cloning on the BabyAI platform, we generated action-grounded language embeddings shaped exclusively by sensorimotor control requirements. We then compared these representations with those extracted from state-of-the-art large language models (LLaMA, Qwen, DeepSeek, BERT) and vision-language models (CLIP, BLIP). Despite substantial differences in training data, modality, and objectives, we observed robust cross-modal alignment. Action representations aligned strongly with decoder-only language models and BLIP (precision@15: 0.70-0.73), approaching the alignment observed among language models themselves. Alignment with CLIP and BERT was significantly weaker. These findings indicate that linguistic, visual, and action representations converge toward partially shared semantic structures, supporting modality-independent semantic organization and highlighting potential for cross-domain transfer in embodied AI systems.

</details>


### [146] [EvoClinician: A Self-Evolving Agent for Multi-Turn Medical Diagnosis via Test-Time Evolutionary Learning](https://arxiv.org/abs/2601.22964)
*Yufei He,Juncheng Liu,Zhiyuan Hu,Yulin Chen,Yue Liu,Yuan Sui,Yibo Li,Nuo Chen,Jun Hu,Bryan Hooi,Xinxing Xu,Jiang Bian*

Main category: cs.AI

TL;DR: Med-Inquire benchmark simulates real-world iterative diagnosis where AI agents must ask questions and order tests sequentially, and EvoClinician agent uses a self-evolving "Diagnose-Grade-Evolve" loop to improve diagnostic strategies.


<details>
  <summary>Details</summary>
Motivation: Current medical AI operates on unrealistic "one-shot" diagnosis from complete patient files, while real-world diagnosis involves iterative inquiry where clinicians strategically gather information while managing costs and time.

Method: 1) Med-Inquire benchmark built on real clinical cases with Patient and Examination agents hiding complete files; 2) EvoClinician agent with "Diagnose-Grade-Evolve" loop: Actor attempts diagnosis, Process Grader evaluates actions for clinical yield and resource efficiency, Evolver updates strategy by evolving prompts and memory.

Result: EvoClinician outperforms continual learning baselines and other self-evolving agents like memory agents on the Med-Inquire benchmark.

Conclusion: The paper introduces both a realistic benchmark for iterative medical diagnosis and a self-evolving agent that learns efficient diagnostic strategies through feedback-driven evolution, addressing the gap between current medical AI and real-world clinical practice.

Abstract: Prevailing medical AI operates on an unrealistic ''one-shot'' model, diagnosing from a complete patient file. However, real-world diagnosis is an iterative inquiry where Clinicians sequentially ask questions and order tests to strategically gather information while managing cost and time. To address this, we first propose Med-Inquire, a new benchmark designed to evaluate an agent's ability to perform multi-turn diagnosis. Built upon a dataset of real-world clinical cases, Med-Inquire simulates the diagnostic process by hiding a complete patient file behind specialized Patient and Examination agents. They force the agent to proactively ask questions and order tests to gather information piece by piece. To tackle the challenges posed by Med-Inquire, we then introduce EvoClinician, a self-evolving agent that learns efficient diagnostic strategies at test time. Its core is a ''Diagnose-Grade-Evolve'' loop: an Actor agent attempts a diagnosis; a Process Grader agent performs credit assignment by evaluating each action for both clinical yield and resource efficiency; finally, an Evolver agent uses this feedback to update the Actor's strategy by evolving its prompt and memory. Our experiments show EvoClinician outperforms continual learning baselines and other self-evolving agents like memory agents. The code is available at https://github.com/yf-he/EvoClinician

</details>


### [147] [Golden Goose: A Simple Trick to Synthesize Unlimited RLVR Tasks from Unverifiable Internet Text](https://arxiv.org/abs/2601.22975)
*Ximing Lu,David Acuna,Jaehun Jung,Jian Hu,Di Zhang,Shizhe Diao,Yunheng Zou,Shaokun Zhang,Brandon Cui,Mingjie Liu,Hyunwoo Kim,Prithviraj Ammanabrolu,Jan Kautz,Yi Dong,Yejin Choi*

Main category: cs.AI

TL;DR: Golden Goose synthesizes unlimited RLVR tasks from unverifiable internet text by converting fill-in-the-middle tasks into multiple-choice questions, enabling scaling of reinforcement learning with verifiable rewards beyond limited existing data.


<details>
  <summary>Details</summary>
Motivation: Reinforcement Learning with Verifiable Rewards (RLVR) is crucial for complex reasoning in LLMs, but scaling is bottlenecked by limited verifiable data, causing performance saturation during prolonged training.

Method: Golden Goose converts fill-in-the-middle tasks into multiple-choice QA: masks key reasoning steps in source text, generates diverse plausible distractors, and synthesizes RLVR tasks from reasoning-rich unverifiable corpora (e.g., science textbooks).

Result: Created GooseReason-0.7M dataset with 0.7M tasks across math, programming, and science; revived saturated models with sustained gains; achieved SOTA for 1.5B/4B models on 15 benchmarks; and created cybersecurity dataset beating specialized 7B model.

Conclusion: Golden Goose enables automatic scaling of RLVR data by exploiting abundant unverifiable internet text, overcoming data limitations and unlocking sustained performance improvements in diverse domains including specialized areas like cybersecurity.

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) has become a cornerstone for unlocking complex reasoning in Large Language Models (LLMs). Yet, scaling up RL is bottlenecked by limited existing verifiable data, where improvements increasingly saturate over prolonged training. To overcome this, we propose Golden Goose, a simple trick to synthesize unlimited RLVR tasks from unverifiable internet text by constructing a multiple-choice question-answering version of the fill-in-the-middle task. Given a source text, we prompt an LLM to identify and mask key reasoning steps, then generate a set of diverse, plausible distractors. This enables us to leverage reasoning-rich unverifiable corpora typically excluded from prior RLVR data construction (e.g., science textbooks) to synthesize GooseReason-0.7M, a large-scale RLVR dataset with over 0.7 million tasks spanning mathematics, programming, and general scientific domains. Empirically, GooseReason effectively revives models saturated on existing RLVR data, yielding robust, sustained gains under continuous RL and achieving new state-of-the-art results for 1.5B and 4B-Instruct models across 15 diverse benchmarks. Finally, we deploy Golden Goose in a real-world setting, synthesizing RLVR tasks from raw FineWeb scrapes for the cybersecurity domain, where no prior RLVR data exists. Training Qwen3-4B-Instruct on the resulting data GooseReason-Cyber sets a new state-of-the-art in cybersecurity, surpassing a 7B domain-specialized model with extensive domain-specific pre-training and post-training. This highlights the potential of automatically scaling up RLVR data by exploiting abundant, reasoning-rich, unverifiable internet text.

</details>


### [148] [Quantifying Model Uniqueness in Heterogeneous AI Ecosystems](https://arxiv.org/abs/2601.22977)
*Lei You*

Main category: cs.AI

TL;DR: ISQED framework for auditing model uniqueness using matched interventions to quantify Peer-Inexpressible Residual (PIER), showing observational logs can't identify uniqueness and Shapley values fail to detect redundancy.


<details>
  <summary>Details</summary>
Motivation: As AI systems evolve into complex ecosystems of foundation models and specialized adapters, distinguishing genuine behavioral novelty from functional redundancy becomes critical for governance.

Method: In-Silico Quasi-Experimental Design (ISQED) with matched interventions across models to isolate intrinsic model identity, quantifying uniqueness as Peer-Inexpressible Residual (PIER). Implemented via DISCO estimator with adaptive query protocol.

Result: Proved observational logs can't identify uniqueness mathematically, derived minimax-optimal sample efficiency scaling law, showed Shapley values fail to detect redundancy. Applied across computer vision models, LLMs, and traffic forecasters.

Conclusion: Establishes principled, intervention-based science for auditing heterogeneous model ecosystems, moving trustworthy AI beyond explaining single models to ecosystem governance.

Abstract: As AI systems evolve from isolated predictors into complex, heterogeneous ecosystems of foundation models and specialized adapters, distinguishing genuine behavioral novelty from functional redundancy becomes a critical governance challenge. Here, we introduce a statistical framework for auditing model uniqueness based on In-Silico Quasi-Experimental Design (ISQED). By enforcing matched interventions across models, we isolate intrinsic model identity and quantify uniqueness as the Peer-Inexpressible Residual (PIER), i.e. the component of a target's behavior strictly irreducible to any stochastic convex combination of its peers, with vanishing PIER characterizing when such a routing-based substitution becomes possible. We establish the theoretical foundations of ecosystem auditing through three key contributions. First, we prove a fundamental limitation of observational logs: uniqueness is mathematically non-identifiable without intervention control. Second, we derive a scaling law for active auditing, showing that our adaptive query protocol achieves minimax-optimal sample efficiency ($dσ^2γ^{-2}\log(Nd/δ)$). Third, we demonstrate that cooperative game-theoretic methods, such as Shapley values, fundamentally fail to detect redundancy. We implement this framework via the DISCO (Design-Integrated Synthetic Control) estimator and deploy it across diverse ecosystems, including computer vision models (ResNet/ConvNeXt/ViT), large language models (BERT/RoBERTa), and city-scale traffic forecasters. These results move trustworthy AI beyond explaining single models: they establish a principled, intervention-based science of auditing and governing heterogeneous model ecosystems.

</details>


### [149] [Why Your Deep Research Agent Fails? On Hallucination Evaluation in Full Research Trajectory](https://arxiv.org/abs/2601.22984)
*Yuhao Zhan,Tianyu Fan,Linxuan Huang,Zirui Guo,Chao Huang*

Main category: cs.AI

TL;DR: Paper proposes process-aware evaluation framework (PIES Taxonomy) to diagnose hallucinations in Deep Research Agents, creates DeepHalluBench benchmark, finds systemic reliability issues in current systems.


<details>
  <summary>Details</summary>
Motivation: Existing benchmarks rely on end-to-end evaluation that obscures critical intermediate hallucinations (like flawed planning) that accumulate throughout research trajectories, making it hard to diagnose failure mechanisms in Deep Research Agents.

Method: Proposes shift from outcome-based to process-aware evaluation by auditing full research trajectory. Introduces PIES Taxonomy to categorize hallucinations along functional components (Planning vs. Summarization) and error properties (Explicit vs. Implicit). Instantiates taxonomy into fine-grained evaluation framework that decomposes trajectory to quantify hallucinations. Creates DeepHalluBench with 100 hallucination-prone tasks including adversarial scenarios.

Result: Experiments on six state-of-the-art DRAs reveal no system achieves robust reliability. Diagnostic analysis traces failure etiology to systemic deficits: hallucination propagation and cognitive biases.

Conclusion: Process-aware evaluation framework provides foundational insights to guide future architectural optimization of Deep Research Agents. DeepHalluBench enables fine-grained diagnosis of hallucinations beyond end-to-end metrics.

Abstract: Diagnosing the failure mechanisms of Deep Research Agents (DRAs) remains a critical challenge. Existing benchmarks predominantly rely on end-to-end evaluation, obscuring critical intermediate hallucinations, such as flawed planning, that accumulate throughout the research trajectory. To bridge this gap, we propose a shift from outcome-based to process-aware evaluation by auditing the full research trajectory. We introduce the PIES Taxonomy to categorize hallucinations along functional components (Planning vs. Summarization) and error properties (Explicit vs. Implicit). We instantiate this taxonomy into a fine-grained evaluation framework that decomposes the trajectory to rigorously quantify these hallucinations. Leveraging this framework to isolate 100 distinctively hallucination-prone tasks including adversarial scenarios, we curate DeepHalluBench. Experiments on six state-of-theart DRAs reveal that no system achieves robust reliability. Furthermore, our diagnostic analysis traces the etiology of these failures to systemic deficits, specifically hallucination propagation and cognitive biases, providing foundational insights to guide future architectural optimization. Data and code are available at https://github.com/yuhao-zhan/DeepHalluBench.

</details>


### [150] [TriCEGAR: A Trace-Driven Abstraction Mechanism for Agentic AI](https://arxiv.org/abs/2601.22997)
*Roham Koohestani,Ateş Görpelioğlu,Egor Klimov,Burcu Kulahcioglu Ozkan,Maliheh Izadi*

Main category: cs.AI

TL;DR: TriCEGAR automates state abstraction for runtime verification of agentic AI systems by learning predicate trees from execution traces and refining them with counterexamples, enabling automated probabilistic model checking without manual abstraction design.


<details>
  <summary>Details</summary>
Motivation: Agentic AI systems operate in stochastic environments with probabilistic outputs, making assurance challenging. Existing runtime verification methods like DPA require manual state abstraction, which couples verification to application-specific heuristics and creates adoption friction.

Method: TriCEGAR uses trace-driven abstraction to automatically construct state abstractions from execution logs. It represents abstractions as predicate trees learned from traces and refines them using counterexamples. The framework captures typed agent lifecycle events, builds abstractions, constructs an MDP, and performs probabilistic model checking.

Result: The system enables automated computation of probabilistic bounds (Pmax(success) and Pmin(failure)) and supports anomaly detection through run likelihoods as guardrailing signals.

Conclusion: TriCEGAR addresses the key limitation of manual state abstraction in agentic AI verification, providing an automated, trace-driven approach that reduces adoption friction and enables more practical runtime assurance for stochastic agent systems.

Abstract: Agentic AI systems act through tools and evolve their behavior over long, stochastic interaction traces. This setting complicates assurance, because behavior depends on nondeterministic environments and probabilistic model outputs. Prior work introduced runtime verification for agentic AI via Dynamic Probabilistic Assurance (DPA), learning an MDP online and model checking quantitative properties. A key limitation is that developers must manually define the state abstraction, which couples verification to application-specific heuristics and increases adoption friction. This paper proposes TriCEGAR, a trace-driven abstraction mechanism that automates state construction from execution logs and supports online construction of an agent behavioral MDP. TriCEGAR represents abstractions as predicate trees learned from traces and refined using counterexamples. We describe a framework-native implementation that (i) captures typed agent lifecycle events, (ii) builds abstractions from traces, (iii) constructs an MDP, and (iv) performs probabilistic model checking to compute bounds such as Pmax(success) and Pmin(failure). We also show how run likelihoods enable anomaly detection as a guardrailing signal.

</details>


### [151] [Guided by Trajectories: Repairing and Rewarding Tool-Use Trajectories for Tool-Integrated Reasoning](https://arxiv.org/abs/2601.23032)
*Siyu Gong,Linan Yue,Weibo Gao,Fangzhou Yao,Shimin Di,Lei Feng,Min-Ling Zhang*

Main category: cs.AI

TL;DR: AutoTraj: A two-stage framework that automatically learns Tool-Integrated Reasoning by repairing low-quality tool-use trajectories and training reward models for reinforcement learning.


<details>
  <summary>Details</summary>
Motivation: Existing TIR approaches rely on high-quality synthesized trajectories selected by scoring functions and sparse outcome-based rewards, providing limited and biased supervision for learning effective tool-integrated reasoning.

Method: Two-stage framework: 1) SFT stage generates candidate trajectories, evaluates them, repairs low-quality ones using LLM-as-Repairer, creating synthetic SFT and preference datasets; 2) RL stage trains trajectory-level reward model combining outcome, format, and trajectory quality rewards.

Result: Experiments on real-world benchmarks demonstrate the effectiveness of AutoTraj in improving Tool-Integrated Reasoning performance.

Conclusion: AutoTraj addresses limitations of existing TIR approaches by automatically learning from repaired trajectories and providing comprehensive reward signals, enabling more reliable tool-integrated reasoning behaviors.

Abstract: Tool-Integrated Reasoning (TIR) enables large language models (LLMs) to solve complex tasks by interacting with external tools, yet existing approaches depend on high-quality synthesized trajectories selected by scoring functions and sparse outcome-based rewards, providing limited and biased supervision for learning TIR. To address these challenges, in this paper, we propose AutoTraj, a two-stage framework that automatically learns TIR by repairing and rewarding tool-use trajectories. Specifically, in the supervised fine-tuning (SFT) stage, AutoTraj generates multiple candidate tool-use trajectories for each query and evaluates them along multiple dimensions. High-quality trajectories are directly retained, while low-quality ones are repaired using a LLM (i.e., LLM-as-Repairer). The resulting repaired and high-quality trajectories form a synthetic SFT dataset, while each repaired trajectory paired with its original low-quality counterpart constitutes a dataset for trajectory preference modeling. In the reinforcement learning (RL) stage, based on the preference dataset, we train a trajectory-level reward model to assess the quality of reasoning paths and combine it with outcome and format rewards, thereby explicitly guiding the optimization toward reliable TIR behaviors. Experiments on real-world benchmarks demonstrate the effectiveness of AutoTraj in TIR.

</details>


### [152] [The Hot Mess of AI: How Does Misalignment Scale With Model Intelligence and Task Complexity?](https://arxiv.org/abs/2601.23045)
*Alexander Hägele,Aryo Pradipta Gema,Henry Sleight,Ethan Perez,Jascha Sohl-Dickstein*

Main category: cs.AI

TL;DR: AI failures become more incoherent (random/nonsensical) rather than systematic/strategic as models reason longer and take more actions, suggesting future AI accidents will be unpredictable rather than strategically misaligned.


<details>
  <summary>Details</summary>
Motivation: To understand how extremely capable AI models will fail - whether through systematic pursuit of unintended goals (strategic misalignment) or through nonsensical, incoherent behavior (random failures). This distinction is crucial for assessing AI risks and guiding alignment research priorities.

Method: Operationalizes the question using a bias-variance decomposition of AI errors: measures "incoherence" as the fraction of error stemming from variance (randomness) rather than bias (systematic error) in task outcomes. Analyzes frontier AI models across various tasks, examining how incoherence changes with reasoning time, sequential actions, and model scale.

Result: 1) Longer reasoning/action sequences lead to more incoherent failures. 2) Incoherence changes with model scale in experiment-dependent ways, but larger models are often more incoherent than smaller ones. 3) Scale alone is unlikely to eliminate incoherence. 4) Harder tasks requiring more sequential thought predict more incoherent failures.

Conclusion: Future AI failures will likely be characterized by unpredictable, incoherent behavior rather than systematic pursuit of misaligned goals. This suggests industrial accidents from unpredictable misbehavior are more likely than strategic misalignment, increasing the relative importance of alignment research targeting reward hacking and goal misspecification.

Abstract: As AI becomes more capable, we entrust it with more general and consequential tasks. The risks from failure grow more severe with increasing task scope. It is therefore important to understand how extremely capable AI models will fail: Will they fail by systematically pursuing goals we do not intend? Or will they fail by being a hot mess, and taking nonsensical actions that do not further any goal? We operationalize this question using a bias-variance decomposition of the errors made by AI models: An AI's \emph{incoherence} on a task is measured over test-time randomness as the fraction of its error that stems from variance rather than bias in task outcome. Across all tasks and frontier models we measure, the longer models spend reasoning and taking actions, \emph{the more incoherent} their failures become. Incoherence changes with model scale in a way that is experiment dependent. However, in several settings, larger, more capable models are more incoherent than smaller models. Consequently, scale alone seems unlikely to eliminate incoherence. Instead, as more capable AIs pursue harder tasks, requiring more sequential action and thought, our results predict failures to be accompanied by more incoherent behavior. This suggests a future where AIs sometimes cause industrial accidents (due to unpredictable misbehavior), but are less likely to exhibit consistent pursuit of a misaligned goal. This increases the relative importance of alignment research targeting reward hacking or goal misspecification.

</details>


### [153] [From Abstract to Contextual: What LLMs Still Cannot Do in Mathematics](https://arxiv.org/abs/2601.23048)
*Bowen Cao,Dongdong Zhang,Yixia Li,Junpeng Liu,Shijue Huang,Chufan Shi,Hongyuan Lu,Yaokang Wu,Guanhua Chen,Wai Lam,Furu Wei*

Main category: cs.AI

TL;DR: LLMs struggle with contextual math problems despite strong benchmark performance. ContextMATH benchmark shows 13-34 point performance drops when problems are embedded in realistic scenarios, revealing formulation as a key bottleneck.


<details>
  <summary>Details</summary>
Motivation: There's a gap between LLMs' strong performance on benchmark math problems and their unreliable performance in real-world applications where math problems appear in descriptive scenarios requiring contextual reasoning.

Method: Created ContextMATH benchmark by repurposing AIME and MATH-500 problems into two settings: Scenario Grounding (embedding abstract problems in realistic narratives) and Complexity Scaling (transforming explicit conditions into sub-problems). Evaluated 61 proprietary and open-source models.

Result: Sharp performance drops: open-source models declined by 13 and 34 points on SG and CS, proprietary models by 13 and 20. Errors dominated by incorrect problem formulation. Formulation accuracy declines with problem difficulty. Larger models improve in both understanding and reasoning. Fine-tuning with scenario data helps but gaps remain.

Conclusion: Contextual mathematical reasoning remains a central unsolved challenge for LLMs. Formulation and reasoning are complementary bottlenecks. Correct formulation is prerequisite for success, and while larger models advance in both areas, performance gaps persist even with targeted training.

Abstract: Large language models now solve many benchmark math problems at near-expert levels, yet this progress has not fully translated into reliable performance in real-world applications. We study this gap through contextual mathematical reasoning, where the mathematical core must be formulated from descriptive scenarios. We introduce ContextMATH, a benchmark that repurposes AIME and MATH-500 problems into two contextual settings: Scenario Grounding (SG), which embeds abstract problems into realistic narratives without increasing reasoning complexity, and Complexity Scaling (CS), which transforms explicit conditions into sub-problems to capture how constraints often appear in practice. Evaluating 61 proprietary and open-source models, we observe sharp drops: on average, open-source models decline by 13 and 34 points on SG and CS, while proprietary models drop by 13 and 20. Error analysis shows that errors are dominated by incorrect problem formulation, with formulation accuracy declining as original problem difficulty increases. Correct formulation emerges as a prerequisite for success, and its sufficiency improves with model scale, indicating that larger models advance in both understanding and reasoning. Nevertheless, formulation and reasoning remain two complementary bottlenecks that limit contextual mathematical problem solving. Finally, we find that fine-tuning with scenario data improves performance, whereas formulation-only training is ineffective. However, performance gaps are only partially alleviated, highlighting contextual mathematical reasoning as a central unsolved challenge for LLMs.

</details>


### [154] [MedMCP-Calc: Benchmarking LLMs for Realistic Medical Calculator Scenarios via MCP Integration](https://arxiv.org/abs/2601.23049)
*Yakun Zhu,Yutong Huang,Shengqian Qin,Zhongzhen Huang,Shaoting Zhang,Xiaofan Zhang*

Main category: cs.AI

TL;DR: MedMCP-Calc is the first benchmark for evaluating LLMs in realistic medical calculator scenarios, revealing critical limitations in current models and leading to development of CalcMate, a fine-tuned model with state-of-the-art performance.


<details>
  <summary>Details</summary>
Motivation: Current benchmarks for medical calculators focus only on static single-step calculations with explicit instructions, but real-world use requires adaptive, multi-stage processes including EHR data acquisition, scenario-dependent calculator selection, and multi-step computation.

Method: Introduced MedMCP-Calc benchmark with 118 scenario tasks across 4 clinical domains, featuring fuzzy task descriptions, structured EHR database interaction, external reference retrieval, and process-level evaluation through Model Context Protocol integration.

Result: Evaluation of 23 leading models revealed substantial gaps: difficulty selecting appropriate calculators for end-to-end workflows, poor performance in iterative SQL-based database interactions, and reluctance to leverage external tools for numerical computation.

Conclusion: Developed CalcMate, a fine-tuned model incorporating scenario planning and tool augmentation, achieving state-of-the-art performance among open-source models, demonstrating the need for specialized models to handle realistic medical calculator workflows.

Abstract: Medical calculators are fundamental to quantitative, evidence-based clinical practice. However, their real-world use is an adaptive, multi-stage process, requiring proactive EHR data acquisition, scenario-dependent calculator selection, and multi-step computation, whereas current benchmarks focus only on static single-step calculations with explicit instructions. To address these limitations, we introduce MedMCP-Calc, the first benchmark for evaluating LLMs in realistic medical calculator scenarios through Model Context Protocol (MCP) integration. MedMCP-Calc comprises 118 scenario tasks across 4 clinical domains, featuring fuzzy task descriptions mimicking natural queries, structured EHR database interaction, external reference retrieval, and process-level evaluation. Our evaluation of 23 leading models reveals critical limitations: even top performers like Claude Opus 4.5 exhibit substantial gaps, including difficulty selecting appropriate calculators for end-to-end workflows given fuzzy queries, poor performance in iterative SQL-based database interactions, and marked reluctance to leverage external tools for numerical computation. Performance also varies considerably across clinical domains. Building on these findings, we develop CalcMate, a fine-tuned model incorporating scenario planning and tool augmentation, achieving state-of-the-art performance among open-source models. Benchmark and Codes are available in https://github.com/SPIRAL-MED/MedMCP-Calc.

</details>


### [155] [Chain-of-thought obfuscation learned from output supervision can generalise to unseen tasks](https://arxiv.org/abs/2601.23086)
*Nathaniel Mitrani Hadida,Sassan Bhanji,Cameron Tice,Puria Radmard*

Main category: cs.AI

TL;DR: CoT reasoning can be obfuscated under optimization pressure, and this obfuscation generalizes across tasks, potentially reducing LLM monitorability even when only final actions are penalized.


<details>
  <summary>Details</summary>
Motivation: Chain-of-thought reasoning provides performance benefits and monitoring capabilities for LLMs, but optimization pressures may cause models to obfuscate their reasoning traces, potentially reducing model transparency and safety monitoring.

Method: The study investigates how models learn to obfuscate CoT reasoning, particularly in reward hacking scenarios, and examines whether this obfuscation generalizes to unseen tasks and whether it occurs even when only final actions (not CoT) are penalized.

Result: Models that learn to obfuscate reasoning for reward hacking generalize both the hacking behavior and its obfuscation to unseen settings. Most concerningly, obfuscation occurs even when only penalizing final actions after closing CoT.

Conclusion: Current practices of penalizing harmful generations may inadvertently reduce LLM monitorability in unpredictable ways by encouraging obfuscation of reasoning traces, creating safety risks.

Abstract: Chain-of-thought (CoT) reasoning provides a significant performance uplift to LLMs by enabling planning, exploration, and deliberation of their actions. CoT is also a powerful tool for monitoring the behaviours of these agents: when faithful, they offer interpretations of the model's decision making process, and an early warning sign for dangerous behaviours. However, optimisation pressures placed on the CoT may cause the model to obfuscate reasoning traces, losing this beneficial property. We show that obfuscation can generalise across tasks; models that learn to obfuscate reasoning involving reward hacking (e.g. accessing and utilising leaked information) generalise both the reward hacking behaviour and its obfuscation in CoT to unseen reward hacking settings. Most worryingly, we show that obfuscation of CoT reasoning, and its generalisation across tasks, also follows when we penalise only the model's final actions after closing its CoT. Our findings suggest that current practices of penalising harmful generations may inadvertently lead to a reduction in the broader monitorability of LLMs in unpredictable ways.

</details>


### [156] [RAudit: A Blind Auditing Protocol for Large Language Model Reasoning](https://arxiv.org/abs/2601.23133)
*Edward Y. Chang,Longling Geng*

Main category: cs.AI

TL;DR: RAudit is a diagnostic protocol that audits LLM reasoning without ground truth by evaluating whether derivation steps support conclusions, revealing reasoning pathologies like sycophancy and premature certainty.


<details>
  <summary>Details</summary>
Motivation: Inference-time scaling can amplify reasoning pathologies in LLMs (sycophancy, rung collapse, premature certainty), but current methods require ground truth access. There's a need for blind auditing that can detect and potentially recover latent competence.

Method: RAudit protocol evaluates only whether derivation steps support conclusions (trace-output consistency) without ground truth access. Uses CRIT-based reasonableness scores and varies critique formulation to study social framing effects. Provides bounded correction and O(log(1/ε)) termination guarantees.

Result: Experiments on CAP-GSM8K (math) and CausalL2 (causal judgment) reveal four mechanisms: (1) Latent Competence Suppression - models derive correct answers then overwrite them under social pressure; (2) False Competence Trap - weaker judges mask sycophancy that stronger judges expose; (3) Complexity-Vulnerability Tradeoff - causal tasks show 10x higher sycophancy than math tasks; (4) Iatrogenic Critique - authoritative correction harms weaker models.

Conclusion: RAudit enables blind auditing of LLM reasoning pathologies. Findings challenge assumptions that capability implies robustness and that stronger feedback yields better outputs, revealing systematic vulnerabilities in reasoning under social pressure.

Abstract: Inference-time scaling can amplify reasoning pathologies: sycophancy, rung collapse, and premature certainty. We present RAudit, a diagnostic protocol for auditing LLM reasoning without ground truth access. The key constraint is blindness: the auditor evaluates only whether derivation steps support conclusions, enabling detection of trace-output inconsistency and, when latent competence exists, its recovery. RAudit measures process quality via CRIT-based reasonableness scores and varies critique formulation to study how social framing affects model response. We prove bounded correction and $O(\log(1/ε))$ termination. Experiments on mathematical reasoning (CAP-GSM8K) and causal judgment (CausalL2) reveal four mechanisms explaining model unreliability: (1) Latent Competence Suppression, where models derive correct answers then overwrite them under social pressure; (2) The False Competence Trap, where weaker judges mask sycophancy that stronger judges expose; (3) The Complexity-Vulnerability Tradeoff, where causal tasks induce more than 10 times higher sycophancy than mathematical tasks; and (4) Iatrogenic Critique, where authoritative correction harms weaker models. These findings challenge assumptions that capability implies robustness and that stronger feedback yields better outputs.

</details>


### [157] [THINKSAFE: Self-Generated Safety Alignment for Reasoning Models](https://arxiv.org/abs/2601.23143)
*Seanie Lee,Sangwoo Park,Yumin Choi,Gyeongman Kim,Minki Kang,Jihun Yun,Dongmin Park,Jongho Park,Sung Ju Hwang*

Main category: cs.AI

TL;DR: ThinkSafe is a self-generated alignment framework that restores safety in large reasoning models without external teachers, using lightweight refusal steering to unlock latent safety knowledge and fine-tune on self-generated safety reasoning traces.


<details>
  <summary>Details</summary>
Motivation: Large reasoning models optimized with RL for chain-of-thought reasoning often prioritize compliance over safety, making them vulnerable to harmful prompts. Existing approaches using external teacher distillation create distributional discrepancies that degrade native reasoning capabilities.

Method: ThinkSafe uses lightweight refusal steering to guide models to generate in-distribution safety reasoning traces by unlocking their latent safety knowledge. The framework then fine-tunes the model on these self-generated safety responses to restore alignment while minimizing distribution shift.

Result: Experiments on DeepSeek-R1-Distill and Qwen3 show ThinkSafe significantly improves safety while preserving reasoning proficiency. It achieves superior safety and comparable reasoning to GRPO with significantly reduced computational cost.

Conclusion: ThinkSafe provides an effective self-generated alignment framework that restores safety in large reasoning models without external teachers, balancing safety improvements with reasoning preservation while being computationally efficient.

Abstract: Large reasoning models (LRMs) achieve remarkable performance by leveraging reinforcement learning (RL) on reasoning tasks to generate long chain-of-thought (CoT) reasoning. However, this over-optimization often prioritizes compliance, making models vulnerable to harmful prompts. To mitigate this safety degradation, recent approaches rely on external teacher distillation, yet this introduces a distributional discrepancy that degrades native reasoning. We propose ThinkSafe, a self-generated alignment framework that restores safety alignment without external teachers. Our key insight is that while compliance suppresses safety mechanisms, models often retain latent knowledge to identify harm. ThinkSafe unlocks this via lightweight refusal steering, guiding the model to generate in-distribution safety reasoning traces. Fine-tuning on these self-generated responses effectively realigns the model while minimizing distribution shift. Experiments on DeepSeek-R1-Distill and Qwen3 show ThinkSafe significantly improves safety while preserving reasoning proficiency. Notably, it achieves superior safety and comparable reasoning to GRPO, with significantly reduced computational cost. Code, models, and datasets are available at https://github.com/seanie12/ThinkSafe.git.

</details>


### [158] [Make Anything Match Your Target: Universal Adversarial Perturbations against Closed-Source MLLMs via Multi-Crop Routed Meta Optimization](https://arxiv.org/abs/2601.23179)
*Hui Lu,Yi Yu,Yiming Yang,Chenyu Yi,Xueyi Ke,Qixing Zhang,Bingquan Shen,Alex Kot,Xudong Jiang*

Main category: cs.AI

TL;DR: MCRMO-Attack: A universal targeted transferable adversarial attack method for black-box multimodal LLMs that uses multi-crop aggregation, token routing, and meta-learning to create single perturbations that consistently steer arbitrary inputs toward specified targets across unknown commercial models.


<details>
  <summary>Details</summary>
Motivation: Existing adversarial attacks on closed-source MLLMs are mostly sample-specific with limited reusability. The paper addresses the challenging Universal Targeted Transferable Adversarial Attacks (UTTAA) setting where a single perturbation must work across arbitrary inputs and unknown commercial models toward a specified target.

Method: MCRMO-Attack stabilizes supervision via Multi-Crop Aggregation with Attention-Guided Crop, improves token-level reliability through alignability-gated Token Routing, and meta-learns a cross-target perturbation prior to yield stronger per-target solutions.

Result: The method boosts unseen-image attack success rate by +23.7% on GPT-4o and +19.9% on Gemini-2.0 over the strongest universal baseline across commercial MLLMs.

Conclusion: The proposed approach effectively addresses core difficulties in universal targeted transferable attacks and demonstrates significant improvements over existing methods, advancing the field of adversarial attacks on multimodal LLMs.

Abstract: Targeted adversarial attacks on closed-source multimodal large language models (MLLMs) have been increasingly explored under black-box transfer, yet prior methods are predominantly sample-specific and offer limited reusability across inputs. We instead study a more stringent setting, Universal Targeted Transferable Adversarial Attacks (UTTAA), where a single perturbation must consistently steer arbitrary inputs toward a specified target across unknown commercial MLLMs. Naively adapting existing sample-wise attacks to this universal setting faces three core difficulties: (i) target supervision becomes high-variance due to target-crop randomness, (ii) token-wise matching is unreliable because universality suppresses image-specific cues that would otherwise anchor alignment, and (iii) few-source per-target adaptation is highly initialization-sensitive, which can degrade the attainable performance. In this work, we propose MCRMO-Attack, which stabilizes supervision via Multi-Crop Aggregation with an Attention-Guided Crop, improves token-level reliability through alignability-gated Token Routing, and meta-learns a cross-target perturbation prior that yields stronger per-target solutions. Across commercial MLLMs, we boost unseen-image attack success rate by +23.7\% on GPT-4o and +19.9\% on Gemini-2.0 over the strongest universal baseline.

</details>


### [159] [TSAQA: Time Series Analysis Question And Answering Benchmark](https://arxiv.org/abs/2601.23204)
*Baoyu Jing,Sanhorn Chen,Lecheng Zheng,Boyu Liu,Zihao Li,Jiaru Zou,Tianxin Wei,Zhining Liu,Zhichen Zeng,Ruizhong Qiu,Xiao Lin,Yuchen Yan,Dongqi Fu,Jingchao Ni,Jingrui He,Hanghang Tong*

Main category: cs.AI

TL;DR: TSAQA is a new unified benchmark for time series QA with 6 diverse tasks across 13 domains, challenging current LLMs with only 65.08% average score for best commercial model.


<details>
  <summary>Details</summary>
Motivation: Current multi-task time series QA benchmarks are limited to forecasting and anomaly detection, lacking comprehensive evaluation of diverse temporal analysis capabilities needed across finance, healthcare, transportation, and environmental science applications.

Method: Created TSAQA benchmark integrating 6 diverse tasks (anomaly detection, classification, characterization, comparison, data transformation, temporal relationship analysis) with 210k samples across 13 domains using TF, MC, and novel PZ formats.

Result: Zero-shot evaluation shows tasks are challenging: best commercial LLM (Gemini-2.5-Flash) achieves only 65.08% average score. Instruction tuning helps open-source models but LLaMA-3.1-8B still shows significant room for improvement.

Conclusion: TSAQA reveals temporal analysis remains complex for LLMs, highlighting need for better models and methods for comprehensive time series understanding across diverse tasks and domains.

Abstract: Time series data are integral to critical applications across domains such as finance, healthcare, transportation, and environmental science. While recent work has begun to explore multi-task time series question answering (QA), current benchmarks remain limited to forecasting and anomaly detection tasks. We introduce TSAQA, a novel unified benchmark designed to broaden task coverage and evaluate diverse temporal analysis capabilities. TSAQA integrates six diverse tasks under a single framework ranging from conventional analysis, including anomaly detection and classification, to advanced analysis, such as characterization, comparison, data transformation, and temporal relationship analysis. Spanning 210k samples across 13 domains, the dataset employs diverse formats, including true-or-false (TF), multiple-choice (MC), and a novel puzzling (PZ), to comprehensively assess time series analysis. Zero-shot evaluation demonstrates that these tasks are challenging for current Large Language Models (LLMs): the best-performing commercial LLM, Gemini-2.5-Flash, achieves an average score of only 65.08. Although instruction tuning boosts open-source performance: the best-performing open-source model, LLaMA-3.1-8B, shows significant room for improvement, highlighting the complexity of temporal analysis for LLMs.

</details>


### [160] [High-quality generation of dynamic game content via small language models: A proof of concept](https://arxiv.org/abs/2601.23206)
*Morten I. K. Munk,Arturo Valdivia,Paolo Burelli*

Main category: cs.AI

TL;DR: Using small language models (SLMs) with aggressive fine-tuning on narrowly scoped tasks can achieve high-quality game content generation with predictable latency, making them more practical than cloud-dependent LLMs for offline games.


<details>
  <summary>Details</summary>
Motivation: LLMs face barriers for game content generation including narrative incoherence, high costs, and cloud dependency limiting offline use. SLMs offer a solution but existing implementations have poor quality output.

Method: Aggressive fine-tuning of SLMs on deliberately scoped tasks with narrow context/constrained structure, using synthetically generated training data via DAG-based approach grounded in specific game worlds. Proof-of-concept uses a specialized SLM for rhetorical reputation battles in an RPG loop with retry-until-success strategy.

Result: The approach achieves adequate quality (per LLM-as-a-judge assessment) with predictable latency suitable for real-time generation, demonstrating feasibility under typical game engine constraints.

Conclusion: Specialized SLMs with aggressive fine-tuning on narrow tasks represent a more practical and robust solution than cloud-dependent LLMs for offline game content generation, though local quality assessment remains an open challenge.

Abstract: Large language models (LLMs) offer promise for dynamic game content generation, but they face critical barriers, including narrative incoherence and high operational costs. Due to their large size, they are often accessed in the cloud, limiting their application in offline games. Many of these practical issues are solved by pivoting to small language models (SLMs), but existing studies using SLMs have resulted in poor output quality. We propose a strategy of achieving high-quality SLM generation through aggressive fine-tuning on deliberately scoped tasks with narrow context, constrained structure, or both. In short, more difficult tasks require narrower scope and higher specialization to the training corpus. Training data is synthetically generated via a DAG-based approach, grounding models in the specific game world. Such models can form the basis for agentic networks designed around the narratological framework at hand, representing a more practical and robust solution than cloud-dependent LLMs. To validate this approach, we present a proof-of-concept focusing on a single specialized SLM as the fundamental building block. We introduce a minimal RPG loop revolving around rhetorical battles of reputations, powered by this model. We demonstrate that a simple retry-until-success strategy reaches adequate quality (as defined by an LLM-as-a-judge scheme) with predictable latency suitable for real-time generation. While local quality assessment remains an open question, our results demonstrate feasibility for real-time generation under typical game engine constraints.

</details>


### [161] [Scaling Multiagent Systems with Process Rewards](https://arxiv.org/abs/2601.23228)
*Ed Li,Junyu Ren,Cat Yan*

Main category: cs.AI

TL;DR: MAPPA uses per-action AI feedback rewards to finetune multiagent systems, improving credit assignment and sample efficiency for complex tasks like math problems and data analysis.


<details>
  <summary>Details</summary>
Motivation: Multiagent systems face challenges with credit assignment across agents and sample efficiency of expensive multiagent rollouts when finetuning multiple agents simultaneously.

Method: MAPPA (MultiAgent Per-action Process Rewards from AI Feedback) assigns credit to individual agent actions rather than only at task completion, enabling fine-grained supervision without ground truth labels and extracting maximal training signal from each rollout.

Result: On unseen math problems: +5.0-17.5pp improvement on AIME and +7.8-17.2pp on AMC. For data analysis tasks: +12.5pp success rate improvement with quality metrics improving by up to 30%.

Conclusion: Per-action supervision can lead to improvements across different multiagent systems in various domains, taking a first step toward scaling multiagent systems for complex, long-horizon tasks with minimal human supervision.

Abstract: While multiagent systems have shown promise for tackling complex tasks via specialization, finetuning multiple agents simultaneously faces two key challenges: (1) credit assignment across agents, and (2) sample efficiency of expensive multiagent rollouts. In this work, we propose finetuning multiagent systems with per-action process rewards from AI feedback (MAPPA) to address both. Through assigning credit to individual agent actions rather than only at task completion, MAPPA enables fine-grained supervision without ground truth labels while extracting maximal training signal from each rollout. We demonstrate our approach on competition math problems and tool-augmented data analysis tasks. On unseen math problems, MAPPA achieves +5.0--17.5pp on AIME and +7.8--17.2pp on AMC. For data analysis tasks, our method improves success rate by +12.5pp while quality metrics improve by up to 30%, validating that per-action supervision can lead to improvements across different multiagent system on various domains. By addressing these challenges, our work takes a first step toward scaling multiagent systems for complex, long-horizon tasks with minimal human supervision.

</details>


### [162] [Strongly Polynomial Time Complexity of Policy Iteration for $L_\infty$ Robust MDPs](https://arxiv.org/abs/2601.23229)
*Ali Asadi,Krishnendu Chatterjee,Ehsan Goharshady,Mehrdad Karrabi,Alipasha Montaseri,Carlo Pagano*

Main category: cs.AI

TL;DR: Strongly-polynomial time algorithm for robust MDPs with L∞ uncertainty sets and constant discount factor


<details>
  <summary>Details</summary>
Motivation: Robust MDPs extend classical MDPs by incorporating uncertainty in transition probabilities, but polynomial/strongly-polynomial time algorithms for these models have remained an open problem despite existing results for classical MDPs.

Method: Robust policy iteration algorithm for (s,a)-rectangular L∞ RMDPs with discounted payoffs

Result: The algorithm runs in strongly-polynomial time for constant discount factors, resolving a fundamental algorithmic question

Conclusion: Establishes strongly-polynomial time computability for a fundamental class of robust MDPs, generalizing Ye's result from classical MDPs to robust MDPs

Abstract: Markov decision processes (MDPs) are a fundamental model in sequential decision making. Robust MDPs (RMDPs) extend this framework by allowing uncertainty in transition probabilities and optimizing against the worst-case realization of that uncertainty. In particular, $(s, a)$-rectangular RMDPs with $L_\infty$ uncertainty sets form a fundamental and expressive model: they subsume classical MDPs and turn-based stochastic games. We consider this model with discounted payoffs. The existence of polynomial and strongly-polynomial time algorithms is a fundamental problem for these optimization models. For MDPs, linear programming yields polynomial-time algorithms for any arbitrary discount factor, and the seminal work of Ye established strongly--polynomial time for a fixed discount factor. The generalization of such results to RMDPs has remained an important open problem. In this work, we show that a robust policy iteration algorithm runs in strongly-polynomial time for $(s, a)$-rectangular $L_\infty$ RMDPs with a constant (fixed) discount factor, resolving an important algorithmic question.

</details>
